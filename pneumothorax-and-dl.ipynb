{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Importing and installing relevant packages for our project","metadata":{}},{"cell_type":"markdown","source":"**Let's install some packages**","metadata":{}},{"cell_type":"code","source":"pip install pyradiomics","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:13.426162Z","iopub.execute_input":"2022-01-19T01:09:13.427023Z","iopub.status.idle":"2022-01-19T01:09:26.224223Z","shell.execute_reply.started":"2022-01-19T01:09:13.426923Z","shell.execute_reply":"2022-01-19T01:09:26.223243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U segmentation-models","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:26.226448Z","iopub.execute_input":"2022-01-19T01:09:26.226697Z","iopub.status.idle":"2022-01-19T01:09:34.571728Z","shell.execute_reply.started":"2022-01-19T01:09:26.226666Z","shell.execute_reply":"2022-01-19T01:09:34.570951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's import some packages**","metadata":{}},{"cell_type":"code","source":"import os \nimport cv2\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nimport random\nfrom tqdm import tqdm\nimport numpy as np\nfrom numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import Input, Dropout, Conv2D, MaxPooling2D, concatenate, Reshape, Conv2DTranspose, LeakyReLU, BatchNormalization, Activation, UpSampling2D \nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import models \nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.callbacks import History \nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping \nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.keras.initializers import RandomNormal\nimport seaborn \nimport seaborn as sns\nfrom tensorflow.keras.optimizers import RMSprop\nfrom sklearn.feature_selection import RFECV\nfrom pathlib import Path\nimport ast\nimport time\nfrom IPython import display\nfrom IPython.display import clear_output\n%env SM_FRAMEWORK=tf.keras","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:34.573557Z","iopub.execute_input":"2022-01-19T01:09:34.573796Z","iopub.status.idle":"2022-01-19T01:09:41.10294Z","shell.execute_reply.started":"2022-01-19T01:09:34.573768Z","shell.execute_reply":"2022-01-19T01:09:41.102113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.inspection import permutation_importance","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:41.104571Z","iopub.execute_input":"2022-01-19T01:09:41.104812Z","iopub.status.idle":"2022-01-19T01:09:41.159012Z","shell.execute_reply.started":"2022-01-19T01:09:41.104786Z","shell.execute_reply":"2022-01-19T01:09:41.15835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:41.160442Z","iopub.execute_input":"2022-01-19T01:09:41.161015Z","iopub.status.idle":"2022-01-19T01:09:41.614964Z","shell.execute_reply.started":"2022-01-19T01:09:41.160971Z","shell.execute_reply":"2022-01-19T01:09:41.614103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport SimpleITK as sitk\nimport six\nfrom radiomics import featureextractor, getTestCase, glcm, glrlm, glszm, imageoperations, shape, getImageTypes, getFeatureClasses, getParameterValidationFiles","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:41.615863Z","iopub.execute_input":"2022-01-19T01:09:41.61608Z","iopub.status.idle":"2022-01-19T01:09:42.05746Z","shell.execute_reply.started":"2022-01-19T01:09:41.616056Z","shell.execute_reply":"2022-01-19T01:09:42.056532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Defining variables","metadata":{}},{"cell_type":"code","source":"SIZE = 256\nCHANNELS = 1\n\nIMG_HEIGHT, IMG_WIDTH = 256,256\nSEED=1\nNUM_SAMPLES = 4000\nBATCH_SIZE = 1\nEPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:42.058652Z","iopub.execute_input":"2022-01-19T01:09:42.058905Z","iopub.status.idle":"2022-01-19T01:09:42.064028Z","shell.execute_reply.started":"2022-01-19T01:09:42.058877Z","shell.execute_reply":"2022-01-19T01:09:42.063191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 128\nCHANNELS = 1\n\nIMG_HEIGHT, IMG_WIDTH = 128,128\nSEED=1\nNUM_SAMPLES = 4000\nBATCH_SIZE = 1\nEPOCHS = 100","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:40:29.127943Z","iopub.execute_input":"2021-10-09T15:40:29.128277Z","iopub.status.idle":"2021-10-09T15:40:29.133897Z","shell.execute_reply.started":"2021-10-09T15:40:29.128246Z","shell.execute_reply":"2021-10-09T15:40:29.133077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Importing datasets path","metadata":{}},{"cell_type":"markdown","source":"**DATASET: *XRAY BONE SHADOW SUPRESSION***","metadata":{}},{"cell_type":"code","source":"supression_images_dir = os.path.join(\"../input/xray-bone-shadow-supression/augmented/augmented/source/\")\nsupression_targets_dir = os.path.join(\"../input/xray-bone-shadow-supression/augmented/augmented/target/\")\nsupression_images_list = os.listdir(supression_images_dir)\nsupression_target_list = os.listdir(supression_targets_dir)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:09:42.06637Z","iopub.execute_input":"2022-01-19T01:09:42.066717Z","iopub.status.idle":"2022-01-19T01:09:42.466505Z","shell.execute_reply.started":"2022-01-19T01:09:42.066687Z","shell.execute_reply":"2022-01-19T01:09:42.465582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *RANZCR CLIP LUNG CONTOURS***\n\nPhilippSchwarz explained how to import this dataset in this [notebook](https://www.kaggle.com/philippschwarz/ranzcr-lung-mask-model-not-pretrained).","metadata":{}},{"cell_type":"code","source":"TRAIN_PATH = '../input/ranzcr-clip-cxr-dataset/kaggle_images/'\nIMAGE_LIB = TRAIN_PATH\nctr = pd.read_csv('../input/ranzcr-clip-lung-contours/RANZCR_CLiP_lung_contours.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *CHEST XRAY MASKS AND LABELS***","metadata":{}},{"cell_type":"code","source":"image_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png\")\nmask_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/\",\"masks/\")\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *CHEST X-RAY IMAGES WITH PNEUMOTHORAX MASKS***","metadata":{}},{"cell_type":"code","source":"DATADIR_IMAGES = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_images/'\nDF_TEST = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_test_images.csv')\nDF_TRAIN = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_train_images.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *NIH Chest X-ray Dataset Sample***","metadata":{}},{"cell_type":"code","source":"DF_LUNG_DISEASES=pd.read_csv(\"../input/data/Data_Entry_2017.csv\")\nLUNG_DISEASES_DIR = os.path.join('../input/data')","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:40:34.551872Z","iopub.execute_input":"2021-10-09T15:40:34.552195Z","iopub.status.idle":"2021-10-09T15:40:34.8474Z","shell.execute_reply.started":"2021-10-09T15:40:34.552161Z","shell.execute_reply":"2021-10-09T15:40:34.846523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nwith zipfile.ZipFile(\"../input/diseases-images//DISEASES.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"images\")","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:40:35.08559Z","iopub.execute_input":"2021-10-09T15:40:35.085894Z","iopub.status.idle":"2021-10-09T15:41:08.287609Z","shell.execute_reply.started":"2021-10-09T15:40:35.085864Z","shell.execute_reply":"2021-10-09T15:41:08.286692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with zipfile.ZipFile(\"../input/diseases-attention//DISEASES_ATTENTION.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"attention_images\")","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:41:08.289536Z","iopub.execute_input":"2021-10-09T15:41:08.289893Z","iopub.status.idle":"2021-10-09T15:41:25.027331Z","shell.execute_reply.started":"2021-10-09T15:41:08.289848Z","shell.execute_reply":"2021-10-09T15:41:25.026527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Catching images","metadata":{}},{"cell_type":"markdown","source":"**DATASET: *XRAY BONE SHADOW SUPRESSION***","metadata":{}},{"cell_type":"code","source":"supression_images = list()\nsupression_targets = list()\nj = 0\nfor i in tqdm(supression_target_list):\n    if j < NUM_SAMPLES:\n        path_images = supression_images_dir + str(i)\n        path_targets = supression_targets_dir + str(i)\n        image = cv2.imread(path_images,cv2.IMREAD_GRAYSCALE)\n        image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n        image = cv2.bitwise_not(image)\n        image = cv2.equalizeHist(image)\n        targets = cv2.imread(path_targets,cv2.IMREAD_GRAYSCALE) \n        targets = cv2.resize(targets, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n        targets = cv2.bitwise_not(targets)\n        targets = cv2.equalizeHist(targets)\n        supression_images.append(image)\n        supression_targets.append(targets)\n    j += 1","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:10:05.519885Z","iopub.execute_input":"2022-01-19T01:10:05.520605Z","iopub.status.idle":"2022-01-19T01:13:00.852912Z","shell.execute_reply.started":"2022-01-19T01:10:05.520558Z","shell.execute_reply":"2022-01-19T01:13:00.851672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"supression_images[0]","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:14:03.972941Z","iopub.execute_input":"2022-01-19T01:14:03.973387Z","iopub.status.idle":"2022-01-19T01:14:03.978629Z","shell.execute_reply.started":"2022-01-19T01:14:03.973357Z","shell.execute_reply":"2022-01-19T01:14:03.978016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"supression_images","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:13:00.855798Z","iopub.execute_input":"2022-01-19T01:13:00.856138Z","iopub.status.idle":"2022-01-19T01:13:01.159138Z","shell.execute_reply.started":"2022-01-19T01:13:00.856108Z","shell.execute_reply":"2022-01-19T01:13:01.158156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,2, figsize = (8,4))\nax[0].imshow(supression_images[number], cmap='gray')\nax[1].imshow(supression_targets[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Autoencoder - Supression","metadata":{}},{"cell_type":"code","source":"SUPRESSION_IMAGES = (np.array(supression_images).reshape((len(supression_images), SIZE, SIZE, 1))).astype('float32') / 255\nSUPRESSION_TARGETS = (np.array(supression_targets).reshape((len(supression_targets), SIZE, SIZE, 1))).astype('float32') / 255\nX_train, X_test, y_train, y_test = train_test_split(SUPRESSION_IMAGES, SUPRESSION_TARGETS, test_size=0.30, random_state=12)","metadata":{"execution":{"iopub.status.busy":"2022-01-19T01:13:26.998165Z","iopub.execute_input":"2022-01-19T01:13:26.998462Z","iopub.status.idle":"2022-01-19T01:13:29.069007Z","shell.execute_reply.started":"2022-01-19T01:13:26.998431Z","shell.execute_reply":"2022-01-19T01:13:29.068161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *RANZCR CLIP LUNG CONTOURS***\n\nHelper Function (load_mask) to read masks proposed by radda in this [notebook](https://www.kaggle.com/raddar/simple-lung-contour-visualization).","metadata":{}},{"cell_type":"code","source":"def load_mask(StudyInstanceUID):\n    img = cv2.imread(IMAGE_LIB+StudyInstanceUID+'.jpg',-1)\n    ctr_left = ast.literal_eval(ctr.loc[ctr.StudyInstanceUID==StudyInstanceUID,'left_lung_contour'].values[0])\n    ctr_right = ast.literal_eval(ctr.loc[ctr.StudyInstanceUID==StudyInstanceUID,'right_lung_contour'].values[0])\n    img = cv2.drawContours(img, np.array([[np.array(x) for x in ctr_left]]), 0, (255), -1)\n    img = cv2.drawContours(img, np.array([[np.array(x) for x in ctr_right]]), 0, (255), -1)\n    img = np.where(img>=255, 1.0, 0.0)\n    return img\n\nall_images = os.listdir(TRAIN_PATH)[:NUM_SAMPLES]\nall_images = [Path(e).stem for e in all_images]\n\nx_data = np.empty((len(all_images), IMG_HEIGHT, IMG_WIDTH), dtype='float32')\nfor i, name in enumerate(tqdm(all_images)):\n    im = cv2.imread(IMAGE_LIB + name +'.jpg', cv2.IMREAD_GRAYSCALE)\n    im = cv2.resize(im, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_LANCZOS4)\n    im = cv2.equalizeHist(im)\n    x_data[i] = im","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,1, figsize = (8,4))\nax.imshow(x_data[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEGMENTATION_IMAGES = (np.array(x_data).reshape((len(x_data), SIZE, SIZE, 1)).astype('float32')) / 255 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel im\ndel x_data\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_mask(StudyInstanceUID):\n    img = cv2.imread(IMAGE_LIB+StudyInstanceUID+'.jpg',-1)\n    ctr_left = ast.literal_eval(ctr.loc[ctr.StudyInstanceUID==StudyInstanceUID,'left_lung_contour'].values[0])\n    ctr_right = ast.literal_eval(ctr.loc[ctr.StudyInstanceUID==StudyInstanceUID,'right_lung_contour'].values[0])\n    img = cv2.drawContours(img, np.array([[np.array(x) for x in ctr_left]]), 0, (255), -1)\n    img = cv2.drawContours(img, np.array([[np.array(x) for x in ctr_right]]), 0, (255), -1)\n    img = np.where(img>=255, 1.0, 0.0)\n    return img\n\nall_images = os.listdir(TRAIN_PATH)[:NUM_SAMPLES]\nall_images = [Path(e).stem for e in all_images]\n\nx_data = list()\nx_data_otsu = list()\nx_data_canny = list()\nfor number in tqdm(range(0,len(SEGMENTATION_IMAGES))):\n    im = loaded_model_autoencoder.predict(SEGMENTATION_IMAGES[[number]].astype(np.float32))\n    im = np.squeeze(im.astype(np.float32))\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    plt.imsave('predicted_supression.jpg', im, cmap='gray')\n    im = cv2.imread('./predicted_supression.jpg',1)\n    im = im[:,:,1]\n    im = cv2.equalizeHist(im)\n    x_data.append(im)\n    im = cv2.GaussianBlur(im,(5,5),0)\n    im_ = cv2.Canny(im,56,56)\n    _,im = cv2.threshold(im,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    im = cv2.bitwise_not(im)\n    x_data_otsu.append(im)\n    x_data_canny.append(im_) \n    \ny_data = list()\nfor i, name in enumerate(tqdm(all_images)):  \n    im = load_mask(name)\n    im = cv2.resize(im, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_NEAREST)\n    y_data.append(im)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,4, figsize = (8,4))\nax[0].imshow(x_data[number], cmap='gray')\nax[1].imshow(x_data_otsu[number], cmap='gray')\nax[2].imshow(x_data_canny[number], cmap='gray')\nax[3].imshow(y_data[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GAN - Input","metadata":{}},{"cell_type":"code","source":"import gc\ndel im\ndel im_\ngc.collect()\n\nSEGMENTATION_IMAGES_GAN = (np.array(x_data).reshape((len(x_data), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nSEGMENTATION_IMAGES_OTSU_GAN = (np.array(x_data_otsu).reshape((len(x_data_otsu), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nSEGMENTATION_IMAGES_CANNY_GAN = (np.array(x_data_canny).reshape((len(x_data_canny), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nSEGMENTATION_TARGETS_GAN = (np.array(y_data).reshape((len(y_data), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel x_data\ndel x_data_otsu\ndel x_data_canny\ndel y_data\ndel SEGMENTATION_IMAGES\n#del SEGMENTATION_IMAGES_OTSU\n#del SEGMENTATION_IMAGES_CANNY\n#del SEGMENTATION_TARGETS\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_X = tf.data.Dataset.from_tensor_slices(SEGMENTATION_IMAGES_GAN).batch(BATCH_SIZE)\ntrain_dataset_otsu_X = tf.data.Dataset.from_tensor_slices(SEGMENTATION_IMAGES_OTSU_GAN).batch(BATCH_SIZE)\ntrain_dataset_canny_X = tf.data.Dataset.from_tensor_slices(SEGMENTATION_IMAGES_CANNY_GAN).batch(BATCH_SIZE)\ntrain_dataset_y = tf.data.Dataset.from_tensor_slices(SEGMENTATION_TARGETS_GAN).batch(BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Autoencoder - Input","metadata":{}},{"cell_type":"code","source":"SEGMENTATION_IMAGES = (np.array(x_data).reshape((len(x_data), SIZE, SIZE, 1)).astype('float32')) / 255\nSEGMENTATION_TARGETS = (np.array(y_data).reshape((len(y_data), SIZE, SIZE, 1)).astype('float32')) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_R = list()\n\nfor img in SEGMENTATION_IMAGES:\n    img_R = np.concatenate((img,)*3, axis=-1)\n    X_train_R.append(img_R)\n    \nX_train_R = np.array(X_train_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n#del im\n#del im_\n#del x_data\n#del x_data_otsu\n#del x_data_canny\n#del y_data\ndel SEGMENTATION_IMAGES_GAN\ndel SEGMENTATION_IMAGES_OTSU_GAN\ndel SEGMENTATION_IMAGES_CANNY_GAN\ndel SEGMENTATION_TARGETS_GAN\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *CHEST XRAY MASKS AND LABELS***\n\nMethodology to read images proposed by sumit pandey in this [notebook](https://www.kaggle.com/sumitai/lung-segmentation-from-chest-x-ray-dataset).","metadata":{}},{"cell_type":"code","source":"mask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]\ncheck = [i for i in mask if \"mask\" in i]\n\ntesting_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check\n\nima = list()\nj = 0\nfor i in tqdm(testing_files):\n    im = cv2.imread(os.path.join(image_path,i),cv2.IMREAD_GRAYSCALE)\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    im = cv2.equalizeHist(im)\n    ima.append(im)\n    \nfor i in tqdm(training_files): \n    im = cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\"),cv2.IMREAD_GRAYSCALE)\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    im = cv2.equalizeHist(im)\n    ima.append(im)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,1, figsize = (8,4))\nax.imshow(ima[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Autoencoder - Supression","metadata":{}},{"cell_type":"code","source":"SEGMENTATION_IMAGES_2 = (np.array(ima).reshape((len(ima), SIZE, SIZE, 1)).astype('float32'))/255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel im\ndel ima\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_data = list()\nx_data_otsu = list()\nx_data_canny = list()\nfor number in tqdm(range(0,len(SEGMENTATION_IMAGES_2))):\n    im = loaded_model_autoencoder.predict(SEGMENTATION_IMAGES_2[[number]].astype(np.float32))\n    im = np.squeeze(im.astype(np.float32))\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    plt.imsave('predicted_supression.jpg', im, cmap='gray')\n    im = cv2.imread('./predicted_supression.jpg',1)\n    im = im[:,:,1]\n    im = cv2.equalizeHist(im)\n    x_data.append(im)\n    im = cv2.GaussianBlur(im,(5,5),0)\n    im_ = cv2.Canny(im,56,56)\n    _,im = cv2.threshold(im,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    im = cv2.bitwise_not(im)\n    x_data_otsu.append(im)\n    x_data_canny.append(im_) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]\ncheck = [i for i in mask if \"mask\" in i]\n\ntesting_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check\n\n\nmas = list()\nj = 0\nfor i in tqdm(testing_files):\n    mask = cv2.imread(os.path.join(mask_path,i),cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    _,mask = cv2.threshold(mask,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    mas.append(mask)\n    \nfor i in tqdm(training_files): \n    mask = cv2.imread(os.path.join(mask_path,i+\".png\"),cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    _,mask = cv2.threshold(mask,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    mas.append(mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,4, figsize = (16,8))\nax[0].imshow(x_data[number], cmap='gray')\nax[1].imshow(x_data_otsu[number], cmap='gray')\nax[2].imshow(x_data_canny[number], cmap='gray')\nax[3].imshow(mas[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GAN - Input","metadata":{}},{"cell_type":"code","source":"SEGMENTATION_IMAGES_GAN_3 = (np.array(x_data).reshape((len(x_data), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nSEGMENTATION_IMAGES_OTSU_GAN_3 = (np.array(x_data_otsu).reshape((len(x_data_otsu), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nSEGMENTATION_IMAGES_CANNY_GAN_3 = (np.array(x_data_canny).reshape((len(x_data_canny), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nSEGMENTATION_TARGETS_GAN_3 = (np.array(mas).reshape((len(mas), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Autoencoder - Input","metadata":{}},{"cell_type":"code","source":"SEGMENTATION_IMAGES_3 = (np.array(x_data).reshape((len(x_data), SIZE, SIZE, 1)).astype('float32')) / 255\nSEGMENTATION_TARGETS_3 = (np.array(mas).reshape((len(mas), SIZE, SIZE, 1)).astype('float32')) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_R = list()\n\nfor img in SEGMENTATION_IMAGES_3:\n    img_R = np.concatenate((img,)*3, axis=-1)\n    X_test_R.append(img_R)\n    \nX_test_R = np.array(X_test_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel im\ndel im_\ndel mas\ndel mask\ndel x_data\ndel x_data_otsu\ndel x_data_canny\ndel y_data\n#del SEGMENTATION_IMAGES_2\n#del SEGMENTATION_IMAGES_OTSU_2\n#del SEGMENTATION_IMAGES_CANNY_2\n#del SEGMENTATION_TARGETS_2\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *CHEST X-RAY IMAGES WITH PNEUMOTHORAX MASKS***","metadata":{}},{"cell_type":"code","source":"LEN_TRAIN_NO_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 0].shape[0]\nLEN_TRAIN_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 1].shape[0]\nLEN_TEST_NO_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 0].shape[0]\nLEN_TEST_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 1].shape[0]\n\nIMAGE_TRAIN_PNEUMO = list()\nIMAGE_TRAIN_NO_PNEUMO = list()\nIMAGE_TEST_PNEUMO = list()\nIMAGE_TEST_NO_PNEUMO = list()\n\nCLASS_IMAGE_TRAIN_PNEUMO = list()\nCLASS_IMAGE_TRAIN_NO_PNEUMO = list()\nCLASS_IMAGE_TEST_PNEUMO = list()\nCLASS_IMAGE_TEST_NO_PNEUMO = list()\n\nNAME_TRAIN_PNEUMO = list()\nNAME_TRAIN_NO_PNEUMO = list()\nNAME_TEST_PNEUMO = list()\nNAME_TEST_NO_PNEUMO = list()\n\nfor i in tqdm(range(0,int(1500))):\n    DF_TRAIN_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 1]\n    IMAGE_NAME = DF_TRAIN_PNEUMO.iloc[i,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TRAIN_PNEUMO.append(image)\n    CLASS_IMAGE_TRAIN_PNEUMO.append(1)\n    NAME_TRAIN_PNEUMO.append(IMAGE_NAME)\n\nfor j in tqdm(range(0,int(1500))):\n    DF_TRAIN_NO_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 0]\n    IMAGE_NAME = DF_TRAIN_NO_PNEUMO.iloc[j,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TRAIN_NO_PNEUMO.append(image)\n    CLASS_IMAGE_TRAIN_NO_PNEUMO.append(0)\n    NAME_TRAIN_NO_PNEUMO.append(IMAGE_NAME)\n    \nfor k in tqdm(range(0,int(250))):\n    DF_TEST_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 1]\n    IMAGE_NAME = DF_TEST_PNEUMO.iloc[k,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TEST_PNEUMO.append(image)\n    CLASS_IMAGE_TEST_PNEUMO.append(1)\n    NAME_TEST_PNEUMO.append(IMAGE_NAME)\n    \nfor l in tqdm(range(0,int(250))):\n    DF_TEST_NO_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 0]\n    IMAGE_NAME = DF_TEST_NO_PNEUMO.iloc[l,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TEST_NO_PNEUMO.append(image)\n    CLASS_IMAGE_TEST_NO_PNEUMO.append(0)\n    NAME_TEST_NO_PNEUMO.append(IMAGE_NAME)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,4, figsize = (8,4))\nax[0].imshow(IMAGE_TRAIN_PNEUMO[number], cmap='gray')\nax[1].imshow(IMAGE_TRAIN_NO_PNEUMO[number], cmap='gray')\nax[2].imshow(IMAGE_TEST_PNEUMO[number], cmap='gray')\nax[3].imshow(IMAGE_TEST_NO_PNEUMO[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLASS_IMAGE_TRAIN_PNEUMO = np.array(CLASS_IMAGE_TRAIN_PNEUMO)\nCLASS_IMAGE_TRAIN_NO_PNEUMO = np.array(CLASS_IMAGE_TRAIN_NO_PNEUMO)\nCLASS_IMAGE_TEST_PNEUMO = np.array(CLASS_IMAGE_TEST_PNEUMO)\nCLASS_IMAGE_TEST_NO_PNEUMO = np.array(CLASS_IMAGE_TEST_NO_PNEUMO)\n\nCLASS_TRAIN = np.concatenate((CLASS_IMAGE_TRAIN_PNEUMO,CLASS_IMAGE_TRAIN_NO_PNEUMO))\nCLASS_TEST = np.concatenate((CLASS_IMAGE_TEST_PNEUMO,CLASS_IMAGE_TEST_NO_PNEUMO))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel image\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Autoencoder - Supression","metadata":{}},{"cell_type":"code","source":"IMAGE_TRAIN_PNEUMO_ = (np.array(IMAGE_TRAIN_PNEUMO).reshape((len(IMAGE_TRAIN_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255\nIMAGE_TRAIN_NO_PNEUMO_ = (np.array(IMAGE_TRAIN_NO_PNEUMO).reshape((len(IMAGE_TRAIN_NO_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255\nIMAGE_TEST_PNEUMO_ = (np.array(IMAGE_TEST_PNEUMO).reshape((len(IMAGE_TEST_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255\nIMAGE_TEST_NO_PNEUMO_ = (np.array(IMAGE_TEST_NO_PNEUMO).reshape((len(IMAGE_TEST_NO_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel IMAGE_TRAIN_PNEUMO\ndel IMAGE_TRAIN_NO_PNEUMO\ndel IMAGE_TEST_PNEUMO\ndel IMAGE_TEST_NO_PNEUMO\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LEN_TRAIN_NO_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 0].shape[0]\nLEN_TRAIN_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 1].shape[0]\nLEN_TEST_NO_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 0].shape[0]\nLEN_TEST_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 1].shape[0]\n\nIMAGE_TRAIN_PNEUMO = list()\nIMAGE_TRAIN_PNEUMO_OTSU = list()\nIMAGE_TRAIN_PNEUMO_CANNY = list()\nIMAGE_TRAIN_NO_PNEUMO = list()\nIMAGE_TRAIN_NO_PNEUMO_OTSU = list()\nIMAGE_TRAIN_NO_PNEUMO_CANNY = list()\nIMAGE_TEST_PNEUMO = list()\nIMAGE_TEST_PNEUMO_OTSU = list()\nIMAGE_TEST_PNEUMO_CANNY = list()\nIMAGE_TEST_NO_PNEUMO = list()\nIMAGE_TEST_NO_PNEUMO_OTSU = list()\nIMAGE_TEST_NO_PNEUMO_CANNY = list()\n\nfor i in tqdm(range(0,int(1500))):\n    image = loaded_model_autoencoder.predict(IMAGE_TRAIN_PNEUMO_[[i]].astype(np.float32))\n    image = np.squeeze(image.astype(np.float32))\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    plt.imsave('predicted_supression.jpg', image, cmap='gray')\n    image = cv2.imread('./predicted_supression.jpg',1)\n    image = image[:,:,1]\n    image = cv2.equalizeHist(image)\n    IMAGE_TRAIN_PNEUMO.append(image)\n    image = cv2.GaussianBlur(image,(5,5),0)\n    image_ = cv2.Canny(image,56,56)\n    _,image = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    image = cv2.bitwise_not(image)\n    IMAGE_TRAIN_PNEUMO_OTSU.append(image)\n    IMAGE_TRAIN_PNEUMO_CANNY.append(image_)\n\nfor j in tqdm(range(0,int(1500))):\n    image = loaded_model_autoencoder.predict(IMAGE_TRAIN_NO_PNEUMO_[[j]].astype(np.float32))\n    image = np.squeeze(image.astype(np.float32))\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    plt.imsave('predicted_supression.jpg', image, cmap='gray')\n    image = cv2.imread('./predicted_supression.jpg',1)\n    image = image[:,:,1]\n    image = cv2.equalizeHist(image)\n    IMAGE_TRAIN_NO_PNEUMO.append(image)\n    image = cv2.GaussianBlur(image,(5,5),0)\n    image_ = cv2.Canny(image,56,56)\n    _,image = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    image = cv2.bitwise_not(image)\n    IMAGE_TRAIN_NO_PNEUMO_OTSU.append(image)\n    IMAGE_TRAIN_NO_PNEUMO_CANNY.append(image_)\n    \nfor k in tqdm(range(0,int(250))):\n    image = loaded_model_autoencoder.predict(IMAGE_TEST_PNEUMO_[[k]].astype(np.float32))\n    image = np.squeeze(image.astype(np.float32))\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    plt.imsave('predicted_supression.jpg', image, cmap='gray')\n    image = cv2.imread('./predicted_supression.jpg',1)\n    image = image[:,:,1]\n    image = cv2.equalizeHist(image)\n    IMAGE_TEST_PNEUMO.append(image)\n    image = cv2.GaussianBlur(image,(5,5),0)\n    image_ = cv2.Canny(image,56,56)\n    _,image = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    image = cv2.bitwise_not(image)\n    IMAGE_TEST_PNEUMO_OTSU.append(image)\n    IMAGE_TEST_PNEUMO_CANNY.append(image_)\n\nfor l in tqdm(range(0,int(250))):\n    image = loaded_model_autoencoder.predict(IMAGE_TEST_NO_PNEUMO_[[l]].astype(np.float32))\n    image = np.squeeze(image.astype(np.float32))\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    plt.imsave('predicted_supression.jpg', image, cmap='gray')\n    image = cv2.imread('./predicted_supression.jpg',1)\n    image = image[:,:,1]\n    image = cv2.equalizeHist(image)\n    IMAGE_TEST_NO_PNEUMO.append(image)\n    image = cv2.GaussianBlur(image,(5,5),0)\n    image_ = cv2.Canny(image,56,56)\n    _,image = cv2.threshold(image,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    image = cv2.bitwise_not(image)\n    IMAGE_TEST_NO_PNEUMO_OTSU.append(image)\n    IMAGE_TEST_NO_PNEUMO_CANNY.append(image_)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,3, figsize = (8,4))\nax[0].imshow(IMAGE_TRAIN_PNEUMO[number], cmap='gray')\nax[1].imshow(IMAGE_TRAIN_PNEUMO_OTSU[number], cmap='gray')\nax[2].imshow(IMAGE_TRAIN_PNEUMO_CANNY[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Autoencoder - Input","metadata":{}},{"cell_type":"code","source":"IMAGE_TRAIN_PNEUMO__ = (np.array(IMAGE_TRAIN_PNEUMO).reshape((len(IMAGE_TRAIN_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255\nIMAGE_TRAIN_NO_PNEUMO__ = (np.array(IMAGE_TRAIN_NO_PNEUMO).reshape((len(IMAGE_TRAIN_NO_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255\nIMAGE_TEST_PNEUMO__ = (np.array(IMAGE_TEST_PNEUMO).reshape((len(IMAGE_TEST_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255\nIMAGE_TEST_NO_PNEUMO__ = (np.array(IMAGE_TEST_NO_PNEUMO).reshape((len(IMAGE_TEST_NO_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32')) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PNEUMOTHORAX_IMAGES_TRAIN = np.concatenate((IMAGE_TRAIN_PNEUMO__,IMAGE_TRAIN_NO_PNEUMO__))\nPNEUMOTHORAX_IMAGES_TEST = np.concatenate((IMAGE_TEST_PNEUMO__,IMAGE_TEST_NO_PNEUMO__))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./PNEUMOTHORAX/images_segment_pneumothorax_train_auto')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_TRAIN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_TRAIN[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_segment_pneumothorax_train_auto/'+ str(i) + '_train.png',predicted_rx, cmap = 'gray')\nos.makedirs('./PNEUMOTHORAX/images_segment_pneumothorax_test_auto')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_TEST))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_TEST[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_segment_pneumothorax_test_auto/'+ str(i) + '_test.png',predicted_rx, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel image\ndel IMAGE_TRAIN_PNEUMO__\ndel IMAGE_TRAIN_NO_PNEUMO__\ndel IMAGE_TEST_PNEUMO__\ndel IMAGE_TEST_NO_PNEUMO__\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GAN - Input","metadata":{}},{"cell_type":"code","source":"IMAGE_TRAIN_PNEUMOx = (np.array(IMAGE_TRAIN_PNEUMO).reshape((len(IMAGE_TRAIN_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TRAIN_PNEUMO_OTSUx = (np.array(IMAGE_TRAIN_PNEUMO_OTSU).reshape((len(IMAGE_TRAIN_PNEUMO_OTSU), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TRAIN_PNEUMO_CANNYx = (np.array(IMAGE_TRAIN_PNEUMO_CANNY).reshape((len(IMAGE_TRAIN_PNEUMO_CANNY), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\n\nIMAGE_TRAIN_NO_PNEUMOx = (np.array(IMAGE_TRAIN_NO_PNEUMO).reshape((len(IMAGE_TRAIN_NO_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TRAIN_NO_PNEUMO_OTSUx = (np.array(IMAGE_TRAIN_NO_PNEUMO_OTSU).reshape((len(IMAGE_TRAIN_NO_PNEUMO_OTSU), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TRAIN_NO_PNEUMO_CANNYx = (np.array(IMAGE_TRAIN_NO_PNEUMO_CANNY).reshape((len(IMAGE_TRAIN_NO_PNEUMO_CANNY), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\n\nIMAGE_TEST_PNEUMOx = (np.array(IMAGE_TEST_PNEUMO).reshape((len(IMAGE_TEST_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TEST_PNEUMO_OTSUx = (np.array(IMAGE_TEST_PNEUMO_OTSU).reshape((len(IMAGE_TEST_PNEUMO_OTSU), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TEST_PNEUMO_CANNYx = (np.array(IMAGE_TEST_PNEUMO_CANNY).reshape((len(IMAGE_TEST_PNEUMO_CANNY), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\n\nIMAGE_TEST_NO_PNEUMOx = (np.array(IMAGE_TEST_NO_PNEUMO).reshape((len(IMAGE_TEST_NO_PNEUMO), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TEST_NO_PNEUMO_OTSUx = (np.array(IMAGE_TEST_NO_PNEUMO_OTSU).reshape((len(IMAGE_TEST_NO_PNEUMO_OTSU), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5\nIMAGE_TEST_NO_PNEUMO_CANNYx = (np.array(IMAGE_TEST_NO_PNEUMO_CANNY).reshape((len(IMAGE_TEST_NO_PNEUMO_CANNY), SIZE, SIZE, CHANNELS)).astype('float32') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel IMAGE_TRAIN_PNEUMO\ndel IMAGE_TRAIN_NO_PNEUMO\ndel IMAGE_TRAIN_PNEUMO_OTSU\ndel IMAGE_TRAIN_NO_PNEUMO_OTSU\ndel IMAGE_TRAIN_PNEUMO_CANNY\ndel IMAGE_TRAIN_NO_PNEUMO_CANNY\ndel IMAGE_TEST_PNEUMO\ndel IMAGE_TEST_NO_PNEUMO\ndel IMAGE_TEST_PNEUMO_OTSU\ndel IMAGE_TEST_NO_PNEUMO_OTSU\ndel IMAGE_TEST_PNEUMO_CANNY\ndel IMAGE_TEST_NO_PNEUMO_CANNY\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PNEUMOTHORAX_IMAGES_TRAIN_GAN = np.concatenate((IMAGE_TRAIN_PNEUMOx,IMAGE_TRAIN_NO_PNEUMOx))\nPNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN = np.concatenate((IMAGE_TRAIN_PNEUMO_OTSUx,IMAGE_TRAIN_NO_PNEUMO_OTSUx))\nPNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN = np.concatenate((IMAGE_TRAIN_PNEUMO_CANNYx,IMAGE_TRAIN_NO_PNEUMO_CANNYx))\nPNEUMOTHORAX_IMAGES_TEST_GAN = np.concatenate((IMAGE_TEST_PNEUMOx,IMAGE_TEST_NO_PNEUMOx))\nPNEUMOTHORAX_IMAGES_OTSU_TEST_GAN = np.concatenate((IMAGE_TEST_PNEUMO_OTSUx,IMAGE_TEST_NO_PNEUMO_OTSUx))\nPNEUMOTHORAX_IMAGES_CANNY_TEST_GAN = np.concatenate((IMAGE_TEST_PNEUMO_CANNYx,IMAGE_TEST_NO_PNEUMO_CANNYx))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel IMAGE_TRAIN_PNEUMOx\ndel IMAGE_TRAIN_NO_PNEUMOx\ndel IMAGE_TRAIN_PNEUMO_OTSUx\ndel IMAGE_TRAIN_NO_PNEUMO_OTSUx\ndel IMAGE_TRAIN_PNEUMO_CANNYx\ndel IMAGE_TRAIN_NO_PNEUMO_CANNYx\ndel IMAGE_TEST_PNEUMOx\ndel IMAGE_TEST_NO_PNEUMOx\ndel IMAGE_TEST_PNEUMO_OTSUx\ndel IMAGE_TEST_NO_PNEUMO_OTSUx\ndel IMAGE_TEST_PNEUMO_CANNYx\ndel IMAGE_TEST_NO_PNEUMO_CANNYx\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del _\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./PNEUMOTHORAX/images_segment_pneumothorax_train_GAN')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_TRAIN_GAN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_TRAIN_GAN[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_segment_pneumothorax_train_GAN/'+ str(i) + '_train.png',predicted_rx, cmap = 'gray')\nos.makedirs('./PNEUMOTHORAX/images_otsu_segment_pneumothorax_train_GAN')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_otsu_segment_pneumothorax_train_GAN/'+ str(i) + '_train.png',predicted_rx, cmap = 'gray')\nos.makedirs('./PNEUMOTHORAX/images_canny_segment_pneumothorax_train_GAN')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_canny_segment_pneumothorax_train_GAN/'+ str(i) + '_train.png',predicted_rx, cmap = 'gray')\n\nos.makedirs('./PNEUMOTHORAX/images_segment_pneumothorax_test_GAN')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_TEST_GAN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_TEST_GAN[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_segment_pneumothorax_test_GAN/'+ str(i) + '_test.png',predicted_rx, cmap = 'gray')\nos.makedirs('./PNEUMOTHORAX/images_segment_otsu_pneumothorax_test_GAN')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_OTSU_TEST_GAN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_OTSU_TEST_GAN[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_segment_otsu_pneumothorax_test_GAN/'+ str(i) + '_test.png',predicted_rx, cmap = 'gray')\nos.makedirs('./PNEUMOTHORAX/images_segment_canny_pneumothorax_test_GAN')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_CANNY_TEST_GAN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_CANNY_TEST_GAN[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/images_segment_canny_pneumothorax_test_GAN/'+ str(i) + '_test.png',predicted_rx, cmap = 'gray')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n \nfantasy_zip = zipfile.ZipFile('./PNEUMOTHORAX_MASKS.zip', 'w')\n \nfor folder, subfolders, files in os.walk('./PNEUMOTHORAX'):\n \n    for file in files:\n        if file.endswith('.png'):\n            fantasy_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), './PNEUMOTHORAX'), compress_type = zipfile.ZIP_DEFLATED)\n \nfantasy_zip.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = cv2.imread('../input/pneumothorax/images_segment_pneumothorax_train_GAN/0_image_train.jpg',0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im = (im.reshape((256, 256, 1)).astype('float32') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(im, cmap = 'gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**DATASET: *NIH Chest X-ray Dataset***","metadata":{}},{"cell_type":"code","source":"DF_LUNG_DISEASES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES[\"Finding Labels\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",'No Finding',\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]\ndisease_of_interest = list()\nfor i in tqdm(range(0,DF_LUNG_DISEASES[\"Finding Labels\"].count())):\n    if DF_LUNG_DISEASES[\"Finding Labels\"].iloc[i] in label_names:\n        class_ = 1\n    else:\n        class_ = 0 \n    disease_of_interest.append(class_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES['disease_of_interest'] = disease_of_interest\nDF_LUNG_DISEASES.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['disease_of_interest'] == 0 ]\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nDF_LUNG_DISEASES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'No Finding']\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES_INTE.head(40198)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nDF_LUNG_DISEASES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NAMES_JPG_1 = DF_LUNG_DISEASES['Image Index'].str.replace('.png', '.jpg')\nNAMES_JPG_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES[\"Finding Labels\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_theme(style=\"darkgrid\")\nplt.figure(figsize=(40,20))\nsns.countplot(DF_LUNG_DISEASES[\"Finding Labels\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###\nIMAGES = list()\nNAMES = list()\n\nfor i in tqdm(range(1,10)):\n    DIR = LUNG_DISEASES_DIR + \"/images_00\" + str(i) + \"/images/\"\n    LIST = os.listdir(DIR)\n    for j in tqdm(LIST):\n        PATH = DIR + j\n        IMAGE = cv2.imread(os.path.join(PATH),cv2.IMREAD_GRAYSCALE)\n        IMAGE = cv2.resize(IMAGE, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n        IMAGES.append(IMAGE)\n        NAMES.append(j)\n        clear_output(wait=True)\n        \nfor i in tqdm(range(10,13)):\n    DIR = LUNG_DISEASES_DIR + \"/images_0\" + str(i) + \"/images/\"\n    LIST = os.listdir(DIR)\n    for j in tqdm(LIST):\n        PATH = DIR + j\n        IMAGE = cv2.imread(os.path.join(PATH),cv2.IMREAD_GRAYSCALE)\n        IMAGE = cv2.resize(IMAGE, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n        IMAGES.append(IMAGE)\n        NAMES.append(j)\n        clear_output(wait=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NME_LIST = pd.DataFrame({'Image Index': NAMES})\nNAMES_JPG_2 = NME_LIST['Image Index'].str.replace('.png', '.jpg')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./DISEASES/images')\nfor i in tqdm(range(0,len(NAMES))):\n    plt.imsave('./DISEASES/images/'+ str(NAMES_JPG_2.iloc[i]),IMAGES[i], cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NAMES_JPG_2.to_csv('./DISEASES/image_names', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n \nfantasy_zip = zipfile.ZipFile('./DISEASES.zip', 'w')\n \nfor folder, subfolders, files in os.walk('./DISEASES'):\n \n    for file in files:\n        if file.endswith('.jpg'):\n            fantasy_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), './PNEUMOTHORAX'), compress_type = zipfile.ZIP_DEFLATED)\n \nfantasy_zip.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**LET'S GO**","metadata":{}},{"cell_type":"code","source":"DF_LUNG_DISEASES_input = pd.read_csv(\"../input/diseases-image-names/image_names.csv\")\nDF_LUNG_DISEASES_input = DF_LUNG_DISEASES_input.drop(columns = 'Unnamed: 0')\nDF_LUNG_DISEASES_input","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"###\nimport gc\n\nDIR_ = './images/DISEASES/images/'\n\nos.makedirs('./Diseases/normal')\nos.makedirs('./Diseases/otsu')\nos.makedirs('./Diseases/canny')\n\nIMAGE_DISEASE = list()\nIMAGE_DISEASE_OTSU = list()\nIMAGE_DISEASE_CANNY = list()\nbatch = 2\nfor h in range(0+batch,1+batch):\n    c = int((len(NAMES_JPG_1)/3)*h) \n    for i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/3)+c))):\n        PATH = DIR_ + NAMES_JPG_1.iloc[i]\n        IMAGE = cv2.imread(os.path.join(PATH),cv2.IMREAD_GRAYSCALE)\n        IMAGE = (np.asarray(IMAGE).reshape(1,SIZE, SIZE, CHANNELS).astype('float16')) / 255\n        IMAGE = loaded_model_autoencoder.predict(IMAGE.astype(np.float16))\n        IMAGE = np.squeeze(IMAGE.astype(np.float32))\n        IMAGE = cv2.resize(IMAGE, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n        plt.imsave('predicted_supression.png', IMAGE, cmap='gray')\n        IMAGE = cv2.imread('./predicted_supression.png',1)\n        IMAGE = IMAGE[:,:,1]\n        IMAGE = cv2.equalizeHist(IMAGE)\n        IMAGE_DISEASE.append(IMAGE)\n        IMAGE_ = cv2.Canny(IMAGE,56,56)\n        IMAGE= cv2.GaussianBlur(IMAGE,(5,5),0)\n        _,IMAGE = cv2.threshold(IMAGE,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        IMAGE = cv2.bitwise_not(IMAGE)\n        IMAGE_DISEASE_OTSU.append(IMAGE)\n        IMAGE_DISEASE_CANNY.append(IMAGE_)\n    \n    \n    for i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/3)+c))):\n        predicted_rx = np.squeeze(IMAGE_DISEASE[i-c].astype(np.float16))\n        plt.imsave('./Diseases/normal/'+ str(NAMES_JPG_1.iloc[i]),predicted_rx, cmap = 'gray')\n    \n    for i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/3)+c))):\n        predicted_rx = np.squeeze(IMAGE_DISEASE_OTSU[i-c].astype(np.float16))\n        plt.imsave('./Diseases/otsu/'+ str(NAMES_JPG_1.iloc[i]),predicted_rx, cmap = 'gray')\n    \n    for i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/3)+c))):\n        predicted_rx = np.squeeze(IMAGE_DISEASE_CANNY[i-c].astype(np.float16))\n        plt.imsave('./Diseases/canny/'+ str(NAMES_JPG_1.iloc[i]),predicted_rx, cmap = 'gray')\n\n    del IMAGE\n    del IMAGE_DISEASE\n    del IMAGE_DISEASE_OTSU\n    del IMAGE_DISEASE_CANNY \n    del predicted_rx\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n \nfantasy_zip = zipfile.ZipFile('./DISEASES_2.zip', 'w')\n \nfor folder, subfolders, files in os.walk('./Diseases'):\n \n    for file in files:\n        if file.endswith('.jpg'):\n            fantasy_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), './PNEUMOTHORAX'), compress_type = zipfile.ZIP_DEFLATED)\n \nfantasy_zip.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Read the images","metadata":{}},{"cell_type":"code","source":"IMAGE_DISEASE_1275 = list()\nIMAGE_DISEASE_2550 = list()\nIMAGE_DISEASE_OTSU = list()\nIMAGE_DISEASE_CANNY = list()\n\nbatch = 15\n\nDIR_input = '../input/diseases-eq-images-otsu-canny/Diseases/normal/'\nfor h in range(0+batch,1+batch):\n    c = int((len(NAMES_JPG_1)/16)*h) \n    for i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/16)+c))):\n        PATH = DIR_input + NAMES_JPG_1.iloc[i]\n        IMAGE_DISEASE_1275.append((cv2.imread(os.path.join(PATH),cv2.IMREAD_GRAYSCALE).astype('float16')- 127.5) / 127.5)\n        IMAGE_DISEASE_2550.append((cv2.imread(os.path.join(PATH),cv2.IMREAD_GRAYSCALE).astype('float16')) / 255.)    \n\nDIR_input = '../input/diseases-eq-images-otsu-canny/Diseases/otsu/'\nfor h in range(0+batch,1+batch):\n    c = int((len(NAMES_JPG_1)/16)*h) \n    for i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/16)+c))):\n        PATH = DIR_input + NAMES_JPG_1.iloc[i]\n        IMAGE_DISEASE_OTSU.append((cv2.imread(os.path.join(PATH),cv2.IMREAD_GRAYSCALE).astype('float16')- 127.5) / 127.5)       \n\nDIR_input = '../input/diseases-eq-images-otsu-canny/Diseases/canny/'\nfor h in range(0+batch,1+batch):\n    c = int((len(NAMES_JPG_1)/16)*h) \n    for i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/16)+c))):\n        PATH = DIR_input + NAMES_JPG_1.iloc[i]\n        IMAGE_DISEASE_CANNY.append((cv2.imread(os.path.join(PATH),cv2.IMREAD_GRAYSCALE).astype('float16')- 127.5) / 127.5)   \n        \nimport gc\ngc.collect()\n\nfrom keras.initializers import RandomNormal\nfrom keras.metrics import MeanIoU\nimport heapq\n\nclass SpectralNormalization(tf.keras.layers.Wrapper):\n    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n        self.iteration = iteration\n        self.eps = eps\n        self.do_power_iteration = training\n        if not isinstance(layer, tf.keras.layers.Layer):\n            raise ValueError(\n                'Please initialize `TimeDistributed` layer with a '\n                '`Layer` instance. You passed: {input}'.format(input=layer))\n        super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n    def build(self, input_shape):\n        self.layer.build(input_shape)\n\n        self.w = self.layer.kernel\n        self.w_shape = self.w.shape.as_list()\n\n        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_v',\n                                 dtype=tf.float32)\n\n        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_u',\n                                 dtype=tf.float32)\n\n        super(SpectralNormalization, self).build()\n\n    def call(self, inputs):\n        self.update_weights()\n        output = self.layer(inputs)\n        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n        return output\n    \n    def update_weights(self):\n        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n        \n        u_hat = self.u\n        v_hat = self.v  # init v vector\n\n        if self.do_power_iteration:\n            for _ in range(self.iteration):\n                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                u_ = tf.matmul(v_hat, w_reshaped)\n                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n        self.u.assign(u_hat)\n        self.v.assign(v_hat)\n\n        self.layer.kernel.assign(self.w / sigma)\n\n    def restore_weights(self):\n        self.layer.kernel.assign(self.w)\n\ndef processing(prediction_,list_prediction):   \n    for predicted_rx in tqdm(prediction_):\n        img = np.squeeze(predicted_rx.astype(np.float16))\n        plt.imsave('predicted_000.jpg', img, cmap='gray')\n        img = cv2.imread('./predicted_000.jpg',1)\n        img = img[:,:,0]\n        min_ = img.min()\n        max_ = img.max()\n        ret1, img = cv2.threshold(img, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        kernel = np.ones((5,5),np.uint8)\n        img = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n        img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n        contours,hierarchy = cv2.findContours(img, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n        len_contours = list()\n        for i in range(0,len(contours)):\n            len_contours.append(len(contours[i]))\n\n        #two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n        try:\n            data = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\n            two_largest, vals = zip(*data)\n        except:\n            pass\n        \n        try:\n            cnt0 = contours[two_largest[0]].reshape(-1,2)\n            epsilon0 = 0.001*cv2.arcLength(cnt0,True)\n            approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n        except:\n            pass\n        try: \n            cnt1 = contours[two_largest[1]].reshape(-1,2)\n            epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n            approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n        except:\n            pass\n\n        canvas = np.zeros(img.shape, np.uint8)\n            \n        del img\n        gc.collect()\n        \n        try:\n            cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n        except:\n            pass\n        try:\n            cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n        except:\n            pass\n        canvas = canvas[:,:]\n        list_prediction.append(canvas)\n\n    list_prediction = np.expand_dims(list_prediction, axis=-1)\n    gc.collect()\n    return list_prediction\n\ndef make_generator_model():\n    \n    input_shape=(SIZE,SIZE,CHANNELS)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    img_input1 = Input(shape=input_shape)\n    img_input2 = Input(shape=input_shape)\n    img_input3 = Input(shape=input_shape)\n\n    concat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n    \n    conv1 = SpectralNormalization(Conv2D(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = layers.LeakyReLU(0.2)(batch1)\n\n    conv2 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = layers.LeakyReLU(0.2)(batch2)\n\n    conv3 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = layers.LeakyReLU(0.2)(batch3)\n\n    conv4 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = layers.LeakyReLU(0.2)(batch4)\n\n    conv5 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = layers.LeakyReLU(0.2)(batch5)\n\n    conv6 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act5)\n    batch6 = BatchNormalization()(conv6)\n    act6 = layers.LeakyReLU(0.2)(batch6)\n    concat6 = concatenate([act2,act6])\n\n    conv7 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat6)\n    batch7 = BatchNormalization()(conv7)\n    act7 = layers.LeakyReLU(0.2)(batch7)\n    concat7 = concatenate([act1,act7])\n\n    conv8 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = layers.LeakyReLU(0.2)(batch8)\n\n    conv9 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = layers.LeakyReLU(0.2)(batch9)\n\n    conv10 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = layers.LeakyReLU(0.2)(batch10)\n\n    conv11 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = layers.LeakyReLU(0.2)(batch11)\n\n    conv12 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act11)\n    batch12 = BatchNormalization()(conv12)\n    act12 = layers.LeakyReLU(0.2)(batch12)\n    concat12 = concatenate([act9,act12])\n\n    conv13 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat12)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  layers.LeakyReLU(0.2)(batch13)\n    concat13 = concatenate([act8,act13])\n\n    conv14 = SpectralNormalization(Conv2DTranspose(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat13)\n    batch14 = BatchNormalization()(conv14)\n    act14 = layers.LeakyReLU(0.2)(batch14)\n    concat14 = concatenate([concat_input,act14])\n\n    output_xnet = SpectralNormalization(Conv2D(1, (1, 1), activation='tanh'))(concat14)\n\n    model = Model(inputs = [img_input1,img_input2,img_input3], outputs = output_xnet)\n       \n    return model\n\ngenerator = make_generator_model()\n\n\n\nmodel1 = generator\nmodel1.load_weights('../input/gan-segmenter-100-bs8-27-bs1/generator_model_segmentation_100_27_epochs.h5')\nmodel2 = load_model('../input/autoencoders-segmentation-300-epochs/xnet_segmenter_300_epochs.h5', compile=False)\nmodel3 = load_model('../input/autoencoders-segmentation-300-epochs/resnet34_segmenter_300_epochs.h5', compile=False)\n\nmodels = [model1, model2, model3]\n\nX_data1 = [np.asarray(IMAGE_DISEASE_1275),np.asarray(IMAGE_DISEASE_OTSU),np.asarray(IMAGE_DISEASE_CANNY)]\n\ndel IMAGE_DISEASE_1275\ndel IMAGE_DISEASE_OTSU\ndel IMAGE_DISEASE_CANNY\ngc.collect()\n\nX_data2 = np.asarray(IMAGE_DISEASE_2550)\nBACKBONE1 = 'resnet34'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\nX_data3 = preprocess_input1(np.asarray(IMAGE_DISEASE_2550))\n\n\npred1 = model1.predict(X_data1)\ndel X_data1\ngc.collect()\n\npred2 = model2.predict(X_data2)\ndel X_data2\ngc.collect()\n\npred3 = model3.predict(X_data3)\ndel X_data3\ngc.collect()\n\nprediction1 = list()\nprediction2 = list()\nprediction3 = list()\n\npredi1 = processing(pred1,prediction1)\ndel pred1\ngc.collect()\n\npredi2 = processing(pred2,prediction2)\ndel pred2\ngc.collect()\n\npredi3 = processing(pred3,prediction3)\ndel pred3\ngc.collect()\n\npreds=np.asarray([predi1, predi2, predi3])\npreds.astype(np.float16)\n\n\ndel predi1\ndel predi2\ndel predi3\ngc.collect()\n\nwted_preds = np.tensordot(preds, [0.2, 0.3, 0.3], axes=((0),(0)))\nwted_ensemble_pred = np.squeeze(wted_preds.astype(np.float16))\ndel wted_preds\ndel preds\ngc.collect()\n\nwted = list()\nfor l,ima in enumerate(tqdm(wted_ensemble_pred)):\n\n    out = np.zeros_like(ima)\n    for i in range(0,SIZE):\n        lim = 0.75*ima.max()\n        for j in range(0,SIZE):\n            if ima[i,j] >= lim:\n                out[i,j] = 255\n    wted.append(out)\n    \nwted_images = np.array(wted)\nwted_images = np.expand_dims(wted_images, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./Diseases/masks')\nfor i in tqdm(range(0+c,(int(len(NAMES_JPG_1)/16)+c))):\n    predicted_rx = np.squeeze(wted_images[i-c].astype(np.float32))\n    cv2.imwrite('./Diseases/masks/'+ str(NAMES_JPG_1.iloc[i]),predicted_rx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n \nfantasy_zip = zipfile.ZipFile('./DISEASES_MASKS_15.zip', 'w')\n \nfor folder, subfolders, files in os.walk('./Diseases'):\n \n    for file in files:\n        if file.endswith('.jpg'):\n            fantasy_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), './PNEUMOTHORAX'), compress_type = zipfile.ZIP_DEFLATED)\n \nfantasy_zip.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/vbookshelf/play-audio-read-the-files-create-a-spectrogram\n\nfrom pydub import AudioSegment\nimport IPython\n\npath = '../input/alarm-sound/Alarm_Slow_A1_fesliyanstudios.mp3'\n\nIPython.display.Audio(path, autoplay=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5.  Defining the metrics for the models","metadata":{}},{"cell_type":"code","source":"def iou_score(y_pred, y_true, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n    iou = (intersection + smooth)/(union + smooth)\n    return iou\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef dice_coef2(y_true, y_pred):\n    y_true_f = y_true.flatten()\n    y_pred_f = y_pred.flatten()\n    union = np.sum(y_true_f) + np.sum(y_pred_f)\n    if union==0: return 1\n    intersection = np.sum(y_true_f * y_pred_f)\n    return 2. * intersection / union\n\ndef mean_dice_coef(y_true, y_pred_bin):\n    batch_size = y_true.shape[0]\n    channel_num = y_true.shape[-1]\n    mean_dice_channel = 0.\n    for i in range(batch_size):\n        for j in range(channel_num):\n            channel_dice = dice_coef2(y_true[i, :, :, j], y_pred_bin[i, :, :, j])\n            mean_dice_channel += channel_dice/(channel_num*batch_size)\n    return mean_dice_channel","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Bone supression from Chest X-Ray using Autoencoder and TPU","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" with tpu_strategy.scope():\n    input_shape=(SIZE,SIZE,1)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64*2,128*2,256*2,512*2,0*2)\n\n    img_input = Input(shape=input_shape)\n\n    conv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(img_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = Activation(\"relu\")(batch1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n\n    conv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(pool1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = Activation(\"relu\")(batch2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n\n    conv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = Activation(\"relu\")(batch3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n\n    conv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = Activation(\"relu\")(batch4)\n\n    conv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = Activation(\"relu\")(batch5)\n\n    up6 = UpSampling2D(size=(2, 2))(act5)\n    conv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up6)\n    batch6 = BatchNormalization()(conv6)\n    act6 = Activation(\"relu\")(batch6)\n    concat6 = concatenate([act3,act6])\n\n    up7 = UpSampling2D(size=(2, 2))(concat6)\n    conv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up7)\n    batch7 = BatchNormalization()(conv7)\n    act7 = Activation(\"relu\")(batch7)\n    concat7 = concatenate([act2,act7])\n\n    conv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = Activation(\"relu\")(batch8)\n    pool8 = MaxPooling2D(pool_size=(2, 2))(act8)\n\n    conv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = Activation(\"relu\")(batch9)\n    pool9 = MaxPooling2D(pool_size=(2, 2))(act9)\n\n    conv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = Activation(\"relu\")(batch10)\n\n    conv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = Activation(\"relu\")(batch11)\n\n    up12 = UpSampling2D(size=(2, 2))(act11)\n    conv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up12)\n    batch12 = BatchNormalization()(conv12)\n    act12 = Activation(\"relu\")(batch12)\n    concat12 = concatenate([act9,act12])\n\n    up13 = UpSampling2D(size=(2, 2))(concat12)\n    conv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up13)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  Activation(\"relu\")(batch13)\n    concat13 = concatenate([act8,act13])\n\n    up14 = UpSampling2D(size=(2, 2))(concat13)\n    conv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(up14)\n    batch14 = BatchNormalization()(conv14)\n    act14 = Activation(\"relu\")(batch14)\n    concat14 = concatenate([act1,act14])\n\n    output_xnet = Conv2D(1, (1, 1), activation='sigmoid')(concat14)\n\n    model = Model(img_input, output_xnet)\n    model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=[dice_coef_loss], steps_per_execution=32)\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/bochrabenjaballah/petals-to-the-metal-flower-classification-on-tpu\n# Learning Rate Schedule for Fine Tuning #\ndef exponential_lr(epoch,\n                   start_lr = 0.00001, min_lr = 0.000001, max_lr = 0.0001,\n                   rampup_epochs = 5, sustain_epochs = 0,\n                   exp_decay = 0.982):\n\n    def lr(epoch, start_lr, min_lr, max_lr, rampup_epochs, sustain_epochs, exp_decay):\n        # linear increase from start to rampup_epochs\n        if epoch < rampup_epochs:\n            lr = ((max_lr - start_lr) /\n                  rampup_epochs * epoch + start_lr)\n        # constant max_lr during sustain_epochs\n        elif epoch < rampup_epochs + sustain_epochs:\n            lr = max_lr\n        # exponential decay towards min_lr\n        else:\n            lr = ((max_lr - min_lr) *\n                  exp_decay**(epoch - rampup_epochs - sustain_epochs) +\n                  min_lr)\n        return lr\n    return lr(epoch,\n              start_lr,\n              min_lr,\n              max_lr,\n              rampup_epochs,\n              sustain_epochs,\n              exp_decay)\n\nlr_callback = tf.keras.callbacks.LearningRateScheduler(exponential_lr, verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 300\nrng = [i for i in range(EPOCHS)]\ny = [exponential_lr(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [lr_callback, ModelCheckpoint('Supression_lung_Xnet.h5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True, mode='min')]\nhistory = model.fit(X_train, y_train, batch_size = 16 * tpu_strategy.num_replicas_in_sync, epochs = 300, verbose = 1, validation_data = (X_test,y_test), callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('Autoencoder_300_Xnet_supression_LearningRateScheduler.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #with tpu_strategy.scope(): \ndependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model_autoencoder = load_model('../input/autoencoder-supression-300-epochs/Autoencoder_300_Xnet_supression_LearningRateScheduler (1).h5', custom_objects=dependencies)\nloaded_model_autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\n    #loaded_model_autoencoder.evaluate(X_test, y_test, batch_size = 16 * tpu_strategy.num_replicas_in_sync)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Gan for semantic segmentationfrom Chest X-Ray","metadata":{}},{"cell_type":"markdown","source":"**Generator architecture** adapted from [link](https://github.com/JosephPB/XNet).","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf  # TF 2.0\n\n\nclass SpectralNormalization(tf.keras.layers.Wrapper):\n    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n        self.iteration = iteration\n        self.eps = eps\n        self.do_power_iteration = training\n        if not isinstance(layer, tf.keras.layers.Layer):\n            raise ValueError(\n                'Please initialize `TimeDistributed` layer with a '\n                '`Layer` instance. You passed: {input}'.format(input=layer))\n        super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n    def build(self, input_shape):\n        self.layer.build(input_shape)\n\n        self.w = self.layer.kernel\n        self.w_shape = self.w.shape.as_list()\n\n        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_v',\n                                 dtype=tf.float32)\n\n        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_u',\n                                 dtype=tf.float32)\n\n        super(SpectralNormalization, self).build()\n\n    def call(self, inputs):\n        self.update_weights()\n        output = self.layer(inputs)\n        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n        return output\n    \n    def update_weights(self):\n        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n        \n        u_hat = self.u\n        v_hat = self.v  # init v vector\n\n        if self.do_power_iteration:\n            for _ in range(self.iteration):\n                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                u_ = tf.matmul(v_hat, w_reshaped)\n                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n        self.u.assign(u_hat)\n        self.v.assign(v_hat)\n\n        self.layer.kernel.assign(self.w / sigma)\n\n    def restore_weights(self):\n        self.layer.kernel.assign(self.w)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.initializers import RandomNormal\ndef make_generator_model():\n    \n    input_shape=(SIZE,SIZE,CHANNELS)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    img_input1 = Input(shape=input_shape)\n    img_input2 = Input(shape=input_shape)\n    img_input3 = Input(shape=input_shape)\n\n    concat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n    \n    conv1 = SpectralNormalization(Conv2D(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = layers.LeakyReLU(0.2)(batch1)\n\n    conv2 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = layers.LeakyReLU(0.2)(batch2)\n\n    conv3 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = layers.LeakyReLU(0.2)(batch3)\n\n    conv4 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = layers.LeakyReLU(0.2)(batch4)\n\n    conv5 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = layers.LeakyReLU(0.2)(batch5)\n\n    conv6 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act5)\n    batch6 = BatchNormalization()(conv6)\n    act6 = layers.LeakyReLU(0.2)(batch6)\n    concat6 = concatenate([act2,act6])\n\n    conv7 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat6)\n    batch7 = BatchNormalization()(conv7)\n    act7 = layers.LeakyReLU(0.2)(batch7)\n    concat7 = concatenate([act1,act7])\n\n    conv8 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = layers.LeakyReLU(0.2)(batch8)\n\n    conv9 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = layers.LeakyReLU(0.2)(batch9)\n\n    conv10 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = layers.LeakyReLU(0.2)(batch10)\n\n    conv11 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = layers.LeakyReLU(0.2)(batch11)\n\n    conv12 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act11)\n    batch12 = BatchNormalization()(conv12)\n    act12 = layers.LeakyReLU(0.2)(batch12)\n    concat12 = concatenate([act9,act12])\n\n    conv13 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat12)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  layers.LeakyReLU(0.2)(batch13)\n    concat13 = concatenate([act8,act13])\n\n    conv14 = SpectralNormalization(Conv2DTranspose(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat13)\n    batch14 = BatchNormalization()(conv14)\n    act14 = layers.LeakyReLU(0.2)(batch14)\n    concat14 = concatenate([concat_input,act14])\n\n    output_xnet = SpectralNormalization(Conv2D(1, (1, 1), activation='tanh'))(concat14)\n\n    model = Model(inputs = [img_input1,img_input2,img_input3], outputs = output_xnet)\n       \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model()\ngenerator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_discrimator_model():\n    \n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n    inp = Input(shape=[SIZE, SIZE, 1], name='input_image')\n    inp_otsu = Input(shape=[SIZE, SIZE, 1], name='input_image_otsu')\n    inp_canny = Input(shape=[SIZE, SIZE, 1], name='input_image_canny')\n    tar = Input(shape=[SIZE, SIZE, 1], name='target_image')\n    \n    merged = tf.keras.layers.concatenate([inp,inp_otsu,inp_canny,tar])\n                                    \n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    flat = layers.Flatten()(d)\n    patch_out = layers.Dense(1, activation='sigmoid')(flat) \n    model = Model(inputs=[inp,inp_otsu,inp_canny, tar], outputs=patch_out)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discrimator_model()\ndiscriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./input/training_checkpoints')\nshutil.rmtree('./input/images_gan')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/training_checkpoints')\n\nMAE = tf.keras.losses.MeanAbsoluteError()\nbinary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(disc_real_output, disc_generated_output):\n    real_loss = binary_cross_entropy(tf.multiply(tf.ones_like(disc_real_output),0.9), disc_real_output)\n    fake_loss = binary_cross_entropy(tf.multiply(tf.zeros_like(disc_generated_output),0.1), disc_generated_output)\n    total_disc_loss = real_loss + fake_loss\n    return total_disc_loss\n\ndef generator_loss(disc_generated_output,fake_output_,real_output_):\n    gan_loss = binary_cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n    l1_loss = MAE(real_output_,fake_output_)\n    total_gen_loss = gan_loss + (100 * l1_loss) \n    return total_gen_loss, gan_loss\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n\ncheckpoint_dir = './input/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 1\nnum_examples_to_generate = 16\nidx = np.random.randint(0, len(SEGMENTATION_IMAGES_GAN_3),num_examples_to_generate)\nseed1 = SEGMENTATION_IMAGES_GAN_3[idx]\nseed2 = SEGMENTATION_IMAGES_OTSU_GAN_3[idx]\nseed3 = SEGMENTATION_IMAGES_CANNY_GAN_3[idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\nlog_dir=\"../logs/\"\n\nsummary_writer = tf.summary.create_file_writer(\n  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_steps(input_image,input_image_otsu,input_image_canny,target, epoch):\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator([input_image,input_image_otsu,input_image_canny], training=True)\n        real_output = discriminator([input_image,input_image_otsu,input_image_canny, target], training=True)\n        fake_output = discriminator([input_image,input_image_otsu,input_image_canny, generated_images], training=True)\n        gen_total_loss, gen_gan_loss = generator_loss(fake_output, generated_images, target)\n        disc_loss = discriminator_loss(real_output, fake_output)\n    gradients_of_generator = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    with summary_writer.as_default():\n        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n    return gen_total_loss,disc_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/images_gan')\ndef generate_and_save_images(model, epoch, test_input,test_input2,test_input3):\n    predictions = model([test_input,test_input2,test_input3],training = False)\n\n    fig = plt.figure(figsize=(8,8))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i + 1)\n        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n        plt.axis('off')\n    plt.savefig('./input/images_gan/image_at_epoch_{:04d}.png'.format(epoch))   \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(epoch, g_losses, d_losses):\n    plt.figure(figsize=(10,5))\n    plt.title(\"Loss, Epochs 0-\" + str(epoch))\n    plt.plot(g_losses,label=\"Generator\")\n    plt.plot(d_losses,label=\"Discriminator\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy\n\ndef train(X_dataset,X_train_dataset_otsu,X_train_dataset_canny,y_dataset, epochs):\n    g_loss = []\n    d_loss = []\n    for epoch in range(epochs):\n        start = time.time()\n        \n        for image_batch,image_batch_otsu,image_batch_canny,target_batch in zip(X_dataset,X_train_dataset_otsu,X_train_dataset_canny,y_dataset):\n            generator_loss, discriminator_loss = train_steps(image_batch,image_batch_otsu,image_batch_canny,target_batch, epochs)\n\n        g_loss.append(generator_loss.numpy())\n    \n        d_loss.append(discriminator_loss.numpy())\n        \n        display.clear_output(wait = True)\n        print(\"Generator loss: \" + str(g_loss))\n        print(\"Discriminator loss: \" + str(d_loss))\n        plot_loss(epoch, g_loss, d_loss)\n        generate_and_save_images(generator, epoch + 1, seed1,seed2,seed3)\n\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix=checkpoint_prefix)\n        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_image(epoch_no):\n    return PIL.Image.open('./input/images_gan/image_at_epoch_{:04d}.png'.format(epoch_no))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(train_dataset_X,train_dataset_otsu_X,train_dataset_canny_X,train_dataset_y, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dice = list()\neee = list()\nfor e in range(1,26):\n    ee = 100 + e\n    eee.append(ee)\n    train(train_dataset_X,train_dataset_otsu_X,train_dataset_canny_X,train_dataset_y, epochs)\n    predictions = generator.predict([SEGMENTATION_IMAGES_GAN_3,SEGMENTATION_IMAGES_OTSU_GAN_3,SEGMENTATION_IMAGES_CANNY_GAN_3])\n    dice.append(mean_dice_coef((SEGMENTATION_TARGETS_GAN_3*127.5 + 127.5)/255, (predictions*127.5 + 127.5)/255))\n    print('Mean dice coef epoch ' + str(ee) + ': ' + str(dice))\n    generator.save('generator_model_segmentation_'+ str(ee) +'_epochs.h5')\n    discriminator.save('discriminartor_segmentation_'+ str(ee) +'_epochs.h5')\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\ndisplay_image(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GIF :)**","metadata":{}},{"cell_type":"code","source":"import glob\nimport imageio\n\nanim_file = 'gan_segmentation.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n    filenames = glob.glob('./input/images_gan/image*.png')\n    filenames = sorted(filenames)\n    for filename in filenames:\n        image = imageio.imread(filename)\n        writer.append_data(image)\n    image = imageio.imread(filename)\n    writer.append_data(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install git+https://github.com/tensorflow/docs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_docs.vis.embed as embed\n\nembed.embed_file(anim_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Save and load the model**","metadata":{}},{"cell_type":"code","source":"generator.save('generator_model_segmentation_100_27_epochs.h5')\ndiscriminator.save('discriminartor_segmentation_100_27_epochs.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/vbookshelf/play-audio-read-the-files-create-a-spectrogram\n\nfrom pydub import AudioSegment\nimport IPython\n\npath = '../input/alarm-sound/Alarm_Slow_A1_fesliyanstudios.mp3'\n\nIPython.display.Audio(path, autoplay=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.load_weights('../input/gan-segmenter-100-bs8-25-bs1/generator_model_segmentation_100_25_epochs.h5')\ndiscriminator.load_weights('../input/gan-segmenter-100-bs8-25-bs1/discriminartor_segmentation_100_25_epochs.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Show and save images**","metadata":{}},{"cell_type":"markdown","source":"Train","metadata":{}},{"cell_type":"code","source":"number = 300\nimage_rx = np.squeeze(...[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\npredicted_rx = generator.predict([...[[number]].astype(np.float64),...[[number]].astype(np.float64),...[[number]].astype(np.float64)],verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\nimg = cv2.imread('./predicted_000.jpg',1)\n\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nkernel = np.ones((5,5),np.uint8)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\ncontours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\ncnt0 = contours[0].reshape(-1,2)\nepsilon0 = 0.000001*cv2.arcLength(cnt0,True)\napprox0 = cv2.approxPolyDP(cnt0,epsilon0,True)\ntry: \n    cnt1 = contours[1].reshape(-1,2)\n    epsilon1 = 0.0000001*cv2.arcLength(cnt1,True)\n    approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\nexcept:\n    pass\ncanvas = np.zeros(thresh.shape, np.uint8)\n\ncv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\ntry:\n    cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\nexcept:\n    pass\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\ncv2.imwrite('predicted_000.png',thresh)\npredicted_000 = cv2.imread('./predicted_000.png',1)\n\nout = np.zeros_like(thresh)\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        if thresh[i,j] == 255:\n            out[i,j] = image_rx[i,j]*127.5 + 127.5\n        \ncv2.imwrite('out_000.png',out)\nout_000 = cv2.imread('./out_000.png',1)\n\nstack = np.hstack((image_000, predicted_000,out_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test","metadata":{}},{"cell_type":"code","source":"import heapq\n\nnumber = 30\nimage_rx = np.squeeze(SEGMENTATION_IMAGES_GAN_3[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\npredicted_rx = generator.predict([SEGMENTATION_IMAGES_GAN_3[[number]].astype(np.float64),SEGMENTATION_IMAGES_OTSU_GAN_3[[number]].astype(np.float64),SEGMENTATION_IMAGES_CANNY_GAN_3[[number]].astype(np.float64)],verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\nimg = cv2.imread('./predicted_000.jpg',1)\n\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nkernel = np.ones((5,5),np.uint8)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\ncontours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\nlen_contours = list()\nfor i in range(0,len(contours)):\n    len_contours.append(len(contours[i]))\n\n#two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n\ndata = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\ntwo_largest, vals = zip(*data)\n\ncnt0 = contours[two_largest[0]].reshape(-1,2)\nepsilon0 = 0.001*cv2.arcLength(cnt0,True)\napprox0 = cv2.approxPolyDP(cnt0,epsilon0,True)\ntry: \n    cnt1 = contours[two_largest[1]].reshape(-1,2)\n    epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n    approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\nexcept:\n    pass\n\ncanvas = np.zeros(thresh.shape, np.uint8)\ncv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n\ntry:\n    cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\nexcept:\n    pass\n#ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\ncv2.imwrite('predicted_000.png',canvas)\npredicted_000 = cv2.imread('./predicted_000.png',1)\n\nout = np.zeros_like(thresh)\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        if canvas[i,j] == 255:\n            out[i,j] = image_rx[i,j]*127.5 + 127.5\n        \ncv2.imwrite('out_000.png',out)\nout_000 = cv2.imread('./out_000.png',1)\n\nstack = np.hstack((image_000, predicted_000,out_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Analyzing the mean dice coefficient for test dataset**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's transform our supressed pneumothorax dataset into segmented pneumothorax dataset**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Autoencoders for semantic segmentation from Chest X-Ray","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    input_shape=(SIZE,SIZE,1)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n\n    img_input = Input(shape=input_shape)\n\n    conv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(img_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = Activation(\"relu\")(batch1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n\n    conv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(pool1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = Activation(\"relu\")(batch2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n\n    conv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = Activation(\"relu\")(batch3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n\n    conv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = Activation(\"relu\")(batch4)\n\n    conv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = Activation(\"relu\")(batch5)\n\n    up6 = UpSampling2D(size=(2, 2))(act5)\n    conv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up6)\n    batch6 = BatchNormalization()(conv6)\n    act6 = Activation(\"relu\")(batch6)\n    concat6 = concatenate([act3,act6])\n\n    up7 = UpSampling2D(size=(2, 2))(concat6)\n    conv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up7)\n    batch7 = BatchNormalization()(conv7)\n    act7 = Activation(\"relu\")(batch7)\n    concat7 = concatenate([act2,act7])\n\n    conv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = Activation(\"relu\")(batch8)\n    pool8 = MaxPooling2D(pool_size=(2, 2))(act8)\n\n    conv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = Activation(\"relu\")(batch9)\n    pool9 = MaxPooling2D(pool_size=(2, 2))(act9)\n\n    conv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = Activation(\"relu\")(batch10)\n\n    conv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = Activation(\"relu\")(batch11)\n\n    up12 = UpSampling2D(size=(2, 2))(act11)\n    conv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up12)\n    batch12 = BatchNormalization()(conv12)\n    act12 = Activation(\"relu\")(batch12)\n    concat12 = concatenate([act9,act12])\n\n    up13 = UpSampling2D(size=(2, 2))(concat12)\n    conv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up13)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  Activation(\"relu\")(batch13)\n    concat13 = concatenate([act8,act13])\n\n    up14 = UpSampling2D(size=(2, 2))(concat13)\n    conv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(up14)\n    batch14 = BatchNormalization()(conv14)\n    act14 = Activation(\"relu\")(batch14)\n    concat14 = concatenate([act1,act14])\n\n    output_xnet = Conv2D(1, (1, 1), activation='sigmoid')(concat14)\n\n    model = Model(img_input, output_xnet)\n    model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=[dice_coef_loss])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 3\nfig, ax = plt.subplots(1,2, figsize = (16,8))\nax[0].imshow(SEGMENTATION_IMAGES[number], cmap='gray')\nax[1].imshow(SEGMENTATION_TARGETS[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ModelCheckpoint('Segmenter_lung_mc_epochs.h5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True, mode='min')]\nresults = model.fit(SEGMENTATION_IMAGES, SEGMENTATION_TARGETS, validation_split=0.1,batch_size=16 * tpu_strategy.num_replicas_in_sync, epochs=300, callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import heapq\nnumber = 3\nimage_rx = np.squeeze(SEGMENTATION_IMAGES[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\ntarget_rx = np.squeeze(SEGMENTATION_TARGETS[number].astype(np.float64))\nplt.imsave('target_000.jpg', target_rx, cmap='gray')\ntarget_000 = cv2.imread('./target_000.jpg',1)\n\npredicted_rx = model.predict([SEGMENTATION_IMAGES[[number]].astype(np.float64)],verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\nimg = cv2.imread('./predicted_000.jpg',1)\n\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nkernel = np.ones((5,5),np.uint8)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\ncontours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\nlen_contours = list()\nfor i in range(0,len(contours)):\n    len_contours.append(len(contours[i]))\n\n#two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n\ndata = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\ntwo_largest, vals = zip(*data)\n\ncnt0 = contours[two_largest[0]].reshape(-1,2)\nepsilon0 = 0.001*cv2.arcLength(cnt0,True)\napprox0 = cv2.approxPolyDP(cnt0,epsilon0,True)\ntry: \n    cnt1 = contours[two_largest[1]].reshape(-1,2)\n    epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n    approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\nexcept:\n    pass\n\ncanvas = np.zeros(thresh.shape, np.uint8)\ncv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n\ntry:\n    cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\nexcept:\n    pass\n#ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\ncv2.imwrite('predicted_000.png',canvas)\npredicted_000 = cv2.imread('./predicted_000.png',1)\n\nout = np.zeros_like(thresh)\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        if canvas[i,j] == 255:\n            out[i,j] = image_rx[i,j]*127.5 + 127.5\n        \ncv2.imwrite('out_000.png',out)\nout_000 = cv2.imread('./out_000.png',1)\n\nstack = np.hstack((image_000, target_000, predicted_000,out_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('xnet_segmenter_300_epochs.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(results.history['dice_coef_loss'], label='train')\nplt.plot(results.history['val_dice_coef_loss'], label='test')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('../input/segmenter-mais-eficente-300/Segmenter_lung (2).h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\nresults = loaded_model.evaluate(x_val,SEGMENTATION_TARGETS_3,batch_size=16, verbose=1)\nprint(\"Loss and dice_coef_loss:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Second autoencoder","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    n_classes = 1\n    activation = 'sigmoid'\n    LR = 0.0001\n    optim = keras.optimizers.Adam(LR)\n    BATCH_SIZE = 16\n    BACKBONE1 = 'resnet34'\n    preprocess_input1 = sm.get_preprocessing(BACKBONE1)\n\n    x_train = preprocess_input1(SEGMENTATION_IMAGES)\n\n    base_model = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes = n_classes, activation = activation)\n\n    inp = Input(shape=(None, None, 1))\n    l1 = Conv2D(3, (1, 1))(inp)\n    out = base_model(l1)\n\n    model = Model(inp, out, name=base_model.name)\n\n    model.compile('Adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\n    print(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train, SEGMENTATION_TARGETS, batch_size = 16 * tpu_strategy.num_replicas_in_sync, epochs = 300, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('resnet34_segmenter_300_epochs.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import heapq\nnumber = 4\nimage_rx = np.squeeze(SEGMENTATION_IMAGES_3[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\ntarget_rx = np.squeeze(SEGMENTATION_TARGETS_3[number].astype(np.float64))\nplt.imsave('target_000.jpg', target_rx, cmap='gray')\ntarget_000 = cv2.imread('./target_000.jpg',1)\n\npredicted_rx = model3.predict([SEGMENTATION_IMAGES_3[[number]].astype(np.float64)],verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\n#predicted_rx = predicted_rx[0,:,:]\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\nimg = cv2.imread('./predicted_000.jpg',1)\n\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nkernel = np.ones((5,5),np.uint8)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\ncontours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\nlen_contours = list()\nfor i in range(0,len(contours)):\n    len_contours.append(len(contours[i]))\n\n#two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n\ndata = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\ntwo_largest, vals = zip(*data)\n\ncnt0 = contours[two_largest[0]].reshape(-1,2)\nepsilon0 = 0.001*cv2.arcLength(cnt0,True)\napprox0 = cv2.approxPolyDP(cnt0,epsilon0,True)\ntry: \n    cnt1 = contours[two_largest[1]].reshape(-1,2)\n    epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n    approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\nexcept:\n    pass\n\ncanvas = np.zeros(thresh.shape, np.uint8)\ncv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n\ntry:\n    cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\nexcept:\n    pass\n#ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\ncv2.imwrite('predicted_000.png',canvas)\npredicted_000 = cv2.imread('./predicted_000.png',1)\n\nout = np.zeros_like(thresh)\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        if canvas[i,j] == 255:\n            out[i,j] = image_rx[i,j]*127.5 + 127.5\n        \ncv2.imwrite('out_000.png',out)\nout_000 = cv2.imread('./out_000.png',1)\n\nstack = np.hstack((image_000, target_000, predicted_000,out_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('./Segmenter_lung.h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Structuring a combinated decision applied to semantic segmentation","metadata":{}},{"cell_type":"code","source":"from keras.initializers import RandomNormal\nfrom keras.metrics import MeanIoU\n\nclass SpectralNormalization(tf.keras.layers.Wrapper):\n    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n        self.iteration = iteration\n        self.eps = eps\n        self.do_power_iteration = training\n        if not isinstance(layer, tf.keras.layers.Layer):\n            raise ValueError(\n                'Please initialize `TimeDistributed` layer with a '\n                '`Layer` instance. You passed: {input}'.format(input=layer))\n        super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n    def build(self, input_shape):\n        self.layer.build(input_shape)\n\n        self.w = self.layer.kernel\n        self.w_shape = self.w.shape.as_list()\n\n        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_v',\n                                 dtype=tf.float32)\n\n        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_u',\n                                 dtype=tf.float32)\n\n        super(SpectralNormalization, self).build()\n\n    def call(self, inputs):\n        self.update_weights()\n        output = self.layer(inputs)\n        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n        return output\n    \n    def update_weights(self):\n        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n        \n        u_hat = self.u\n        v_hat = self.v  # init v vector\n\n        if self.do_power_iteration:\n            for _ in range(self.iteration):\n                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                u_ = tf.matmul(v_hat, w_reshaped)\n                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n        self.u.assign(u_hat)\n        self.v.assign(v_hat)\n\n        self.layer.kernel.assign(self.w / sigma)\n\n    def restore_weights(self):\n        self.layer.kernel.assign(self.w)\n\ndef make_generator_model():\n    \n    input_shape=(SIZE,SIZE,CHANNELS)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    img_input1 = Input(shape=input_shape)\n    img_input2 = Input(shape=input_shape)\n    img_input3 = Input(shape=input_shape)\n\n    concat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n    \n    conv1 = SpectralNormalization(Conv2D(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = layers.LeakyReLU(0.2)(batch1)\n\n    conv2 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = layers.LeakyReLU(0.2)(batch2)\n\n    conv3 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = layers.LeakyReLU(0.2)(batch3)\n\n    conv4 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = layers.LeakyReLU(0.2)(batch4)\n\n    conv5 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = layers.LeakyReLU(0.2)(batch5)\n\n    conv6 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act5)\n    batch6 = BatchNormalization()(conv6)\n    act6 = layers.LeakyReLU(0.2)(batch6)\n    concat6 = concatenate([act2,act6])\n\n    conv7 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat6)\n    batch7 = BatchNormalization()(conv7)\n    act7 = layers.LeakyReLU(0.2)(batch7)\n    concat7 = concatenate([act1,act7])\n\n    conv8 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = layers.LeakyReLU(0.2)(batch8)\n\n    conv9 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = layers.LeakyReLU(0.2)(batch9)\n\n    conv10 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = layers.LeakyReLU(0.2)(batch10)\n\n    conv11 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = layers.LeakyReLU(0.2)(batch11)\n\n    conv12 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act11)\n    batch12 = BatchNormalization()(conv12)\n    act12 = layers.LeakyReLU(0.2)(batch12)\n    concat12 = concatenate([act9,act12])\n\n    conv13 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat12)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  layers.LeakyReLU(0.2)(batch13)\n    concat13 = concatenate([act8,act13])\n\n    conv14 = SpectralNormalization(Conv2DTranspose(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat13)\n    batch14 = BatchNormalization()(conv14)\n    act14 = layers.LeakyReLU(0.2)(batch14)\n    concat14 = concatenate([concat_input,act14])\n\n    output_xnet = SpectralNormalization(Conv2D(1, (1, 1), activation='tanh'))(concat14)\n\n    model = Model(inputs = [img_input1,img_input2,img_input3], outputs = output_xnet)\n       \n    return model\n\ngenerator = make_generator_model()\ngenerator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = generator\nmodel1.load_weights('../input/gan-segmenter-100-bs8-27-bs1/generator_model_segmentation_100_27_epochs.h5')\nmodel2 = load_model('../input/autoencoders-segmentation-300-epochs/xnet_segmenter_300_epochs.h5', compile=False)\nmodel3 = load_model('../input/autoencoders-segmentation-300-epochs/resnet34_segmenter_300_epochs.h5', compile=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ensemble - methodology avaliable on [link](https://github.com/bnsreenu/python_for_microscopists/blob/master/214_multiclass_Unet_sandstone_segm_models_ensemble.py).","metadata":{}},{"cell_type":"code","source":"models = [model1, model2, model3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_data1 = [SEGMENTATION_IMAGES_GAN_3.astype(np.float32),SEGMENTATION_IMAGES_OTSU_GAN_3.astype(np.float32),SEGMENTATION_IMAGES_CANNY_GAN_3.astype(np.float32)]\n\nX_data2 = SEGMENTATION_IMAGES_3.astype(np.float32)\n\nBACKBONE1 = 'resnet34'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\nX_data3 = preprocess_input1(SEGMENTATION_IMAGES_3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred1 = model1.predict(X_data1)\npred2 = model2.predict(X_data2)\npred3 = model3.predict(X_data3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction1 = list()\nprediction2 = list()\nprediction3 = list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import heapq","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for predicted_rx in tqdm(pred1):\n    predicted_rxx = np.squeeze(predicted_rx.astype(np.float32))\n    plt.imsave('predicted_000.jpg', predicted_rxx, cmap='gray')\n    img = cv2.imread('./predicted_000.jpg',1)\n\n    img_grey = img[:,:,0]\n    min_ = img_grey.min()\n    max_ = img_grey.max()\n    ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    kernel = np.ones((5,5),np.uint8)\n    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n    contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n    len_contours = list()\n    for i in range(0,len(contours)):\n        len_contours.append(len(contours[i]))\n\n    #two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n\n    data = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\n    two_largest, vals = zip(*data)\n\n    cnt0 = contours[two_largest[0]].reshape(-1,2)\n    epsilon0 = 0.001*cv2.arcLength(cnt0,True)\n    approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n    try: \n        cnt1 = contours[two_largest[1]].reshape(-1,2)\n        epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n        approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n    except:\n        pass\n\n    canvas = np.zeros(thresh.shape, np.uint8)\n    cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n\n    try:\n        cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n    except:\n        pass\n    canvas = canvas[:,:]\n    prediction1.append(canvas)\n\npredi1 = np.expand_dims(prediction1, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for predicted_rx in tqdm(pred2):\n    predicted_rxx = np.squeeze(predicted_rx.astype(np.float32))\n    plt.imsave('predicted_000.jpg', predicted_rxx, cmap='gray')\n    img = cv2.imread('./predicted_000.jpg',1)\n\n    img_grey = img[:,:,0]\n    min_ = img_grey.min()\n    max_ = img_grey.max()\n    ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    kernel = np.ones((5,5),np.uint8)\n    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n    contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n    len_contours = list()\n    for i in range(0,len(contours)):\n        len_contours.append(len(contours[i]))\n\n    #two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n\n    data = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\n    two_largest, vals = zip(*data)\n\n    cnt0 = contours[two_largest[0]].reshape(-1,2)\n    epsilon0 = 0.001*cv2.arcLength(cnt0,True)\n    approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n    try: \n        cnt1 = contours[two_largest[1]].reshape(-1,2)\n        epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n        approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n    except:\n        pass\n\n    canvas = np.zeros(thresh.shape, np.uint8)\n    cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n\n    try:\n        cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n    except:\n        pass\n    canvas = canvas[:,:]\n    prediction2.append(canvas)\n\npredi2 = np.expand_dims(prediction2, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p = 0\nfor predicted_rx in tqdm(pred3):\n    predicted_rxx = np.squeeze(predicted_rx.astype(np.float32))\n    plt.imsave('predicted_000.jpg', predicted_rxx, cmap='gray')\n    img = cv2.imread('./predicted_000.jpg',1)\n\n    img_grey = img[:,:,0]\n    min_ = img_grey.min()\n    max_ = img_grey.max()\n    ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    kernel = np.ones((5,5),np.uint8)\n    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n    contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n    len_contours = list()\n    for i in range(0,len(contours)):\n        len_contours.append(len(contours[i]))\n\n    #two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n\n    data = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\n    two_largest, vals = zip(*data)\n\n    cnt0 = contours[two_largest[0]].reshape(-1,2)\n    epsilon0 = 0.001*cv2.arcLength(cnt0,True)\n    approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n    try: \n        cnt1 = contours[two_largest[1]].reshape(-1,2)\n        epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n        approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n    except:\n        pass\n\n    canvas = np.zeros(thresh.shape, np.uint8)\n    cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n\n    try:\n        cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n    except:\n        pass\n    canvas = canvas[:,:]\n    prediction3.append(canvas)\n    \npredi3 = np.expand_dims(prediction3, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=np.array([predi1, predi2, predi3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.astype(np.float32)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nwted_preds = np.tensordot(preds, [0.0, 0.0, 0.1], axes=((0),(0)))\nwted_ensemble_pred = np.squeeze(wted_preds.astype(np.float32))\nwted = list()\nima = wted_ensemble_pred[2]\n\nout = np.zeros_like(ima)\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        if ima[i,j] >= 0.75*ima.max():\n            out[i,j] = 255.0\nwted.append(out)\n\"\"\"\n\nnumber = 0\n#wted_ensemble_pred = np.argwhere(wted_preds==wted_preds.max())\n#wted_ensemble_pred = np.argmax(wted_preds, axis=3)\nfig, ax = plt.subplots(1,2, figsize = (8,4))\nax[0].imshow(np.array(SEGMENTATION_TARGETS_3[:,:,:,0][number]*255).astype(np.float32), cmap='gray')\nax[1].imshow(np.array(wted[number]), cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice(im1, im2):\n    im1 = np.asarray(im1).astype(np.bool)\n    im2 = np.asarray(im2).astype(np.bool)\n\n    if im1.shape != im2.shape:\n        raise ValueError(\"Shape mismatch: im1 and im2 must have the same shape.\")\n\n    # Compute Dice coefficient\n    intersection = np.logical_and(im1, im2)\n\n    return 2. * intersection.sum() / (im1.sum() + im2.sum())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.DataFrame([])\ni = 0\nfor w3 in range(0, 4):\n    for w2 in range(0,4):\n        for w1 in range(0,4):\n            wts = [w1/10.,w2/10.,w3/10.]\n            if (w1 != 3) or (w2 != 3) or (w3 != 3):\n                pass\n            else:\n                wted_preds = np.tensordot(preds, wts, axes=((0),(0)))\n                wted_ensemble_pred = np.squeeze(wted_preds.astype(np.float32))\n\n                wted = list()\n                for ima in tqdm(wted_ensemble_pred):\n\n                    out = np.zeros_like(ima)\n                    for i in range(0,SIZE):\n                        for j in range(0,SIZE):\n                            if ima[i,j] >= 0.75*ima.max():\n                                out[i,j] = 255.0\n                    wted.append(out)\n\n                Xtrue = np.array(SEGMENTATION_TARGETS_3[:,:,:,0]*255.0)\n                Xtrue = np.expand_dims(Xtrue, axis=-1)\n                Xpred = np.array(wted)\n                Xpred = np.expand_dims(Xpred, axis=-1)\n                Xtrue /= 255.\n                Xpred /= 255.\n                print(\"Now predciting for weights :\", w1/10., w2/10., w3/10., \" : DICE = \", mean_dice_coef(Xtrue,Xpred))\n                df = df.append(pd.DataFrame({'wt1':wts[0],'wt2':wts[1], \n                                             'wt3':wts[2], 'DICE': mean_dice_coef(Xtrue,Xpred)}, index=[0]), ignore_index=True)\n            i+=1\n            \nmax_dice_row = df.iloc[df['DICE'].idxmax()]\nprint(\"Max DICE of \", max_dice_row[3], \" obained with w1=\", max_dice_row[0],\n      \" w2=\", max_dice_row[1], \" and w3=\", max_dice_row[2]) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading images","metadata":{}},{"cell_type":"code","source":"auto_train_dir = os.path.join(\"../input/p-i-3000-500/images_segment_pneumothorax_train_auto/\")\nauto_test_dir = os.path.join(\"../input/p-i-3000-500/images_segment_pneumothorax_test_auto/\")\nauto_train_list = os.listdir(auto_train_dir)\nauto_test_list = os.listdir(auto_test_dir)\n\nGAN_train_dir = os.path.join(\"../input/p-i-3000-500/images_segment_pneumothorax_train_GAN/\")\nGAN_train_otsu_dir = os.path.join(\"../input/p-i-3000-500/images_otsu_segment_pneumothorax_train_GAN/\")                             \nGAN_train_canny_dir = os.path.join(\"../input/p-i-3000-500/images_canny_segment_pneumothorax_train_GAN/\")\nGAN_test_dir = os.path.join(\"../input/p-i-3000-500/images_segment_pneumothorax_test_GAN/\")\nGAN_test_otsu_dir = os.path.join(\"../input/p-i-3000-500/images_segment_otsu_pneumothorax_test_GAN/\")                             \nGAN_test_canny_dir = os.path.join(\"../input/p-i-3000-500/images_segment_canny_pneumothorax_test_GAN/\")\nGAN_train_list = os.listdir(GAN_train_dir)\nGAN_train_otsu_list = os.listdir(GAN_train_otsu_dir)                          \nGAN_train_canny_list = os.listdir(GAN_train_canny_dir)\nGAN_test_list = os.listdir(GAN_test_dir)\nGAN_test_otsu_list = os.listdir(GAN_test_otsu_dir)                            \nGAN_test_canny_list = os.listdir(GAN_test_canny_dir)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PNEUMOTHORAX_IMAGES_TRAIN_ = list()\nPNEUMOTHORAX_IMAGES_TRAIN_GAN_ = list()\nPNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN_ = list()\nPNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN_ = list()\n\nfor item in tqdm(auto_train_list):\n    dir_auto = auto_train_dir + item\n    dir_GAN = GAN_train_dir + item\n    dir_GAN_otsu = GAN_train_otsu_dir + item\n    dir_GAN_canny = GAN_train_canny_dir + item\n    \n    PNEUMOTHORAX_IMAGES_TRAIN_.append((cv2.imread(dir_auto,0).reshape((256, 256, 1)).astype('float16')) / 255.)\n    \n    PNEUMOTHORAX_IMAGES_TRAIN_GAN_.append((cv2.imread(dir_GAN,0).reshape((256, 256, 1)).astype('float16') - 127.5) / 127.5)\n    \n    PNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN_.append((cv2.imread(dir_GAN_otsu,0).reshape((256, 256, 1)).astype('float16') - 127.5) / 127.5)\n    \n    PNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN_.append((cv2.imread(dir_GAN_canny,0).reshape((256, 256, 1)).astype('float16') - 127.5) / 127.5)\n    \nimport gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PNEUMOTHORAX_IMAGES_TRAIN = np.asarray(PNEUMOTHORAX_IMAGES_TRAIN_)\nPNEUMOTHORAX_IMAGES_TRAIN_GAN = np.asarray(PNEUMOTHORAX_IMAGES_TRAIN_GAN_)\nPNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN = np.asarray(PNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN_)\nPNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN = np.asarray(PNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del PNEUMOTHORAX_IMAGES_TRAIN_\ndel PNEUMOTHORAX_IMAGES_TRAIN_GAN_\ndel PNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN_\ndel PNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN_\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PNEUMOTHORAX_IMAGES_TEST = list()\nPNEUMOTHORAX_IMAGES_TEST_GAN = list()\nPNEUMOTHORAX_IMAGES_OTSU_TEST_GAN = list()\nPNEUMOTHORAX_IMAGES_CANNY_TEST_GAN = list()\n\nfor item in tqdm(auto_test_list):\n    dir_auto = auto_test_dir + item\n    dir_GAN = GAN_test_dir + item\n    dir_GAN_otsu = GAN_test_otsu_dir + item\n    dir_GAN_canny = GAN_test_canny_dir + item\n    \n    im_auto = cv2.imread(dir_auto,0)\n    im_auto = (im_auto.reshape((256, 256, 1)).astype('float16')) / 255.\n    \n    im_GAN = cv2.imread(dir_GAN,0)\n    im_GAN = (im_GAN.reshape((256, 256, 1)).astype('float16') - 127.5) / 127.5\n    \n    im_GAN_otsu = cv2.imread(dir_GAN_otsu,0)\n    im_GAN_otsu = (im_GAN_otsu.reshape((256, 256, 1)).astype('float16') - 127.5) / 127.5\n    \n    im_GAN_canny = cv2.imread(dir_GAN_canny,0)\n    im_GAN_canny = (im_GAN_canny.reshape((256, 256, 1)).astype('float16') - 127.5) / 127.5\n    \n    PNEUMOTHORAX_IMAGES_TEST.append(im_auto)\n    PNEUMOTHORAX_IMAGES_TEST_GAN.append(im_GAN)\n    PNEUMOTHORAX_IMAGES_OTSU_TEST_GAN.append(im_GAN_otsu)\n    PNEUMOTHORAX_IMAGES_CANNY_TEST_GAN.append(im_GAN_canny)\n    \nimport gc\ndel im_auto\ndel im_GAN\ndel im_GAN_otsu\ndel im_GAN_canny\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PNEUMOTHORAX_IMAGES_TEST = np.asarray(PNEUMOTHORAX_IMAGES_TEST)\nPNEUMOTHORAX_IMAGES_TEST_GAN = np.asarray(PNEUMOTHORAX_IMAGES_TEST_GAN)\nPNEUMOTHORAX_IMAGES_OTSU_TEST_GAN = np.asarray(PNEUMOTHORAX_IMAGES_OTSU_TEST_GAN)\nPNEUMOTHORAX_IMAGES_CANNY_TEST_GAN = np.asarray(PNEUMOTHORAX_IMAGES_CANNY_TEST_GAN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.initializers import RandomNormal\nfrom keras.metrics import MeanIoU\nimport heapq\n\nclass SpectralNormalization(tf.keras.layers.Wrapper):\n    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n        self.iteration = iteration\n        self.eps = eps\n        self.do_power_iteration = training\n        if not isinstance(layer, tf.keras.layers.Layer):\n            raise ValueError(\n                'Please initialize `TimeDistributed` layer with a '\n                '`Layer` instance. You passed: {input}'.format(input=layer))\n        super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n    def build(self, input_shape):\n        self.layer.build(input_shape)\n\n        self.w = self.layer.kernel\n        self.w_shape = self.w.shape.as_list()\n\n        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_v',\n                                 dtype=tf.float32)\n\n        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_u',\n                                 dtype=tf.float32)\n\n        super(SpectralNormalization, self).build()\n\n    def call(self, inputs):\n        self.update_weights()\n        output = self.layer(inputs)\n        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n        return output\n    \n    def update_weights(self):\n        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n        \n        u_hat = self.u\n        v_hat = self.v  # init v vector\n\n        if self.do_power_iteration:\n            for _ in range(self.iteration):\n                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                u_ = tf.matmul(v_hat, w_reshaped)\n                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n        self.u.assign(u_hat)\n        self.v.assign(v_hat)\n\n        self.layer.kernel.assign(self.w / sigma)\n\n    def restore_weights(self):\n        self.layer.kernel.assign(self.w)\n\ndef processing(prediction_,list_prediction):   \n    for predicted_rx in tqdm(prediction_):\n        predicted_rxx = np.squeeze(predicted_rx.astype(np.float16))\n        plt.imsave('predicted_000.jpg', predicted_rxx, cmap='gray')\n        img = cv2.imread('./predicted_000.jpg',1)\n\n        img_grey = img[:,:,0]\n        min_ = img_grey.min()\n        max_ = img_grey.max()\n        ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        kernel = np.ones((5,5),np.uint8)\n        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n        contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n        len_contours = list()\n        for i in range(0,len(contours)):\n            len_contours.append(len(contours[i]))\n\n        #two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n        try:\n            data = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\n            two_largest, vals = zip(*data)\n        except:\n            pass\n        \n        try:\n            cnt0 = contours[two_largest[0]].reshape(-1,2)\n            epsilon0 = 0.001*cv2.arcLength(cnt0,True)\n            approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n        except:\n            pass\n        try: \n            cnt1 = contours[two_largest[1]].reshape(-1,2)\n            epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n            approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n        except:\n            pass\n\n        canvas = np.zeros(thresh.shape, np.uint8)\n        try:\n            cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n        except:\n            pass\n        try:\n            cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n        except:\n            pass\n        canvas = canvas[:,:]\n        list_prediction.append(canvas)\n\n    list_prediction = np.expand_dims(list_prediction, axis=-1)\n    gc.collect()\n    return list_prediction\n\ndef make_generator_model():\n    \n    input_shape=(SIZE,SIZE,CHANNELS)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    img_input1 = Input(shape=input_shape)\n    img_input2 = Input(shape=input_shape)\n    img_input3 = Input(shape=input_shape)\n\n    concat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n    \n    conv1 = SpectralNormalization(Conv2D(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = layers.LeakyReLU(0.2)(batch1)\n\n    conv2 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = layers.LeakyReLU(0.2)(batch2)\n\n    conv3 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = layers.LeakyReLU(0.2)(batch3)\n\n    conv4 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = layers.LeakyReLU(0.2)(batch4)\n\n    conv5 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = layers.LeakyReLU(0.2)(batch5)\n\n    conv6 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act5)\n    batch6 = BatchNormalization()(conv6)\n    act6 = layers.LeakyReLU(0.2)(batch6)\n    concat6 = concatenate([act2,act6])\n\n    conv7 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat6)\n    batch7 = BatchNormalization()(conv7)\n    act7 = layers.LeakyReLU(0.2)(batch7)\n    concat7 = concatenate([act1,act7])\n\n    conv8 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = layers.LeakyReLU(0.2)(batch8)\n\n    conv9 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = layers.LeakyReLU(0.2)(batch9)\n\n    conv10 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = layers.LeakyReLU(0.2)(batch10)\n\n    conv11 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = layers.LeakyReLU(0.2)(batch11)\n\n    conv12 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act11)\n    batch12 = BatchNormalization()(conv12)\n    act12 = layers.LeakyReLU(0.2)(batch12)\n    concat12 = concatenate([act9,act12])\n\n    conv13 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat12)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  layers.LeakyReLU(0.2)(batch13)\n    concat13 = concatenate([act8,act13])\n\n    conv14 = SpectralNormalization(Conv2DTranspose(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat13)\n    batch14 = BatchNormalization()(conv14)\n    act14 = layers.LeakyReLU(0.2)(batch14)\n    concat14 = concatenate([concat_input,act14])\n\n    output_xnet = SpectralNormalization(Conv2D(1, (1, 1), activation='tanh'))(concat14)\n\n    model = Model(inputs = [img_input1,img_input2,img_input3], outputs = output_xnet)\n       \n    return model\n\ngenerator = make_generator_model()\n\n\n\nmodel1 = generator\nmodel1.load_weights('../input/gan-segmenter-100-bs8-27-bs1/generator_model_segmentation_100_27_epochs.h5')\nmodel2 = load_model('../input/autoencoders-segmentation-300-epochs/xnet_segmenter_300_epochs.h5', compile=False)\nmodel3 = load_model('../input/autoencoders-segmentation-300-epochs/resnet34_segmenter_300_epochs.h5', compile=False)\n\nmodels = [model1, model2, model3]\n\nX_data1 = [PNEUMOTHORAX_IMAGES_TEST_GAN.astype(np.float16),PNEUMOTHORAX_IMAGES_OTSU_TEST_GAN.astype(np.float16),PNEUMOTHORAX_IMAGES_CANNY_TEST_GAN.astype(np.float16)]\nX_data2 = PNEUMOTHORAX_IMAGES_TEST.astype(np.float16)\nBACKBONE1 = 'resnet34'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\nX_data3 = preprocess_input1(PNEUMOTHORAX_IMAGES_TEST)\n\npred1 = model1.predict(X_data1)\npred2 = model2.predict(X_data2)\npred3 = model3.predict(X_data3)\n\nprediction1 = list()\nprediction2 = list()\nprediction3 = list()\n\npredi1 = processing(pred1,prediction1)\npredi2 = processing(pred2,prediction2)\npredi3 = processing(pred3,prediction3)\n\npreds=np.asarray([predi1, predi2, predi3])\npreds.astype(np.float16)\n\ngc.collect()\n\nwted_preds = np.tensordot(preds, [0.2, 0.3, 0.3], axes=((0),(0)))\nwted_ensemble_pred = np.squeeze(wted_preds.astype(np.float16))\n\nwted = list()\nfor ima in tqdm(wted_ensemble_pred):\n\n    out = np.zeros_like(ima)\n    for i in range(0,SIZE):\n        lim = 0.75*ima.max()\n        for j in range(0,SIZE):\n            if ima[i,j] >= lim:\n                out[i,j] = 255.0\n    wted.append(out)\n    \nwted_images = np.array(wted)\nwted_images = np.expand_dims(wted_images, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 30\nfig, ax = plt.subplots(1,3, figsize = (8,4))\nax[0].imshow(np.array(PNEUMOTHORAX_IMAGES_TEST[number]).astype(np.float32), cmap='gray')\nax[1].imshow(np.array(wted_images[number]), cmap='gray')\nout = np.zeros_like(wted_images[number])\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        if wted_images[number][i,j] == 255:\n            out[i,j] = PNEUMOTHORAX_IMAGES_TEST[number][i,j]\nax[2].imshow(np.array(out), cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./PNEUMOTHORAX/masks_pneumothorax_test')\nfor i in tqdm(range(0,len(wted_images))):\n    predicted_rx = np.squeeze(wted_images[i].astype(np.float32))\n    plt.imsave('./PNEUMOTHORAX/masks_pneumothorax_test/'+ auto_test_list[i] + '_mask.png',predicted_rx, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del out\ndel ima\ndel wted_preds\ndel wted_ensemble_pred\ndel preds\ndel pred1\ndel pred2\ndel pred3\ndel predi1\ndel predi2\ndel predi3\ndel wted_images\ndel X_data1\ndel X_data2\ndel X_data3\ndel PNEUMOTHORAX_IMAGES_TEST_GAN\ndel PNEUMOTHORAX_IMAGES_TEST\ndel PNEUMOTHORAX_IMAGES_OTSU_TEST_GAN\ndel PNEUMOTHORAX_IMAGES_CANNY_TEST_GAN\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.initializers import RandomNormal\nfrom keras.metrics import MeanIoU\nimport heapq\n\nclass SpectralNormalization(tf.keras.layers.Wrapper):\n    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n        self.iteration = iteration\n        self.eps = eps\n        self.do_power_iteration = training\n        if not isinstance(layer, tf.keras.layers.Layer):\n            raise ValueError(\n                'Please initialize `TimeDistributed` layer with a '\n                '`Layer` instance. You passed: {input}'.format(input=layer))\n        super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n    def build(self, input_shape):\n        self.layer.build(input_shape)\n\n        self.w = self.layer.kernel\n        self.w_shape = self.w.shape.as_list()\n\n        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_v',\n                                 dtype=tf.float32)\n\n        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_u',\n                                 dtype=tf.float32)\n\n        super(SpectralNormalization, self).build()\n\n    def call(self, inputs):\n        self.update_weights()\n        output = self.layer(inputs)\n        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n        return output\n    \n    def update_weights(self):\n        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n        \n        u_hat = self.u\n        v_hat = self.v  # init v vector\n\n        if self.do_power_iteration:\n            for _ in range(self.iteration):\n                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                u_ = tf.matmul(v_hat, w_reshaped)\n                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n        self.u.assign(u_hat)\n        self.v.assign(v_hat)\n\n        self.layer.kernel.assign(self.w / sigma)\n\n    def restore_weights(self):\n        self.layer.kernel.assign(self.w)\n\ndef processing(prediction_,list_prediction):   \n    for predicted_rx in tqdm(prediction_):\n        predicted_rxx = np.squeeze(predicted_rx.astype(np.float16))\n        plt.imsave('predicted_000.jpg', predicted_rxx, cmap='gray')\n        img = cv2.imread('./predicted_000.jpg',1)\n\n        img_grey = img[:,:,0]\n        min_ = img_grey.min()\n        max_ = img_grey.max()\n        ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n        kernel = np.ones((5,5),np.uint8)\n        thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n        thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n        contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n        len_contours = list()\n        for i in range(0,len(contours)):\n            len_contours.append(len(contours[i]))\n\n        #two_largest = list(map(len_contours.index, heapq.nlargest(2, len_contours)))  \n\n        data = heapq.nlargest(2, enumerate(len_contours), key=lambda x:x[1])\n        two_largest, vals = zip(*data)\n\n        cnt0 = contours[two_largest[0]].reshape(-1,2)\n        epsilon0 = 0.001*cv2.arcLength(cnt0,True)\n        approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n        try: \n            cnt1 = contours[two_largest[1]].reshape(-1,2)\n            epsilon1 = 0.001*cv2.arcLength(cnt1,True)\n            approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n        except:\n            pass\n\n        canvas = np.zeros(thresh.shape, np.uint8)\n        cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n\n        try:\n            cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n        except:\n            pass\n        canvas = canvas[:,:]\n        list_prediction.append(canvas)\n\n    list_prediction = np.expand_dims(list_prediction, axis=-1)\n    gc.collect()\n    return list_prediction\n\ndef make_generator_model():\n    \n    input_shape=(SIZE,SIZE,CHANNELS)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    img_input1 = Input(shape=input_shape)\n    img_input2 = Input(shape=input_shape)\n    img_input3 = Input(shape=input_shape)\n\n    concat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n    \n    conv1 = SpectralNormalization(Conv2D(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = layers.LeakyReLU(0.2)(batch1)\n\n    conv2 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = layers.LeakyReLU(0.2)(batch2)\n\n    conv3 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = layers.LeakyReLU(0.2)(batch3)\n\n    conv4 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = layers.LeakyReLU(0.2)(batch4)\n\n    conv5 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = layers.LeakyReLU(0.2)(batch5)\n\n    conv6 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act5)\n    batch6 = BatchNormalization()(conv6)\n    act6 = layers.LeakyReLU(0.2)(batch6)\n    concat6 = concatenate([act2,act6])\n\n    conv7 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat6)\n    batch7 = BatchNormalization()(conv7)\n    act7 = layers.LeakyReLU(0.2)(batch7)\n    concat7 = concatenate([act1,act7])\n\n    conv8 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = layers.LeakyReLU(0.2)(batch8)\n\n    conv9 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = layers.LeakyReLU(0.2)(batch9)\n\n    conv10 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = layers.LeakyReLU(0.2)(batch10)\n\n    conv11 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = layers.LeakyReLU(0.2)(batch11)\n\n    conv12 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act11)\n    batch12 = BatchNormalization()(conv12)\n    act12 = layers.LeakyReLU(0.2)(batch12)\n    concat12 = concatenate([act9,act12])\n\n    conv13 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat12)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  layers.LeakyReLU(0.2)(batch13)\n    concat13 = concatenate([act8,act13])\n\n    conv14 = SpectralNormalization(Conv2DTranspose(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat13)\n    batch14 = BatchNormalization()(conv14)\n    act14 = layers.LeakyReLU(0.2)(batch14)\n    concat14 = concatenate([concat_input,act14])\n\n    output_xnet = SpectralNormalization(Conv2D(1, (1, 1), activation='tanh'))(concat14)\n\n    model = Model(inputs = [img_input1,img_input2,img_input3], outputs = output_xnet)\n       \n    return model\n\ngenerator = make_generator_model()\n\n\nmodel1 = generator\nmodel1.load_weights('../input/gan-segmenter-100-bs8-27-bs1/generator_model_segmentation_100_27_epochs.h5')\nmodel2 = load_model('../input/autoencoders-segmentation-300-epochs/xnet_segmenter_300_epochs.h5', compile=False)\nmodel3 = load_model('../input/autoencoders-segmentation-300-epochs/resnet34_segmenter_300_epochs.h5', compile=False)\n\nmodels = [model1, model2, model3]\n\npred1 = model1.predict([PNEUMOTHORAX_IMAGES_TRAIN_GAN.astype(np.float16),PNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN.astype(np.float16),PNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN.astype(np.float16)])\npred2 = model2.predict(PNEUMOTHORAX_IMAGES_TRAIN.astype(np.float16))\nBACKBONE1 = 'resnet34'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\npred3 = model3.predict(preprocess_input1(PNEUMOTHORAX_IMAGES_TRAIN))\n\ndel PNEUMOTHORAX_IMAGES_TRAIN_GAN\ndel PNEUMOTHORAX_IMAGES_TRAIN\ndel PNEUMOTHORAX_IMAGES_OTSU_TRAIN_GAN\ndel PNEUMOTHORAX_IMAGES_CANNY_TRAIN_GAN\ngc.collect()\n\nprediction1 = list()\nprediction2 = list()\nprediction3 = list()\n\npredi1 = processing(pred1,prediction1)\npredi2 = processing(pred2,prediction2)\npredi3 = processing(pred3,prediction3)\n\ndel pred1\ndel pred2\ndel pred3\ngc.collect()\n\npreds=np.asarray([predi1, predi2, predi3])\npreds.astype(np.float16)\n\n\ndel predi1\ndel predi2\ndel predi3\ngc.collect()\n\nwted_preds = np.tensordot(preds, [0.2, 0.3, 0.3], axes=((0),(0)))\nwted_ensemble_pred = np.squeeze(wted_preds.astype(np.float16))\n\ndel wted_preds\ndel preds\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wted = list()\nfor ima in tqdm(wted_ensemble_pred):\n    lim = 0.75*ima.max()\n    out = np.zeros_like(ima)\n    for i in range(0,SIZE):\n        for j in range(0,SIZE):\n            if ima[i,j] >= lim:\n                out[i,j] = 255.0\n    wted.append(out)\n    \nwted_images = np.array(wted)\nwted_images = np.expand_dims(wted_images, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 30\nfig, ax = plt.subplots(1,3, figsize = (8,4))\nax[0].imshow(np.array(PNEUMOTHORAX_IMAGES_TRAIN[number]).astype(np.float32), cmap='gray')\nax[1].imshow(np.array(wted_images[number]), cmap='gray')\nout = np.zeros_like(wted_images[number])\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        if wted_images[number][i,j] == 255:\n            out[i,j] = PNEUMOTHORAX_IMAGES_TRAIN[number][i,j]\nax[2].imshow(np.array(out), cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./PNEUMOTHORAX/masks_pneumothorax_train')\nfor i in tqdm(range(0,len(wted_images))):\n    predicted_rx = np.squeeze(wted_images[i].astype(np.float16))\n    plt.imsave('./PNEUMOTHORAX/masks_pneumothorax_train/'+ auto_train_list[i] + '_mask.png',predicted_rx, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n       \njungle_zip = zipfile.ZipFile('./images_and_masks.zip', 'w')\njungle_zip.write('./PNEUMOTHORAX', compress_type=zipfile.ZIP_DEFLATED)\n \njungle_zip.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10. Structuring the radiomics analysis","metadata":{}},{"cell_type":"code","source":"auto_train_dir = os.path.join(\"../input/pneumothorax-xray-images-and-masks/masks_pneumothorax_train/\")\nauto_test_dir = os.path.join(\"../input/pneumothorax-xray-images-and-masks/masks_pneumothorax_test/\")\nauto_train_list = os.listdir(auto_train_dir)\nauto_test_list = os.listdir(auto_test_dir)\nDATADIR_IMAGES = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_images/'\nDF_TEST = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_test_images.csv')\nDF_TRAIN = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_train_images.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = os.path.join(\"../input/pneumothorax-xray-images-and-masks/masks_pneumothorax_test/\")\ntest_list = os.listdir(test_dir)\nos.makedirs('./PNEUMOTHORAX/masks_pneumothorax_test')\nfor i in tqdm(range(0,len(test_list))):\n    im = cv2.imread('../input/pneumothorax-xray-images-and-masks/masks_pneumothorax_test/'+ test_list[i],cv2.IMREAD_GRAYSCALE)\n    im = np.squeeze(im.astype(np.float16))\n    plt.imsave('./PNEUMOTHORAX/masks_pneumothorax_test/'+ str(i) + '.jpg',im, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = os.path.join(\"../input/pneumothorax-xray-images-and-masks/masks_pneumothorax_train/\")\ntrain_list = os.listdir(train_dir)\nos.makedirs('./PNEUMOTHORAX/masks_pneumothorax_train')\nfor i in tqdm(range(0,len(train_list))):\n    im = cv2.imread('../input/pneumothorax-xray-images-and-masks/masks_pneumothorax_train/'+ train_list[i],cv2.IMREAD_GRAYSCALE)\n    im = np.squeeze(im.astype(np.float16))\n    plt.imsave('./PNEUMOTHORAX/masks_pneumothorax_train/'+ str(i) + '.jpg',im, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LEN_TRAIN_NO_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 0].shape[0]\nLEN_TRAIN_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 1].shape[0]\nLEN_TEST_NO_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 0].shape[0]\nLEN_TEST_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 1].shape[0]\n\nIMAGE_TRAIN_PNEUMO = list()\nIMAGE_TRAIN_NO_PNEUMO = list()\nIMAGE_TEST_PNEUMO = list()\nIMAGE_TEST_NO_PNEUMO = list()\n\nCLASS_IMAGE_TRAIN_PNEUMO = list()\nCLASS_IMAGE_TRAIN_NO_PNEUMO = list()\nCLASS_IMAGE_TEST_PNEUMO = list()\nCLASS_IMAGE_TEST_NO_PNEUMO = list()\n\nNAME_TRAIN_PNEUMO = list()\nNAME_TRAIN_NO_PNEUMO = list()\nNAME_TEST_PNEUMO = list()\nNAME_TEST_NO_PNEUMO = list()\n\nfor i in tqdm(range(0,int(1500))):\n    DF_TRAIN_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 1]\n    IMAGE_NAME = DF_TRAIN_PNEUMO.iloc[i,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TRAIN_PNEUMO.append(image)\n    CLASS_IMAGE_TRAIN_PNEUMO.append(1)\n    NAME_TRAIN_PNEUMO.append(IMAGE_NAME)\n\nfor j in tqdm(range(0,int(1500))):\n    DF_TRAIN_NO_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 0]\n    IMAGE_NAME = DF_TRAIN_NO_PNEUMO.iloc[j,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TRAIN_NO_PNEUMO.append(image)\n    CLASS_IMAGE_TRAIN_NO_PNEUMO.append(0)\n    NAME_TRAIN_NO_PNEUMO.append(IMAGE_NAME)\n    \nfor k in tqdm(range(0,int(250))):\n    DF_TEST_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 1]\n    IMAGE_NAME = DF_TEST_PNEUMO.iloc[k,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TEST_PNEUMO.append(image)\n    CLASS_IMAGE_TEST_PNEUMO.append(1)\n    NAME_TEST_PNEUMO.append(IMAGE_NAME)\n    \nfor l in tqdm(range(0,int(250))):\n    DF_TEST_NO_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 0]\n    IMAGE_NAME = DF_TEST_NO_PNEUMO.iloc[l,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    IMAGE_TEST_NO_PNEUMO.append(image)\n    CLASS_IMAGE_TEST_NO_PNEUMO.append(0)\n    NAME_TEST_NO_PNEUMO.append(IMAGE_NAME)\n\nCLASS_IMAGE_TRAIN_PNEUMO = np.array(CLASS_IMAGE_TRAIN_PNEUMO)\nCLASS_IMAGE_TRAIN_NO_PNEUMO = np.array(CLASS_IMAGE_TRAIN_NO_PNEUMO)\nCLASS_IMAGE_TEST_PNEUMO = np.array(CLASS_IMAGE_TEST_PNEUMO)\nCLASS_IMAGE_TEST_NO_PNEUMO = np.array(CLASS_IMAGE_TEST_NO_PNEUMO)\n\nCLASS_TRAIN = np.concatenate((CLASS_IMAGE_TRAIN_PNEUMO,CLASS_IMAGE_TRAIN_NO_PNEUMO))\nCLASS_TEST = np.concatenate((CLASS_IMAGE_TEST_PNEUMO,CLASS_IMAGE_TEST_NO_PNEUMO))\n\nIMAGE_TRAIN_PNEUMO = np.array(IMAGE_TRAIN_PNEUMO).reshape((len(IMAGE_TRAIN_PNEUMO), SIZE, SIZE, CHANNELS))\nIMAGE_TRAIN_NO_PNEUMO = np.array(IMAGE_TRAIN_NO_PNEUMO).reshape((len(IMAGE_TRAIN_NO_PNEUMO), SIZE, SIZE, CHANNELS))\nIMAGE_TEST_PNEUMO = np.array(IMAGE_TEST_PNEUMO).reshape((len(IMAGE_TEST_PNEUMO), SIZE, SIZE, CHANNELS))\nIMAGE_TEST_NO_PNEUMO = np.array(IMAGE_TEST_NO_PNEUMO).reshape((len(IMAGE_TEST_NO_PNEUMO), SIZE, SIZE, CHANNELS))\n\nPNEUMOTHORAX_IMAGES_TRAIN = np.concatenate((IMAGE_TRAIN_PNEUMO,IMAGE_TRAIN_NO_PNEUMO))\nPNEUMOTHORAX_IMAGES_TEST = np.concatenate((IMAGE_TEST_PNEUMO,IMAGE_TEST_NO_PNEUMO))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.makedirs('./PNEUMOTHORAX/images_pneumothorax_train')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_TRAIN))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_TRAIN[i].astype(np.float16))\n    plt.imsave('./PNEUMOTHORAX/images_pneumothorax_train/'+ str(i) + '.jpg',predicted_rx, cmap = 'gray')\n#os.makedirs('./PNEUMOTHORAX/images_pneumothorax_test')\nfor i in tqdm(range(0,len(PNEUMOTHORAX_IMAGES_TEST))):\n    predicted_rx = np.squeeze(PNEUMOTHORAX_IMAGES_TEST[i].astype(np.float16))\n    plt.imsave('./PNEUMOTHORAX/images_pneumothorax_test/'+ str(i) + '.jpg',predicted_rx, cmap = 'gray')    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"applyLog = False\napplyWavelet = False\n\nsettings = {'binWidth':128,\n            'label': 1, \n            'interpolator': sitk.sitkBSpline, \n            'resampledPixelSpacing':None, \n            'force2D': True,\n            'force2Ddimension': 0}\n\nextractor = featureextractor.RadiomicsFeatureExtractor(additionalInfo=True, **settings)\nextractor.enableAllImageTypes()\n\nfeatureVector_test = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(PNEUMOTHORAX_IMAGES_TEST)): \n    image_test = sitk.ReadImage('./PNEUMOTHORAX/images_pneumothorax_test/'+ str(i) + '.jpg', sitk.sitkInt8)\n    mask_test = sitk.ReadImage('./PNEUMOTHORAX/masks_pneumothorax_test/'+ str(i) + '.jpg', sitk.sitkInt8)\n    result_test = pd.Series(extractor.execute(image_test, mask_test))\n    featureVector_test.append(result_test)\n    clear_output(wait=True)\n\ndf_test = pd.DataFrame(featureVector_test)\ndf_test.to_csv('Features_test', sep=',', encoding='utf-8')\ndf_test = pd.read_csv('./Features_test')\ndf_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"applyLog = False\napplyWavelet = False\n\nsettings = {'binWidth':128,\n            'label': 1, \n            'interpolator': sitk.sitkBSpline, \n            'resampledPixelSpacing':None, \n            'force2D': True,\n            'force2Ddimension': 0}\n\nextractor = featureextractor.RadiomicsFeatureExtractor(additionalInfo=True, **settings)\nextractor.enableAllImageTypes()\n\nfeatureVector_train = []","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len(PNEUMOTHORAX_IMAGES_TRAIN)): \n    image_train = sitk.ReadImage('./PNEUMOTHORAX/images_pneumothorax_train/'+ str(i) + '.jpg', sitk.sitkInt8)\n    mask_train = sitk.ReadImage('./PNEUMOTHORAX/masks_pneumothorax_train/'+ str(i) + '.jpg', sitk.sitkInt8)\n    result_train = pd.Series(extractor.execute(image_train, mask_train))\n    featureVector_train.append(result_train)\n    clear_output(wait=True)\n\ndf_train = pd.DataFrame(featureVector_train)\ndf_train.to_csv('Features_train', sep=',', encoding='utf-8')\ndf_train = pd.read_csv('./Features_train')\ndf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('./Features_train')\ndf_test = pd.read_csv('./Features_train')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', df_train.shape[0]+1)\ndf_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train.columns.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_test.columns.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(columns = ['Unnamed: 0', 'diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy', 'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python', 'diagnostics_Configuration_Settings', 'diagnostics_Configuration_EnabledImageTypes', 'diagnostics_Image-original_Hash', 'diagnostics_Image-original_Dimensionality', 'diagnostics_Image-original_Spacing', 'diagnostics_Image-original_Size', 'diagnostics_Image-original_Mean', 'diagnostics_Image-original_Minimum', 'diagnostics_Image-original_Maximum', 'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_Spacing', 'diagnostics_Mask-original_Size', 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_VoxelNum', 'diagnostics_Mask-original_VolumeNum', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'])\ndf_test = df_test.drop(columns = ['Unnamed: 0', 'diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy', 'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python', 'diagnostics_Configuration_Settings', 'diagnostics_Configuration_EnabledImageTypes', 'diagnostics_Image-original_Hash', 'diagnostics_Image-original_Dimensionality', 'diagnostics_Image-original_Spacing', 'diagnostics_Image-original_Size', 'diagnostics_Image-original_Mean', 'diagnostics_Image-original_Minimum', 'diagnostics_Image-original_Maximum', 'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_Spacing', 'diagnostics_Mask-original_Size', 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_VoxelNum', 'diagnostics_Mask-original_VolumeNum', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', df_test.shape[0]+1)\ndf_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['class'] = CLASS_TRAIN\ndf_test['class'] = CLASS_TEST","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count_nan_in_df = df_train.isnull().sum()\ndf_nan = pd.DataFrame(count_nan_in_df)\npd.set_option('display.max_rows', df_nan.shape[0]+1)\ndf_nan","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_nonan = df_train.apply (pd.to_numeric, errors='coerce')\ndf_train_nonan = df_train_nonan.dropna()\ndf_train_nonan = df_train_nonan.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test_nonan = df_test.apply (pd.to_numeric, errors='coerce')\ndf_test_nonan = df_test_nonan.dropna()\ndf_test_nonan = df_test_nonan.reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"frames = [df_train_nonan, df_test_nonan]\ndf = pd.concat(frames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_columns = df.columns.tolist()\nlist_columns = list_columns[0:837]\nnew = pd.DataFrame(columns=list_columns)\nfor col in list_columns:\n    new = df[df[str(col)] <= np.percentile(df[str(col)],95)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = new['class']\nX = new.drop(columns = ['class'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(X, y, test_size=0.30, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_F_train, y_C_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nconfusion_matrix = confusion_matrix(y_C_test, prediction.round())\nsn.heatmap(confusion_matrix, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = ExtraTreesClassifier(n_estimators=100)\nclf = clf.fit(X_F_train, y_C_train)\nmodel = SelectFromModel(clf, prefit=True)\nnew = model.transform(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced = pd.DataFrame(new)\nreduced.to_csv('Reduced.csv', sep=',', encoding='utf-8')\nreduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(reduced, y, test_size=0.30, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_F_train, y_C_train)\nprediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = list()\ncorr_matrix = reduced.corr()\n\nfor i in range(len(corr_matrix.columns)):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i, j]) > 0.4:\n            colname = corr_matrix.columns[i]\n            corr_features.append(str(colname))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_corr = list()\nfor item in corr_features:\n    list_corr.append(int(item))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr = reduced.drop(columns = list_corr, axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr.to_csv('Features_reduced_corr', sep=',', encoding='utf-8')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df_reduced_corr, y, test_size=0.30, random_state=42)\nrf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_F_train, y_C_train)\nprediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"Accuracy = \", metrics.accuracy_score(y_C_test, rf.predict(X_F_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 11. Structuring a deseases detection","metadata":{}},{"cell_type":"code","source":"label_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",'No Finding',\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]\ndisease_of_interest = list()\nfor i in tqdm(range(0,DF_LUNG_DISEASES[\"Finding Labels\"].count())):\n    if DF_LUNG_DISEASES[\"Finding Labels\"].iloc[i] in label_names:\n        class_ = 1\n    else:\n        class_ = 0 \n    disease_of_interest.append(class_)\n    \nDF_LUNG_DISEASES['disease_of_interest'] = disease_of_interest\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['disease_of_interest'] == 0 ]\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'No Finding']\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES_INTE.head(40198)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nNAMES_JPG_1 = DF_LUNG_DISEASES['Image Index'].str.replace('.png', '.jpg')\nNAMES_JPG_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./Diseases/attention')\nDIR_1 = './images/DISEASES/images/'\nDIR_2 = '../input/diseases-masks/Diseases/masks/'\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    PATH1 = DIR_1 + NAMES_JPG_1.iloc[i]\n    IMAGE1 = cv2.imread(os.path.join(PATH1),cv2.IMREAD_GRAYSCALE)\n    PATH2 = DIR_2 + NAMES_JPG_1.iloc[i]\n    IMAGE2 = cv2.imread(os.path.join(PATH2),cv2.IMREAD_GRAYSCALE)\n    _,IMAGE2 = cv2.threshold(IMAGE2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    for j in range(0,SIZE):\n        for k in range(0,SIZE):\n            if IMAGE2[j,k] == 255:\n                IMAGE2[j,k] = IMAGE1[j,k]\n    cv2.imwrite('./Diseases/attention/'+ str(NAMES_JPG_1.iloc[i]),(np.array(IMAGE2).reshape(SIZE, SIZE, 1)).astype('float32'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,2, figsize = (8,4))\nax[0].imshow((np.array(IMAGE1[number]).reshape(SIZE, SIZE, 1)).astype('float32'), cmap='gray')\nax[1].imshow((np.array(IMAGE2[number]).reshape(SIZE, SIZE, 1)).astype('float32'), cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n \nfantasy_zip = zipfile.ZipFile('./DISEASES_ATTENTION.zip', 'w')\n \nfor folder, subfolders, files in os.walk('./Diseases'):\n \n    for file in files:\n        if file.endswith('.jpg'):\n            fantasy_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), './PNEUMOTHORAX'), compress_type = zipfile.ZIP_DEFLATED)\n \nfantasy_zip.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By here","metadata":{}},{"cell_type":"code","source":"DIR_1 = './images/DISEASES/images/'\nDIR_2 = './attention_images/Diseases/attention/'\nIMAGES_ORIGINAL = list()\nIMAGES_COLLIMATED = list()\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    #PATH1 = DIR_1 + NAMES_JPG_1.iloc[i]\n    #IMAGE1 = cv2.imread(os.path.join(PATH1),cv2.IMREAD_GRAYSCALE)\n    #IMAGES_ORIGINAL.append(IMAGE1)\n    PATH2 = DIR_2 + NAMES_JPG_1.iloc[i]\n    IMAGE2 = cv2.imread(os.path.join(PATH2),cv2.IMREAD_GRAYSCALE)\n    IMAGES_COLLIMATED.append(IMAGE2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#3C\nDIR_1 = './images/DISEASES/images/'\nDIR_2 = './attention_images/Diseases/attention/'\nIMAGES_ORIGINAL = list()\nIMAGES_COLLIMATED = list()\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    #PATH1 = DIR_1 + NAMES_JPG_1.iloc[i]\n    #IMAGE1 = cv2.imread(os.path.join(PATH1))\n    #IMAGES_ORIGINAL.append(IMAGE1)\n    PATH2 = DIR_2 + NAMES_JPG_1.iloc[i]\n    IMAGE2 = cv2.imread(os.path.join(PATH2),cv2.IMREAD_GRAYSCALE)\n    IMAGES_COLLIMATED.append(IMAGE2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n#del IMAGE1\ndel IMAGE2\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,2, figsize = (8,4))\nax[0].imshow((np.array(IMAGES_ORIGINAL[number]).reshape(SIZE, SIZE, 1)).astype('float32'), cmap='gray')\nax[1].imshow((np.array(IMAGES_COLLIMATED[number]).reshape(SIZE, SIZE, 1)).astype('float32'), cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES.head(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nlabelencorder_targets = LabelEncoder()\nDF_LUNG_DISEASES['Finding Labels'] = labelencorder_targets.fit_transform(DF_LUNG_DISEASES['Finding Labels'])\n\nonehotencorder = ColumnTransformer(transformers=[(\"OneHot\", OneHotEncoder(),[1])],remainder='passthrough')\npredictors = onehotencorder.fit_transform(DF_LUNG_DISEASES)\nclasses = predictors[:,0:14]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X_train1, X_test1, y_train1, y_test1 = train_test_split(np.array(IMAGES_ORIGINAL), classes, test_size=0.25,random_state=0)\nX_train2, X_test2, y_train2, y_test2 = train_test_split(np.array(IMAGES_COLLIMATED), classes, test_size=0.25,random_state=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n#del IMAGES_ORIGINAL\n#del IMAGES_COLLIMATED\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nfrom keras.layers import *\n\nimg_size_target = 256\nimg_input = Input(shape=(img_size_target, img_size_target, 1))\nimg_conc = Concatenate()([img_input, img_input, img_input])\nbase_model = VGG16(input_tensor=img_conc,weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n\nfor layer in base_model.layers[:19]:\n    layer.trainable = False\nmodel = models.Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nbase_model.summary()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, layer in enumerate(base_model.layers):\n    print(i,layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(pd.DataFrame(np.squeeze(np.array(X_feature)))).to_csv('./features_test', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfj = pd.DataFrame(np.squeeze(np.array(X_feature)))\ndfj","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number_ = 4\nfor num in range(number_,number_+1):\n    c = int((len(IMAGES_COLLIMATED)/5)*num)\n    X_feature = list()\n    for i in tqdm(range(0+c,int((len(IMAGES_COLLIMATED)/5)+c))):\n        images_col = (IMAGES_COLLIMATED[i].reshape((1,256, 256,1)).astype('float16')) / 255.\n        X_feature.append(model.predict(images_col))\n    (pd.DataFrame(np.squeeze(np.array(X_feature)))).to_csv('./features_'+str(num+1)+'_5.csv', sep=',', encoding='utf-8')\n    del images_col\n    del X_feature\n    gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total = pd.read_csv('./features_0_5.csv',dtype = np.float16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total.to_csv('./features_total.csv', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total = pd.concat([df_total,pd.read_csv('./features_2_5.csv',dtype = np.float16)], ignore_index=True)\nimport gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total = pd.concat([df_total,pd.read_csv('./features_3_5.csv',dtype = np.float16)], ignore_index=True)\nimport gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total = pd.concat([df_total,pd.read_csv('./features_4_5.csv',dtype = np.float16)], ignore_index=True)\nimport gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total = pd.concat([df_total,pd.read_csv('./features_5_5.csv',dtype = np.float16)], ignore_index=True)\nimport gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_total.iloc[:,1:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del images_col\ndel X_feature\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*New stage - Let's try somethings*","metadata":{}},{"cell_type":"code","source":"DATA1 = (pd.read_csv('../input/test-features1/features_1_5.csv',dtype = np.float16,nrows=2)).iloc[:,1:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = DF_LUNG_DISEASES['Finding Labels'].head(10000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = pd.DataFrame(classes[0:10000])\ntarget","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = ExtraTreesClassifier(n_estimators=100)\nclf = clf.fit(DATA, target)\nmodel = SelectFromModel(clf, prefit=True)\nnew = model.transform(DATA)\n\nreduced = pd.DataFrame(new)\nreduced.to_csv('Reduced.csv', sep=',', encoding='utf-8')\nreduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_idx = model.get_support()\nfeature_name = DATA.columns[feature_idx]\nfeature_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(range(0,13284)):\n    reduced.rename(columns={i: feature_name[i]}, inplace = True)\nreduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = list()\ncorr_matrix = reduced.corr()\n\nfor i in range(len(corr_matrix.columns)):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i, j]) > 0.4:\n            colname = corr_matrix.columns[i]\n            corr_features.append(str(colname))\n\nlist_corr = list()\nfor item in corr_features:\n    list_corr.append(int(item))\n\ndf_reduced_corr = reduced.drop(columns = list_corr, axis=0)\ndf_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"set(list_corr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr = reduced.copy()\nfor item in tqdm(set(list_corr)):\n    df_reduced_corr.drop(columns = str(item), inplace = True)\ndf_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_n = pd.DataFrame(columns = feature_name)\nfeature_n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_n.to_csv('Feature.csv', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = pd.read_csv('./Feature.csv').iloc[:,1:-1]\na","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df_reduced_corr, target, test_size=0.20, random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_F_train, y_C_train)\nprediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Let's work with complete dataset**","metadata":{}},{"cell_type":"code","source":"label_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",'No Finding',\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]\ndisease_of_interest = list()\nfor i in tqdm(range(0,DF_LUNG_DISEASES[\"Finding Labels\"].count())):\n    if DF_LUNG_DISEASES[\"Finding Labels\"].iloc[i] in label_names:\n        class_ = 1\n    else:\n        class_ = 0 \n    disease_of_interest.append(class_)\n    \nDF_LUNG_DISEASES['disease_of_interest'] = disease_of_interest\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['disease_of_interest'] == 0 ]\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'No Finding']\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES_INTE.head(40198)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nNAMES_JPG_1 = DF_LUNG_DISEASES['Image Index'].str.replace('.png', '.jpg')\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nlabelencorder_targets = LabelEncoder()\nDF_LUNG_DISEASES['Finding Labels'] = labelencorder_targets.fit_transform(DF_LUNG_DISEASES['Finding Labels'])\n\nonehotencorder = ColumnTransformer(transformers=[(\"OneHot\", OneHotEncoder(),[1])],remainder='passthrough')\npredictors = onehotencorder.fit_transform(DF_LUNG_DISEASES)\nclasses = predictors[:,0:14]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES['Finding Labels'][10000:22500].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cudf\nDATA = cudf.read_csv('../input/diseases-dataset-features-50000/features_total.csv', skiprows=10000, nrows=12500).iloc[:,2:-1]\n#PANDAS === DATA = (pd.read_csv('../input/diseases-dataset-features-50000/features_total.csv',dtype = np.float16)).iloc[:,1:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arr = np.array(DATA.to_gpu_matrix())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET = pd.DataFrame(arr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del arr\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = DF_LUNG_DISEASES['Finding Labels'][10000:22500]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nclf = ExtraTreesClassifier(n_estimators=100)\nclf = clf.fit(DATASET, targets)\nmodel = SelectFromModel(clf, prefit=True)\nnew = model.transform(DATASET)\nreduced = pd.DataFrame(new)\nreduced.to_csv('Reduced.csv', sep=',', encoding='utf-8')\nfeature_idx = model.get_support()\nfeature_name = DATASET.columns[feature_idx]\nreduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_name = np.array(feature_name)\nfeature_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_n = pd.DataFrame(columns = feature_name)\nfeature_n.to_csv('Features_rf.csv', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced.columns = feature_name\nreduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced.to_csv('Reduced_ok.csv', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced = pd.read_csv('../input/features-ok/Reduced_ok.csv',dtype = np.float16).iloc[:,1:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"reduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = list()\ncorr_matrix = reduced.corr()\n\nfor i in tqdm(range(len(corr_matrix.columns))):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i, j]) > 0.25:\n            colname = corr_matrix.columns[i]\n            corr_features.append(str(colname))\n\nlist_corr = list()\nfor item in tqdm(corr_features):\n    list_corr.append(int(item))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(set(list_corr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"haha = reduced.head(10)\nhaha","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr = haha.copy()\nfor item in tqdm(set(list_corr)):\n    df_reduced_corr.drop(columns = str(item), inplace = True)\ndf_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"g = pd.DataFrame(columns = df_reduced_corr.columns)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr.to_csv('Reduced_final.csv', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/vbookshelf/play-audio-read-the-files-create-a-spectrogram\n\nfrom pydub import AudioSegment\nimport IPython\n\npath = '../input/alarm-sound/Alarm_Slow_A1_fesliyanstudios.mp3'\n\nIPython.display.Audio(path, autoplay=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 12. Structuring neural network","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/diseases-dataset-features-50000/features_total.csv', usecols = df_reduced_corr.columns, low_memory = True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets = DF_LUNG_DISEASES['Finding Labels']\ntargets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df, targets, test_size=0.25, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier()\nrf.fit(X_F_train, y_C_train)\nprediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nfig, ax = plt.subplots(1,1, figsize = (16,16))\nconfusion_matrix = confusion_matrix(y_C_test, prediction.round())\nsn.heatmap(confusion_matrix, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from tensorflow.keras.applications import VGG16\n#from keras.layers import *\n#with tpu_strategy.scope(): \n    #img_size_target = 256\n    #img_input = Input(shape=(img_size_target, img_size_target, 1))\n    #img_conc = Concatenate()([img_input, img_input, img_input])\n#    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n#    for layer in base_model.layers[:19]:\n#        layer.trainable = False  \n#\n#    base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df, classes, test_size=0.25, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with tpu_strategy.scope(): \nmodel = models.Sequential()\nmodel.add(layers.Dense(256, activation=\"relu\", input_shape=(X_F_train.shape[-1],)))\nmodel.add(layers.Dense(128, activation=\"relu\"))\nmodel.add(layers.Dense(y_C_train.shape[-1], activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(X_F_train, np.asarray(y_C_train).astype(np.float32), batch_size = 32, epochs = 100, verbose = 1, validation_split=0.20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 13. VGG16","metadata":{}},{"cell_type":"code","source":"label_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",'No Finding',\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]\nDF_LUNG_DISEASES['diseases'] = DF_LUNG_DISEASES['Finding Labels']\nDF_LUNG_DISEASES['diseases'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(DF_LUNG_DISEASES['diseases'].value_counts().to_string())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disease_of_interest = list()\nfor i in tqdm(range(0,DF_LUNG_DISEASES[\"Finding Labels\"].count())):\n    if DF_LUNG_DISEASES[\"Finding Labels\"].iloc[i] in label_names:\n        class_ = 1\n    else:\n        class_ = 0 \n    disease_of_interest.append(class_)\n    \nDF_LUNG_DISEASES['disease_of_interest'] = disease_of_interest\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['disease_of_interest'] == 0 ]\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\n\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Atelectasis']\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES_INTE0.head(3215)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE0.index, axis=0)\n\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Cardiomegaly']\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES_INTE1.head(93)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE1.index, axis=0)\n\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Consolidation']\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES_INTE2.head(1310)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE2.index, axis=0)\n\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Edema']\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES_INTE3.head(628)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE3.index, axis=0)\n\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Effusion']\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES_INTE4.head(2955)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE4.index, axis=0)\n\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Emphysema']\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES_INTE5.head(892)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE5.index, axis=0)\n\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Fibrosis']\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES_INTE6.head(727)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE6.index, axis=0)\n\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Hernia']\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES_INTE7.head(110)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE7.index, axis=0)\n\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Infiltration']\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES_INTE8.head(8547)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE8.index, axis=0)\n\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Mass']\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES_INTE9.head(1139)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE9.index, axis=0)\n\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'No Finding']\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES_INTE10.head(59361)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE10.index, axis=0)\n\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Nodule']\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES_INTE11.head(1705)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE11.index, axis=0)\n\n#DF_LUNG_DISEASES_INTE12 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Pneumonia']\n#DF_LUNG_DISEASES_INTE12 = DF_LUNG_DISEASES_INTE12.head(0)\n#DF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE12.index, axis=0)\n\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Pneumothorax']\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES_INTE13.head(1194)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE13.index, axis=0)\n\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nNAMES_JPG_1 = DF_LUNG_DISEASES['Image Index'].str.replace('.png', '.jpg')\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nlabelencorder_targets = LabelEncoder()\nDF_LUNG_DISEASES['Finding Labels'] = labelencorder_targets.fit_transform(DF_LUNG_DISEASES['Finding Labels'])\n\nonehotencorder = ColumnTransformer(transformers=[(\"OneHot\", OneHotEncoder(),[1])],remainder='passthrough')\npredictors = onehotencorder.fit_transform(DF_LUNG_DISEASES)\nclasses = predictors[:,0:9]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cla =  pd.DataFrame(classes)\ncla","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols = cla.columns.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i,colu in enumerate(cols):\n    DF_LUNG_DISEASES[colu] = cla[i]\nDF_LUNG_DISEASES","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES['diseases']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES.iloc[:,14:23]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES['Finding Labels'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR_1 = './images/DISEASES/images/'\nDIR_2 = './attention_images/Diseases/attention/'\n#IMAGES_ORIGINAL = list()\n#IMAGES_COLLIMATED = list()\nIMAGES_COLLIMATED = np.empty((len(NAMES_JPG_1), IMG_HEIGHT, IMG_WIDTH,1), dtype='float16')\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    #PATH1 = DIR_1 + NAMES_JPG_1.iloc[i]\n    #IMAGE1 = cv2.imread(os.path.join(PATH1),cv2.IMREAD_GRAYSCALE)\n    #IMAGES_ORIGINAL.append(IMAGE1)\n    #Change 1 or 2\n    PATH2 = DIR_1 + NAMES_JPG_1.iloc[i]\n    IMAGE2 = cv2.imread(os.path.join(PATH2),0)\n    IMAGE2 = cv2.resize(IMAGE2, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGES_COLLIMATED[i] = (np.asarray(IMAGE2).reshape((1, SIZE, SIZE, 1)).astype('float16')) / 255.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel IMAGE2\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/qubvel/classification_models.git\nfrom classification_models.tfkeras import Classifiers\nClassifiers.models_names()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    seresnext50, _ = Classifiers.get('seresnext50')\n    base = seresnext50(input_shape=(SIZE, SIZE, 3), include_top=False, weights='imagenet')\n    \n    input_tensor = Input(shape=(SIZE, SIZE,1))\n    x = Conv2D(3,(1,1),padding='same')(input_tensor)\n    out = base(x) \n    base_model = Model(inputs=input_tensor,outputs=out)\n    \n    #x= input_tensor(base_model)\n    #x= layers.GlobalAveragePooling2D()(layers.Dropout(0.16)(x))\n    #x= layers.Dropout(0.3)(x)\n    #model = layers.Dense(14, 'sigmoid')(x)\n    #model.summary()\n    \n    model = models.Sequential()\n    model.add(base_model)\n\n    model.add(layers.Dropout(0.16))\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.3))\n    #model.add(layers.Dense(256, activation='relu'))\n    #model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(9, activation='softmax'))\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nseresnext50, _ = Classifiers.get('seresnext50')\nbase = seresnext50(input_shape=(SIZE, SIZE, 3), include_top=False, weights='imagenet')\n\ninput_tensor = Input(shape=(SIZE, SIZE,1))\nx = Conv2D(3,(1,1),padding='same')(input_tensor)\nout = base(x) \nbase_model = Model(inputs=input_tensor,outputs=out)\n\n#x= input_tensor(base_model)\n#x= layers.GlobalAveragePooling2D()(layers.Dropout(0.16)(x))\n#x= layers.Dropout(0.3)(x)\n#model = layers.Dense(14, 'sigmoid')(x)\n#model.summary()\n\nmodel = models.Sequential()\nmodel.add(base_model)\n\nmodel.add(layers.Dropout(0.16))\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.3))\n#model.add(layers.Dense(256, activation='relu'))\n#model.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(9, activation='sigmoid'))\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom tensorflow.keras.applications import VGG16\nfrom keras.layers import *\nwith tpu_strategy.scope():\n    #img_size_target = 256\n    #img_input = Input(shape=(img_size_target, img_size_target, 1))\n    #img_conc = Concatenate()([img_input, img_input, img_input])\n    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n    \n    for layer in base_model.layers[:19]:\n        layer.trainable = False\n        \n    input_tensor = Input(shape=(SIZE, SIZE,1))\n    x = Conv2D(3,(3,3),padding='same')(input_tensor)\n    out = base_model (x) \n    base_model = Model(inputs=input_tensor,outputs=out)\n    base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nfrom tensorflow.keras.applications import ResNet50\nfrom keras.layers import *\nwith tpu_strategy.scope():\n    resnet = ResNet50(weights='imagenet',include_top= False) \n\n    input_tensor = Input(shape=(SIZE, SIZE,1))\n    x = Conv2D(3,(3,3),padding='same')(input_tensor)\n    out = resnet (x) \n    base_model = Model(inputs=input_tensor,outputs=out)\n    base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nwith tpu_strategy.scope():\n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.BatchNormalization())\n    model.add(layers.Flatten())\n    model.add(layers.Dense(1024, activation='relu'))\n    model.add(layers.Dropout(0.6))\n    model.add(layers.Dense(128, activation='relu'))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(14, activation='sigmoid'))\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\noptimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\nmodel.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=[tf.keras.metrics.AUC(multi_label=True)])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(IMAGES_COLLIMATED, DF_LUNG_DISEASES,train_size = 0.80,test_size=0.20, random_state=42)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_C_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_C_test.iloc[:,14:23]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_C_train.to_csv('df_train_val.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_C_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_F_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.asarray(y_C_train.iloc[:,14:23])[0].astype('int8').mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel IMAGES_COLLIMATED\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Callbacks: https://www.kaggle.com/akhileshdkapse/nih-x-ray-multilabel-classification-tpu-guide\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping \nname= 'NIH_seresnext50_model_256_no_col.h5'\nrlr = ReduceLROnPlateau(monitor = 'val_auc_1', factor = 0.1, patience = 3, verbose = 1, min_delta = 1e-4, min_lr = 1e-6, mode = 'max', cooldown=1)\nckp = ModelCheckpoint(name,monitor = 'val_auc_1',verbose = 1, save_best_only = True, mode = 'max')    \nes = EarlyStopping(monitor = 'val_auc_1', min_delta = 1e-4, patience =10, mode = 'max', restore_best_weights = True, verbose = 1)\nhistory = model.fit(IMAGES_COLLIMATED, np.asarray(DF_LUNG_DISEASES.iloc[:,14:23]).astype('float16'), batch_size = 8 * tpu_strategy.num_replicas_in_sync, epochs = 100, verbose = 1, validation_split=0.2,shuffle=True,callbacks=[rlr,es,ckp])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Callbacks: https://www.kaggle.com/akhileshdkapse/nih-x-ray-multilabel-classification-tpu-guide\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping \nname= 'NIH_seresnext50_model_256_no_col.h5'\nrlr = ReduceLROnPlateau(monitor = 'val_auc_5', factor = 0.1, patience = 3, verbose = 1, min_delta = 1e-4, min_lr = 1e-6, mode = 'max', cooldown=1)\nckp = ModelCheckpoint(name,monitor = 'val_auc_5',verbose = 1, save_best_only = True, mode = 'max')    \nes = EarlyStopping(monitor = 'val_auc_5', min_delta = 1e-4, patience =10, mode = 'max', restore_best_weights = True, verbose = 1)\nhistory = model.fit(X_F_train, np.asarray(y_C_train.iloc[:,14:23]).astype('int8'), batch_size =  19 * tpu_strategy.num_replicas_in_sync, epochs = 100, verbose = 1, validation_data = (X_F_test,np.asarray(y_C_test.iloc[:,14:23]).astype('int8')),shuffle=True,callbacks=[rlr,es,ckp])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES[\"Finding Labels\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils import class_weight\nclass_weights = class_weight.compute_class_weight('balanced', np.unique(np.argmax(np.asarray(y_C_train.iloc[:,14:23]), axis=1)), np.argmax(np.asarray(y_C_train.iloc[:,14:23].values), axis=1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_weights = dict(enumerate(class_weights))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Callbacks: https://www.kaggle.com/akhileshdkapse/nih-x-ray-multilabel-classification-tpu-guide\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping \nname= 'NIH_seresnext50_model_256_no_col.h5'\nrlr = ReduceLROnPlateau(monitor = 'val_auc', factor = 0.1, patience = 3, verbose = 1, min_delta = 1e-4, min_lr = 1e-6, mode = 'max', cooldown=1)\nckp = ModelCheckpoint(name,monitor = 'val_auc',verbose = 1, save_best_only = True, mode = 'max')    \nes = EarlyStopping(monitor = 'val_auc', min_delta = 1e-4, patience =10, mode = 'max', restore_best_weights = True, verbose = 1)\nhistory = model.fit(X_F_train, np.asarray(y_C_train.iloc[:,14:23]).astype('float16'), batch_size = 32, epochs = 100, verbose = 1, validation_data = (X_F_test,np.asarray(y_C_test.iloc[:,14:23]).astype('float16')),shuffle=True,class_weight=class_weights,callbacks=[rlr,es,ckp])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#validation_data = (X_F_test,np.asarray(y_C_test.iloc[:,14:23]).astype('float16'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_= tf.keras.models.load_model('./NIH_seresnext50_model_256_no_col.h5')\n#pred= model_.predict(X_F_test, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_.evaluate(X_F_test,np.asarray(y_C_test.iloc[:,14:28]).astype('float16')) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES['diseases'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES['Finding Labels'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_C_test.iloc[:,14:28].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_C_test['diseases'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del X_F_train\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_label_names = ['Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass','No Finding','Nodule','Pneumonia','Pneumothorax']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\n\npredictions = model_.predict(X_F_test,verbose =1) \ntest_Y = np.asarray(y_C_test.iloc[:,14:23]).astype('float16')\n\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor i, name in enumerate(new_label_names): \n    #for line in range(0,len(predictions)):\n    #    predictions[line][predictions[line]==max(predictions[line])] = 1\n    #    predictions[line][predictions[line]<max(predictions[line])] = 0\n    #class_test = [np.argmax(t) for t in test_Y]\n    #pred2 = [np.argmax(t) for t in predictions]\n    fpr, tpr, thresholds = roc_curve(test_Y[:,i].astype(int), predictions[:,i])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (name, auc(fpr, tpr)))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('quick_trained_model_128_col.png')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.argmax(predictions.round(),axis = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_Y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\n\nconfusion_matrix = confusion_matrix(np.argmax(test_Y,axis=1), np.argmax(predictions.round(),axis = 1))\nsn.heatmap(confusion_matrix, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    seresnext50, _ = Classifiers.get('seresnext50')\n    base = seresnext50(input_shape=(SIZE, SIZE, 3), include_top=False, weights='imagenet')\n    \n    input_tensor = Input(shape=(SIZE, SIZE,1))\n    x = Conv2D(3,(3,3),padding='same')(input_tensor)\n    out = base(x) \n    base_model = Model(inputs=input_tensor,outputs=out)\n    \n    #x= input_tensor(base_model)\n    #x= layers.GlobalAveragePooling2D()(layers.Dropout(0.16)(x))\n    #x= layers.Dropout(0.3)(x)\n    #model = layers.Dense(14, 'sigmoid')(x)\n    #model.summary()\n    \n    model = models.Sequential()\n    model.add(base_model)\n    model.add(layers.Dropout(0.16))\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.3))\n    #model.add(layers.Dense(256, activation='relu'))\n    #model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(14, activation='sigmoid'))\n    model.summary()\n\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=[tf.keras.metrics.AUC(multi_label=True)])\nX_F_train, X_F_test, y_C_train, y_C_test = train_test_split(IMAGES_COLLIMATED, DF_LUNG_DISEASES,train_size = 0.80,test_size=0.20, random_state=42)\n\n#Callbacks: https://www.kaggle.com/akhileshdkapse/nih-x-ray-multilabel-classification-tpu-guide\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping \nname= 'NIH_seresnext50_model_128_no_col.h5'\nrlr = ReduceLROnPlateau(monitor = 'val_auc', factor = 0.1, patience = 3, verbose = 1, min_delta = 1e-4, min_lr = 1e-6, mode = 'max', cooldown=1)\nckp = ModelCheckpoint(name,monitor = 'val_auc',verbose = 1, save_best_only = True, mode = 'max')    \nes = EarlyStopping(monitor = 'val_auc', min_delta = 1e-4, patience =10, mode = 'max', restore_best_weights = True, verbose = 1)\nhistory = model.fit(X_F_train, np.asarray(y_C_train.iloc[:,14:28]).astype('float16'), batch_size = 8 * tpu_strategy.num_replicas_in_sync, epochs = 100, verbose = 1, validation_data = (X_F_test,np.asarray(y_C_test.iloc[:,14:28]).astype('float16')),shuffle=True,callbacks=[rlr,es,ckp])\n\nnew_label_names = ['Atelectasis','Cardiomegaly','Consolidation','Edema','Effusion','Emphysema','Fibrosis','Hernia','Infiltration','Mass','No Finding','Nodule','Pneumonia','Pneumothorax']\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\n\npredictions = model_.predict(X_F_test,verbose =1) \ntest_Y = np.asarray(y_C_test.iloc[:,14:28]).astype('float16')\n\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor i, name in enumerate(new_label_names): \n    #for line in range(0,len(predictions)):\n    #    predictions[line][predictions[line]==max(predictions[line])] = 1\n    #    predictions[line][predictions[line]<max(predictions[line])] = 0\n    #class_test = [np.argmax(t) for t in test_Y]\n    #pred2 = [np.argmax(t) for t in predictions]\n    fpr, tpr, thresholds = roc_curve(test_Y[:,i].astype(int), predictions[:,i])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (name, auc(fpr, tpr)))\n\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('quick_trained_model_128_no_col.png')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve(test_Y[:,i].astype(int), predictions[:,i].astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_Y[:,i].astype(int)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions[0][predictions[0]<max(predictions[0])] = 0\npredictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"roc_curve(test_Y[:,i].astype(int), predictions[:,i].astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr, tpr, thresholds = roc_curve(np.squeeze(test_Y[:,[i]].astype(int)), np.squeeze(predictions[:,[i]].astype(int)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('oi')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.squeeze(test_Y[:,0].astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.squeeze(predictions[:,0].astype(int))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = (pred > 0.5)\nclass_test = [np.argmax(t) for t in X_F_test]\npred2 = [np.argmax(t) for t in pred]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 13. Structuring gridsearch and crossvalidation applied to classification ","metadata":{}},{"cell_type":"code","source":"SIZE = 256\nCHANNELS = 1\n\nIMG_HEIGHT, IMG_WIDTH = 256,256\nSEED=1\nNUM_SAMPLES = 4000\nBATCH_SIZE = 1\nEPOCHS = 100\n\nDF_LUNG_DISEASES=pd.read_csv(\"../input/data/Data_Entry_2017.csv\")\nLUNG_DISEASES_DIR = os.path.join('../input/data')\n\nlabel_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",'No Finding',\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]\nDF_LUNG_DISEASES['diseases'] = DF_LUNG_DISEASES['Finding Labels']\nDF_LUNG_DISEASES['diseases'].value_counts()\ndisease_of_interest = list()\nfor i in tqdm(range(0,DF_LUNG_DISEASES[\"Finding Labels\"].count())):\n    if DF_LUNG_DISEASES[\"Finding Labels\"].iloc[i] in label_names:\n        class_ = 1\n    else:\n        class_ = 0 \n    disease_of_interest.append(class_)\n    \nDF_LUNG_DISEASES['disease_of_interest'] = disease_of_interest\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['disease_of_interest'] == 0 ]\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\n\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Atelectasis']\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES_INTE0.head(3215)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE0.index, axis=0)\n\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Cardiomegaly']\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES_INTE1.head(93)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE1.index, axis=0)\n\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Consolidation']\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES_INTE2.head(1310)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE2.index, axis=0)\n\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Edema']\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES_INTE3.head(628)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE3.index, axis=0)\n\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Effusion']\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES_INTE4.head(2955)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE4.index, axis=0)\n\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Emphysema']\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES_INTE5.head(892)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE5.index, axis=0)\n\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Fibrosis']\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES_INTE6.head(727)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE6.index, axis=0)\n\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Hernia']\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES_INTE7.head(110)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE7.index, axis=0)\n\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Infiltration']\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES_INTE8.head(8547)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE8.index, axis=0)\n\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Mass']\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES_INTE9.head(1139)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE9.index, axis=0)\n\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'No Finding']\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES_INTE10.head(59361)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE10.index, axis=0)\n\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Nodule']\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES_INTE11.head(1705)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE11.index, axis=0)\n\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Pneumothorax']\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES_INTE13.head(1194)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE13.index, axis=0)\n\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nNAMES_JPG_1 = DF_LUNG_DISEASES['Image Index'].str.replace('.png', '.jpg')\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nlabelencorder_targets = LabelEncoder()\nDF_LUNG_DISEASES['Finding Labels'] = labelencorder_targets.fit_transform(DF_LUNG_DISEASES['Finding Labels'])\n\nonehotencorder = ColumnTransformer(transformers=[(\"OneHot\", OneHotEncoder(),[1])],remainder='passthrough')\npredictors = onehotencorder.fit_transform(DF_LUNG_DISEASES)\nclasses = predictors[:,0:9]\ncla =  pd.DataFrame(classes)\ncols = cla.columns.values\n\nfor i,colu in enumerate(cols):\n    DF_LUNG_DISEASES[colu] = cla[i]\nDF_LUNG_DISEASES\n\nDIR_1 = './images/DISEASES/images/'\nDIR_2 = './attention_images/Diseases/attention/'\n\ndependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model_autoencoder = load_model('../input/autoencoder-supression-300-epochs/Autoencoder_300_Xnet_supression_LearningRateScheduler (1).h5', custom_objects=dependencies)\nloaded_model_autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\n\n#IMAGES_ORIGINAL = list()\n#IMAGES_COLLIMATED = list()\nIMAGES_COLLIMATED = np.empty((len(NAMES_JPG_1), IMG_HEIGHT, IMG_WIDTH,1), dtype='float16')\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    #PATH1 = DIR_1 + NAMES_JPG_1.iloc[i]\n    #IMAGE1 = cv2.imread(os.path.join(PATH1),cv2.IMREAD_GRAYSCALE)\n    #IMAGES_ORIGINAL.append(IMAGE1)\n    #Change 1, 2 or 3\n    PATH2 = DIR_1 + NAMES_JPG_1.iloc[i]\n    IMAGE2 = cv2.imread(os.path.join(PATH2),0)\n    IMAGE2 = cv2.equalizeHist(IMAGE2)\n    IMAGE2 = (np.asarray(IMAGE2).reshape(1,SIZE, SIZE, CHANNELS).astype('float16')) / 255\n    IMAGE2 = loaded_model_autoencoder.predict(IMAGE2.astype(np.float16))\n    IMAGE2 = np.squeeze(IMAGE2.astype(np.float32))\n    IMAGE2 = cv2.resize(IMAGE2, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    #IMAGE2 = cv2.equalizeHist(IMAGE2)\n    IMAGES_COLLIMATED[i] = (np.asarray(IMAGE2).reshape((1, SIZE, SIZE, 1)).astype('float16'))\n    #/ 255.\n    #number = 0\n    #fig, ax = plt.subplots(1,1, figsize = (8,4))\n    #plt.imshow(IMAGE2, cmap='gray')\n    #plt.show()\n    \nos.makedirs('./DISEASES_supre/')\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    im = np.squeeze(IMAGES_COLLIMATED[i].astype(np.float32))\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    plt.imsave('./DISEASES_supre/'+ str(NAMES_JPG_1.iloc[i]),im, cmap = 'gray')\n\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n#tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n!pip install git+https://github.com/qubvel/classification_models.git\nfrom classification_models.tfkeras import Classifiers\n\n#X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(IMAGES_COLLIMATED, DF_LUNG_DISEASES,train_size = 0.80,test_size=0.20, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-09-16T00:29:12.701598Z","iopub.status.idle":"2021-09-16T00:29:12.70202Z","shell.execute_reply.started":"2021-09-16T00:29:12.701763Z","shell.execute_reply":"2021-09-16T00:29:12.701789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,1, figsize = (8,4))\nplt.imshow(IMAGE2, cmap='gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-16T00:29:12.703494Z","iopub.status.idle":"2021-09-16T00:29:12.703932Z","shell.execute_reply.started":"2021-09-16T00:29:12.703671Z","shell.execute_reply":"2021-09-16T00:29:12.703695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\n \nfantasy_zip = zipfile.ZipFile('./DISEASES_supre.zip', 'w')\n \nfor folder, subfolders, files in os.walk('./DISEASES_supre'):\n \n    for file in files:\n        if file.endswith('.jpg'):\n            fantasy_zip.write(os.path.join(folder, file), os.path.relpath(os.path.join(folder,file), './DISEASES'), compress_type = zipfile.ZIP_DEFLATED)\n \nfantasy_zip.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# New beginning","metadata":{}},{"cell_type":"code","source":"with zipfile.ZipFile(\"../input/supre2/DISEASES_supre.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(\"DISEASES_supre\")","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:41:25.029074Z","iopub.execute_input":"2021-10-09T15:41:25.029448Z","iopub.status.idle":"2021-10-09T15:41:27.554784Z","shell.execute_reply.started":"2021-10-09T15:41:25.029404Z","shell.execute_reply":"2021-10-09T15:41:27.554132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 256\nCHANNELS = 1\n\nIMG_HEIGHT, IMG_WIDTH = 256,256\nSEED=1\nNUM_SAMPLES = 4000\nBATCH_SIZE = 1\nEPOCHS = 100\n\nDF_LUNG_DISEASES=pd.read_csv(\"../input/data/Data_Entry_2017.csv\")\nLUNG_DISEASES_DIR = os.path.join('../input/data')\n\nlabel_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",'No Finding',\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]\nDF_LUNG_DISEASES['diseases'] = DF_LUNG_DISEASES['Finding Labels']\nDF_LUNG_DISEASES['diseases'].value_counts()\ndisease_of_interest = list()\nfor i in tqdm(range(0,DF_LUNG_DISEASES[\"Finding Labels\"].count())):\n    if DF_LUNG_DISEASES[\"Finding Labels\"].iloc[i] in label_names:\n        class_ = 1\n    else:\n        class_ = 0 \n    disease_of_interest.append(class_)\n    \nDF_LUNG_DISEASES['disease_of_interest'] = disease_of_interest\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['disease_of_interest'] == 0 ]\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\n\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Atelectasis']\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES_INTE0.head(3215)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE0.index, axis=0)\n\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Cardiomegaly']\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES_INTE1.head(93)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE1.index, axis=0)\n\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Consolidation']\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES_INTE2.head(1310)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE2.index, axis=0)\n\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Edema']\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES_INTE3.head(628)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE3.index, axis=0)\n\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Effusion']\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES_INTE4.head(2955)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE4.index, axis=0)\n\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Emphysema']\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES_INTE5.head(892)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE5.index, axis=0)\n\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Fibrosis']\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES_INTE6.head(727)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE6.index, axis=0)\n\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Hernia']\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES_INTE7.head(110)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE7.index, axis=0)\n\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Infiltration']\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES_INTE8.head(8547)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE8.index, axis=0)\n\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Mass']\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES_INTE9.head(1139)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE9.index, axis=0)\n\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'No Finding']\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES_INTE10.head(59361)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE10.index, axis=0)\n\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Nodule']\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES_INTE11.head(1705)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE11.index, axis=0)\n\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Pneumothorax']\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES_INTE13.head(1194)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE13.index, axis=0)\n\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nNAMES_JPG_1 = DF_LUNG_DISEASES['Image Index'].str.replace('.png', '.jpg')\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nlabelencorder_targets = LabelEncoder()\nDF_LUNG_DISEASES['Finding Labels'] = labelencorder_targets.fit_transform(DF_LUNG_DISEASES['Finding Labels'])\n\nonehotencorder = ColumnTransformer(transformers=[(\"OneHot\", OneHotEncoder(),[1])],remainder='passthrough')\npredictors = onehotencorder.fit_transform(DF_LUNG_DISEASES)\nclasses = predictors[:,0:9]\ncla =  pd.DataFrame(classes)\ncols = cla.columns.values\n\nfor i,colu in enumerate(cols):\n    DF_LUNG_DISEASES[colu] = cla[i]\nDF_LUNG_DISEASES\n\nDIR_1 = './images/DISEASES/images/'\nDIR_2 = './attention_images/Diseases/attention/'\nDIR_3 = './DISEASES_supre/DISEASES_supre/'\n#IMAGES_ORIGINAL = list()\n#IMAGES_COLLIMATED = list()\nIMAGES_COLLIMATED = np.empty((len(NAMES_JPG_1), IMG_HEIGHT, IMG_WIDTH,1), dtype='float16')\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    #PATH1 = DIR_1 + NAMES_JPG_1.iloc[i]\n    #IMAGE1 = cv2.imread(os.path.join(PATH1),cv2.IMREAD_GRAYSCALE)\n    #IMAGES_ORIGINAL.append(IMAGE1)\n    #Change 1 or 2\n    PATH2 = DIR_3 + NAMES_JPG_1.iloc[i]\n    IMAGE2 = cv2.imread(os.path.join(PATH2),0)\n    #IMAGE2 = np.squeeze(IMAGE2.astype(np.float32))\n    IMAGE2 = cv2.resize(IMAGE2, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGES_COLLIMATED[i] = (np.asarray(IMAGE2).reshape((1, SIZE, SIZE, 1)).astype('float16')) / 255.\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n!pip install git+https://github.com/qubvel/classification_models.git\nfrom classification_models.tfkeras import Classifiers\n\n#X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(IMAGES_COLLIMATED, DF_LUNG_DISEASES,train_size = 0.80,test_size=0.20, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-09-28T20:48:17.492672Z","iopub.execute_input":"2021-09-28T20:48:17.492928Z","iopub.status.idle":"2021-09-28T20:48:51.236714Z","shell.execute_reply.started":"2021-09-28T20:48:17.492891Z","shell.execute_reply":"2021-09-28T20:48:51.235663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF_LUNG_DISEASES=pd.read_csv(\"../input/data/Data_Entry_2017.csv\")\nLUNG_DISEASES_DIR = os.path.join('../input/data')\n\nlabel_names = [\"Atelectasis\",\"Cardiomegaly\",\"Effusion\",\"Infiltration\",\"Mass\",\"Nodule\",'No Finding',\"Pneumonia\",\"Pneumothorax\",\"Consolidation\",\"Edema\",\"Emphysema\",\"Fibrosis\",\"Pleural Thickening\",\"Hernia\"]\nDF_LUNG_DISEASES['diseases'] = DF_LUNG_DISEASES['Finding Labels']\nDF_LUNG_DISEASES['diseases'].value_counts()\ndisease_of_interest = list()\nfor i in tqdm(range(0,DF_LUNG_DISEASES[\"Finding Labels\"].count())):\n    if DF_LUNG_DISEASES[\"Finding Labels\"].iloc[i] in label_names:\n        class_ = 1\n    else:\n        class_ = 0 \n    disease_of_interest.append(class_)\n    \nDF_LUNG_DISEASES['disease_of_interest'] = disease_of_interest\nDF_LUNG_DISEASES_INTE = DF_LUNG_DISEASES[DF_LUNG_DISEASES['disease_of_interest'] == 0 ]\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE.index, axis=0)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\n\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Atelectasis']\nDF_LUNG_DISEASES_INTE0 = DF_LUNG_DISEASES_INTE0.head(3215)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE0.index, axis=0)\n\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Cardiomegaly']\nDF_LUNG_DISEASES_INTE1 = DF_LUNG_DISEASES_INTE1.head(93)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE1.index, axis=0)\n\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Consolidation']\nDF_LUNG_DISEASES_INTE2 = DF_LUNG_DISEASES_INTE2.head(1310)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE2.index, axis=0)\n\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Edema']\nDF_LUNG_DISEASES_INTE3 = DF_LUNG_DISEASES_INTE3.head(628)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE3.index, axis=0)\n\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Effusion']\nDF_LUNG_DISEASES_INTE4 = DF_LUNG_DISEASES_INTE4.head(2955)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE4.index, axis=0)\n\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Emphysema']\nDF_LUNG_DISEASES_INTE5 = DF_LUNG_DISEASES_INTE5.head(892)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE5.index, axis=0)\n\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Fibrosis']\nDF_LUNG_DISEASES_INTE6 = DF_LUNG_DISEASES_INTE6.head(727)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE6.index, axis=0)\n\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Hernia']\nDF_LUNG_DISEASES_INTE7 = DF_LUNG_DISEASES_INTE7.head(110)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE7.index, axis=0)\n\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Infiltration']\nDF_LUNG_DISEASES_INTE8 = DF_LUNG_DISEASES_INTE8.head(8547)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE8.index, axis=0)\n\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Mass']\nDF_LUNG_DISEASES_INTE9 = DF_LUNG_DISEASES_INTE9.head(1139)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE9.index, axis=0)\n\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'No Finding']\nDF_LUNG_DISEASES_INTE10 = DF_LUNG_DISEASES_INTE10.head(59361)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE10.index, axis=0)\n\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Nodule']\nDF_LUNG_DISEASES_INTE11 = DF_LUNG_DISEASES_INTE11.head(1705)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE11.index, axis=0)\n\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES[DF_LUNG_DISEASES['Finding Labels'] == 'Pneumothorax']\nDF_LUNG_DISEASES_INTE13 = DF_LUNG_DISEASES_INTE13.head(1194)\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.drop(DF_LUNG_DISEASES_INTE13.index, axis=0)\n\nDF_LUNG_DISEASES = DF_LUNG_DISEASES.reset_index(drop=True)\nNAMES_JPG_1 = DF_LUNG_DISEASES['Image Index'].str.replace('.png', '.jpg')\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn.compose import ColumnTransformer\n\nlabelencorder_targets = LabelEncoder()\nDF_LUNG_DISEASES['Finding Labels'] = labelencorder_targets.fit_transform(DF_LUNG_DISEASES['Finding Labels'])\n\nonehotencorder = ColumnTransformer(transformers=[(\"OneHot\", OneHotEncoder(),[1])],remainder='passthrough')\npredictors = onehotencorder.fit_transform(DF_LUNG_DISEASES)\nclasses = predictors[:,0:9]\ncla =  pd.DataFrame(classes)\ncols = cla.columns.values\n\nfor i,colu in enumerate(cols):\n    DF_LUNG_DISEASES[colu] = cla[i]\nDF_LUNG_DISEASES\n\nDIR_1 = './images/DISEASES/images/'\nDIR_2 = './attention_images/Diseases/attention/'\nDIR_3 = './DISEASES_supre/DISEASES_supre/'\n#IMAGES_ORIGINAL = list()\n#IMAGES_COLLIMATED = list()\nIMAGES_COLLIMATED = np.empty((len(NAMES_JPG_1), IMG_HEIGHT, IMG_WIDTH,1), dtype='float16')\nfor i in tqdm(range(0,len(NAMES_JPG_1))):\n    #PATH1 = DIR_1 + NAMES_JPG_1.iloc[i]\n    #IMAGE1 = cv2.imread(os.path.join(PATH1),cv2.IMREAD_GRAYSCALE)\n    #IMAGES_ORIGINAL.append(IMAGE1)\n    #Change 1 or 2\n    PATH2 = DIR_1 + NAMES_JPG_1.iloc[i]\n    IMAGE2 = cv2.imread(os.path.join(PATH2),0)\n    #IMAGE2 = np.squeeze(IMAGE2.astype(np.float32))\n    IMAGE2 = cv2.resize(IMAGE2, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGES_COLLIMATED[i] = (np.asarray(IMAGE2).reshape((1, SIZE, SIZE, 1)).astype('float16')) / 255.\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\n!pip install git+https://github.com/qubvel/classification_models.git\nfrom classification_models.tfkeras import Classifiers\n\n#X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(IMAGES_COLLIMATED, DF_LUNG_DISEASES,train_size = 0.80,test_size=0.20, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:41:27.556589Z","iopub.execute_input":"2021-10-09T15:41:27.557063Z","iopub.status.idle":"2021-10-09T15:41:54.558259Z","shell.execute_reply.started":"2021-10-09T15:41:27.557029Z","shell.execute_reply":"2021-10-09T15:41:54.55705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\nfig, ax = plt.subplots(1,1, figsize = (8,4))\nplt.imshow(IMAGE2, cmap='gray')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:41:54.559635Z","iopub.execute_input":"2021-10-09T15:41:54.559861Z","iopub.status.idle":"2021-10-09T15:41:54.811687Z","shell.execute_reply.started":"2021-10-09T15:41:54.559834Z","shell.execute_reply":"2021-10-09T15:41:54.811045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Normal","metadata":{}},{"cell_type":"code","source":"with tpu_strategy.scope():\n    seresnext50, _ = Classifiers.get('seresnext50')\n    base = seresnext50(input_shape=(SIZE, SIZE, 3), include_top=False, weights='imagenet')\n    \n    input_tensor = Input(shape=(SIZE, SIZE,1))\n    x = Conv2D(3,(1,1),padding='same')(input_tensor)\n    out = base(x) \n    base_model = Model(inputs=input_tensor,outputs=out)\n    \n    model = models.Sequential()\n    model.add(base_model)\n\n    model.add(layers.Dropout(0.16))\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.3))\n    #model.add(layers.Dense(256, activation='relu'))\n    #model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(9, activation='softmax'))\n    model.summary()\n\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=1e-2,\n    decay_steps=10000,\n    decay_rate=0.9)\noptimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[tf.keras.metrics.AUC(multi_label=True)])\n","metadata":{"execution":{"iopub.status.busy":"2021-09-13T21:53:16.768557Z","iopub.status.idle":"2021-09-13T21:53:16.769359Z","shell.execute_reply.started":"2021-09-13T21:53:16.769067Z","shell.execute_reply":"2021-09-13T21:53:16.769096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Callbacks: https://www.kaggle.com/akhileshdkapse/nih-x-ray-multilabel-classification-tpu-guide\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,ModelCheckpoint,EarlyStopping \nname= 'NIH_seresnext50_model_256_no_col.h5'\nrlr = ReduceLROnPlateau(monitor = 'val_auc_2', factor = 0.1, patience = 3, verbose = 1, min_delta = 1e-4, min_lr = 1e-6, mode = 'max', cooldown=1)\nckp = ModelCheckpoint(name,monitor = 'val_auc_2',verbose = 1, save_best_only = True, mode = 'max')    \nes = EarlyStopping(monitor = 'val_auc_2', min_delta = 1e-4, patience =10, mode = 'max', restore_best_weights = True, verbose = 1)\nhistory = model.fit(X_F_train, np.asarray(y_C_train.iloc[:,14:23]).astype('float16'), batch_size =  19 * tpu_strategy.num_replicas_in_sync, epochs = 100, verbose = 1, validation_data = (X_F_test,np.asarray(y_C_test.iloc[:,14:23]).astype('float16')),shuffle=True,callbacks=[rlr,es,ckp])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cross validation","metadata":{}},{"cell_type":"code","source":"ppr = [0] * 10\nfor i in range(10):\n    ppr[i] = [0] * 9\nppr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#fpr[j][i] \nppr[0][6] = 2\nppr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\nppr_ = np.array(ppr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ppr_[:,6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ppr_[:,6].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ppr_[0][6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install np_utils","metadata":{"execution":{"iopub.status.busy":"2021-09-14T01:44:17.769407Z","iopub.status.idle":"2021-09-14T01:44:17.769896Z","shell.execute_reply.started":"2021-09-14T01:44:17.769628Z","shell.execute_reply":"2021-09-14T01:44:17.769652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from tensorflow.keras.utils import np_utils\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import roc_auc_score\n\nkfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)\nresultados = []\nj = 0\n\nfpr = [0] * 10\nfor i in range(10):\n    fpr[i] = [0] * 9\n    \ntpr = [0] * 10\nfor i in range(10):\n    tpr[i] = [0] * 9\n\ndef Average(lst):\n    return sum(lst) / len(lst)\n\nfor train_index, test_index in kfold.split(IMAGES_COLLIMATED,np.zeros(shape = (IMAGES_COLLIMATED.shape[0],1))):\n    \n    with tpu_strategy.scope():\n        seresnext50, _ = Classifiers.get('seresnext50')\n        base = seresnext50(input_shape=(SIZE, SIZE, 3), include_top=False, weights='imagenet')\n        input_tensor = Input(shape=(SIZE, SIZE,1))\n        x = Conv2D(3,(1,1),padding='same')(input_tensor)\n        out = base(x) \n        base_model = Model(inputs=input_tensor,outputs=out)\n        model = models.Sequential()\n        model.add(base_model)\n        model.add(layers.Dropout(0.16))\n        model.add(layers.GlobalAveragePooling2D())\n        model.add(layers.Dropout(0.3))\n        model.add(layers.Dense(9, activation='softmax'))\n        model.summary()\n\n    model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=[tf.keras.metrics.AUC(multi_label=True)])\n    \n    if j == 0:\n        k = 'val_auc'\n    else:\n        k = 'val_auc_'+str(j)\n    \n    name= 'NIH_seresnext50_model_256_no_col.h5'\n    rlr = ReduceLROnPlateau(monitor = k, factor = 0.1, patience = 3, verbose = 1, min_delta = 1e-4, min_lr = 1e-6, mode = 'max', cooldown=1)\n    ckp = ModelCheckpoint(name,monitor = k,verbose = 1, save_best_only = True, mode = 'max')    \n    es = EarlyStopping(monitor = k, min_delta = 1e-4, patience =10, mode = 'max', restore_best_weights = True, verbose = 1)\n    history = model.fit(IMAGES_COLLIMATED[train_index], np.asarray(DF_LUNG_DISEASES.iloc[:,14:23])[train_index].astype('int8'), batch_size = 128, epochs = 100, validation_data = (IMAGES_COLLIMATED[test_index], np.asarray(DF_LUNG_DISEASES.iloc[:,14:23])[test_index].astype('int8')),callbacks=[rlr,es,ckp])\n    \n    model_= tf.keras.models.load_model('./NIH_seresnext50_model_256_no_col.h5')\n    precision = model_.evaluate(IMAGES_COLLIMATED[test_index], np.asarray(DF_LUNG_DISEASES.iloc[:,14:23])[test_index].astype('int8'), batch_size = 128)\n    new_label_names = ['Atelectasis','Cardiomegaly','Effusion','Infiltration','Mass','No Finding','Nodule','Pneumonia','Pneumothorax']\n    predictions = model_.predict(IMAGES_COLLIMATED[test_index]) \n\n    for i, name in enumerate(new_label_names): \n        fpr[j][i], tpr[j][i], thresholds = roc_curve(np.asarray(DF_LUNG_DISEASES.iloc[:,14:23])[test_index].astype('int8')[:,i].astype(int), predictions[:,i])\n\n    resultados.append(precision[1])\n    j += 1","metadata":{"execution":{"iopub.status.busy":"2021-10-09T15:41:54.813211Z","iopub.execute_input":"2021-10-09T15:41:54.813437Z","iopub.status.idle":"2021-10-09T17:27:34.964697Z","shell.execute_reply.started":"2021-10-09T15:41:54.813411Z","shell.execute_reply":"2021-10-09T17:27:34.961735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resultados","metadata":{"execution":{"iopub.status.busy":"2021-10-09T17:27:34.969571Z","iopub.execute_input":"2021-10-09T17:27:34.9698Z","iopub.status.idle":"2021-10-09T17:27:34.978132Z","shell.execute_reply.started":"2021-10-09T17:27:34.969775Z","shell.execute_reply":"2021-10-09T17:27:34.977002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/vbookshelf/play-audio-read-the-files-create-a-spectrogram\n\nfrom pydub import AudioSegment\nimport IPython\n\npath = '../input/alarm-sound/Alarm_Slow_A1_fesliyanstudios.mp3'\n\nIPython.display.Audio(path, autoplay=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-25T15:47:38.636935Z","iopub.execute_input":"2021-09-25T15:47:38.637381Z","iopub.status.idle":"2021-09-25T15:47:38.90042Z","shell.execute_reply.started":"2021-09-25T15:47:38.637313Z","shell.execute_reply":"2021-09-25T15:47:38.899433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testes","metadata":{}},{"cell_type":"code","source":"fpr_[3,0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_ = np.array(fpr)\ntpr_ = np.array(tpr)\n\nfpr_m = [0]*9\ntpr_m = [0]*9\n\nfor j in range(9):\n    fpr_m[j] = fpr_[:,j].mean()\n    tpr_m[j] = tpr_[:,j].mean()\n    \nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor j in range(1):\n    for i, name in enumerate(new_label_names):\n        c_ax.plot(fpr_m[j][i], tpr_m[j][i], label = '%s (AUC:%0.2f)'  % (name, auc(fpr_m[j][i], tpr_m[j][i])))\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    fig.savefig('quick_trained_model_256_no_col_1.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resultados","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grid (memory error)","metadata":{}},{"cell_type":"code","source":"def network(type_network):    \n    K.clear_session()\n    with tpu_strategy.scope():\n        net, _ = Classifiers.get(type_network)\n        base = net(input_shape=(SIZE, SIZE, 3), include_top=False, weights='imagenet')\n\n        input_tensor = Input(shape=(SIZE, SIZE,1))\n        x = Conv2D(3,(1,1),padding='same')(input_tensor)\n        out = base(x) \n        base_model = Model(inputs=input_tensor,outputs=out)\n\n        model = models.Sequential()\n        model.add(base_model)\n\n        model.add(layers.Dropout(0.16))\n        model.add(layers.GlobalAveragePooling2D())\n        model.add(layers.Dropout(0.3))\n        #model.add(layers.Dense(256, activation='relu'))\n        #model.add(layers.Dropout(0.5))\n        model.add(layers.Dense(9, activation='softmax'))\n        model.summary()\n\n    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n        initial_learning_rate=1e-2,\n        decay_steps=10000,\n        decay_rate=0.9)\n    optimizer = keras.optimizers.SGD(learning_rate=lr_schedule)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[tf.keras.metrics.AUC(multi_label=True)])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nclassifier = KerasClassifier(build_fn = network)\nparameters = {'batch_size': [19 * tpu_strategy.num_replicas_in_sync], 'epochs': [10],'type_network':['resnet18','resnet34']}\ngrid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = tf.keras.metrics.AUC(multi_label=True), cv = 2)\ngrid_search = grid_search.fit(IMAGES_COLLIMATED, np.asarray(DF_LUNG_DISEASES.iloc[:,14:23]).astype('float16'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(grid_search.cv_results_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"PATH2PATH2os.path.join(PATH2)","metadata":{}},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./Diseases')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}