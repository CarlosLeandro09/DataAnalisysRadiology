{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Importing relevant packages for neural networks","metadata":{}},{"cell_type":"code","source":"import os \nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dropout, Conv2D, MaxPooling2D, concatenate, Reshape, Conv2DTranspose, LeakyReLU, BatchNormalization, Activation, UpSampling2D \nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import models \nfrom tensorflow.keras import backend as K\nfrom keras.callbacks import History \nfrom tensorflow.keras.applications import VGG19\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Assigning a seed","metadata":{}},{"cell_type":"code","source":"seed = 0 \nrandom.seed = seed\nnp.random.seed = seed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Defining variables","metadata":{}},{"cell_type":"code","source":"SIZE = 256\nCHANNELS = 1\nCHANNELS_3C = 3\nDATADIR_IMAGES = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_images/'\nDATADIR_MASKS = '../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/png_masks/'\nDF_TEST = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_test_images.csv')\nDF_TRAIN = pd.read_csv('../input/pneumothorax-chest-xray-images-and-masks/siim-acr-pneumothorax/stage_1_train_images.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Separating test and training groups","metadata":{}},{"cell_type":"markdown","source":"I. Let's consult and assign the size of the groups","metadata":{}},{"cell_type":"code","source":"LEN_TRAIN_NO_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 0].shape[0]\nLEN_TRAIN_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 1].shape[0]\nLEN_TEST_NO_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 0].shape[0]\nLEN_TEST_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 1].shape[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"II. Defining empty lists for segmentation and classification tasks","metadata":{}},{"cell_type":"code","source":"IMAGE_TRAIN_PNEUMO = list()\nIMAGE_TRAIN_NO_PNEUMO = list()\nIMAGE_TEST_PNEUMO = list()\nIMAGE_TEST_NO_PNEUMO = list()\nMASKS_TRAIN_PNEUMO = list()\nMASKS_TRAIN_NO_PNEUMO = list()\nMASKS_TEST_PNEUMO = list()\nMASKS_TEST_NO_PNEUMO = list()\nCLASS_IMAGE_TRAIN_PNEUMO = list()\nCLASS_IMAGE_TRAIN_NO_PNEUMO = list()\nCLASS_IMAGE_TEST_PNEUMO = list()\nCLASS_IMAGE_TEST_NO_PNEUMO = list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Loading data","metadata":{}},{"cell_type":"markdown","source":"I. Train group with pneumothorax","metadata":{}},{"cell_type":"code","source":"for i in tqdm(range(0,int(LEN_TRAIN_PNEUMO))):\n    DF_TRAIN_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 1]\n    IMAGE_NAME = DF_TRAIN_PNEUMO.iloc[i,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    PATH_MASKS = DATADIR_MASKS + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    masks = cv2.imread(os.path.join(PATH_MASKS),cv2.IMREAD_GRAYSCALE) \n    masks = cv2.resize(masks, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGE_TRAIN_PNEUMO.append(image)\n    MASKS_TRAIN_PNEUMO.append(masks)\n    CLASS_IMAGE_TRAIN_PNEUMO.append(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"II. Train group without pneumothorax","metadata":{}},{"cell_type":"code","source":"for j in tqdm(range(0,int(LEN_TRAIN_PNEUMO))):\n    DF_TRAIN_NO_PNEUMO = DF_TRAIN[DF_TRAIN['has_pneumo'] == 0]\n    IMAGE_NAME = DF_TRAIN_NO_PNEUMO.iloc[j,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    PATH_MASKS = DATADIR_MASKS + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    masks = cv2.imread(os.path.join(PATH_MASKS),cv2.IMREAD_GRAYSCALE)\n    masks = cv2.resize(masks, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGE_TRAIN_NO_PNEUMO.append(image)\n    MASKS_TRAIN_NO_PNEUMO.append(masks)\n    CLASS_IMAGE_TRAIN_NO_PNEUMO.append(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"III. Test group with pneumothorax","metadata":{}},{"cell_type":"code","source":"for k in tqdm(range(0,int(LEN_TEST_PNEUMO))):\n    DF_TEST_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 1]\n    IMAGE_NAME = DF_TEST_PNEUMO.iloc[k,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    PATH_MASKS = DATADIR_MASKS + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    masks = cv2.imread(os.path.join(PATH_MASKS),cv2.IMREAD_GRAYSCALE) \n    masks = cv2.resize(masks, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGE_TEST_PNEUMO.append(image)\n    MASKS_TEST_PNEUMO.append(masks)\n    CLASS_IMAGE_TEST_PNEUMO.append(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"IV. Test group without pneumothorax","metadata":{}},{"cell_type":"code","source":"for l in tqdm(range(0,int(LEN_TEST_PNEUMO))):\n    DF_TEST_NO_PNEUMO = DF_TEST[DF_TEST['has_pneumo'] == 0]\n    IMAGE_NAME = DF_TEST_NO_PNEUMO.iloc[l,0]\n    PATH_IMAGES = DATADIR_IMAGES + IMAGE_NAME\n    PATH_MASKS = DATADIR_MASKS + IMAGE_NAME\n    image = cv2.imread(os.path.join(PATH_IMAGES),cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    masks = cv2.imread(os.path.join(PATH_MASKS),cv2.IMREAD_GRAYSCALE)\n    masks = cv2.resize(masks, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGE_TEST_NO_PNEUMO.append(image)\n    MASKS_TEST_NO_PNEUMO.append(masks)\n    CLASS_IMAGE_TEST_NO_PNEUMO.append(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Converting to numpy format, reshaping and normalizing to the range 0-1","metadata":{}},{"cell_type":"code","source":"IMAGE_TRAIN_PNEUMO = np.array(IMAGE_TRAIN_PNEUMO)\nIMAGE_TRAIN_PNEUMO = IMAGE_TRAIN_PNEUMO.reshape((len(IMAGE_TRAIN_PNEUMO), SIZE, SIZE, 1))\nIMAGE_TRAIN_PNEUMO = IMAGE_TRAIN_PNEUMO.astype('float16') / 255\n\nIMAGE_TRAIN_NO_PNEUMO = np.array(IMAGE_TRAIN_NO_PNEUMO)\nIMAGE_TRAIN_NO_PNEUMO = IMAGE_TRAIN_NO_PNEUMO.reshape((len(IMAGE_TRAIN_NO_PNEUMO), SIZE, SIZE, 1))\nIMAGE_TRAIN_NO_PNEUMO = IMAGE_TRAIN_NO_PNEUMO.astype('float16') / 255\n\nIMAGE_TEST_PNEUMO = np.array(IMAGE_TEST_PNEUMO)\nIMAGE_TEST_PNEUMO = IMAGE_TEST_PNEUMO.reshape((len(IMAGE_TEST_PNEUMO), SIZE, SIZE, 1))\nIMAGE_TEST_PNEUMO = IMAGE_TEST_PNEUMO.astype('float16') / 255\n\nIMAGE_TEST_NO_PNEUMO = np.array(IMAGE_TEST_NO_PNEUMO)\nIMAGE_TEST_NO_PNEUMO = IMAGE_TEST_NO_PNEUMO.reshape((len(IMAGE_TEST_NO_PNEUMO), SIZE, SIZE, 1))\nIMAGE_TEST_NO_PNEUMO = IMAGE_TEST_NO_PNEUMO.astype('float16') / 255\n\nMASKS_TRAIN_PNEUMO = np.array(MASKS_TRAIN_PNEUMO)\nMASKS_TRAIN_PNEUMO = MASKS_TRAIN_PNEUMO.reshape((len(MASKS_TRAIN_PNEUMO), SIZE, SIZE, 1))\nMASKS_TRAIN_PNEUMO = MASKS_TRAIN_PNEUMO.astype('float16') / 255\n\nMASKS_TRAIN_NO_PNEUMO = np.array(MASKS_TRAIN_NO_PNEUMO)\nMASKS_TRAIN_NO_PNEUMO = MASKS_TRAIN_NO_PNEUMO.reshape((len(MASKS_TRAIN_NO_PNEUMO), SIZE, SIZE, 1))\nMASKS_TRAIN_NO_PNEUMO = MASKS_TRAIN_NO_PNEUMO.astype('float16') / 255\n\nMASKS_TEST_PNEUMO = np.array(MASKS_TEST_PNEUMO)\nMASKS_TEST_PNEUMO = MASKS_TEST_PNEUMO.reshape((len(MASKS_TEST_PNEUMO), SIZE, SIZE, 1))\nMASKS_TEST_PNEUMO = MASKS_TEST_PNEUMO.astype('float16') / 255\n\nMASKS_TEST_NO_PNEUMO = np.array(MASKS_TEST_NO_PNEUMO)\nMASKS_TEST_NO_PNEUMO = MASKS_TEST_NO_PNEUMO.reshape((len(MASKS_TEST_NO_PNEUMO), SIZE, SIZE, 1))\nMASKS_TEST_NO_PNEUMO = MASKS_TEST_NO_PNEUMO.astype('float16') / 255\n\nCLASS_IMAGE_TRAIN_PNEUMO = np.array(CLASS_IMAGE_TRAIN_PNEUMO)\nCLASS_IMAGE_TRAIN_NO_PNEUMO = np.array(CLASS_IMAGE_TRAIN_NO_PNEUMO)\nCLASS_IMAGE_TEST_PNEUMO = np.array(CLASS_IMAGE_TEST_PNEUMO)\nCLASS_IMAGE_TEST_NO_PNEUMO = np.array(CLASS_IMAGE_TEST_NO_PNEUMO)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Concatenated separation of training and test groups","metadata":{}},{"cell_type":"code","source":"X_train = np.concatenate((IMAGE_TRAIN_PNEUMO,IMAGE_TRAIN_NO_PNEUMO))\ny_train = np.concatenate((MASKS_TRAIN_PNEUMO,MASKS_TRAIN_NO_PNEUMO))\nX_test = np.concatenate((IMAGE_TEST_PNEUMO,IMAGE_TEST_NO_PNEUMO))\ny_test = np.concatenate((MASKS_TEST_PNEUMO,MASKS_TEST_NO_PNEUMO))\nclass_train = np.concatenate((CLASS_IMAGE_TRAIN_PNEUMO,CLASS_IMAGE_TRAIN_NO_PNEUMO))\nclass_test = np.concatenate((CLASS_IMAGE_TEST_PNEUMO,CLASS_IMAGE_TEST_NO_PNEUMO))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 0\npredicted_rx = np.squeeze(y_train[number].astype(np.float32))\nplt.imshow(predicted_rx, cmap='gray')\nplt.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 3\nfig, ax = plt.subplots(1,2, figsize = (16,8))\nax[0].imshow(X_test[number], cmap='gray')\nax[1].imshow(y_test[number], cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel IMAGE_TRAIN_PNEUMO \ndel IMAGE_TRAIN_NO_PNEUMO\ndel MASKS_TRAIN_PNEUMO \ndel MASKS_TRAIN_NO_PNEUMO\ndel IMAGE_TEST_PNEUMO\ndel IMAGE_TEST_NO_PNEUMO\ndel MASKS_TEST_PNEUMO\ndel MASKS_TEST_NO_PNEUMO\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation:** *We will make some changes in the groups in order to adapt to the VGG19*","metadata":{}},{"cell_type":"code","source":"X_train_3C = list()\nX_test_3C = list()\n\nfor img in X_train:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    X_train_3C.append(img_3C)\n    \nfor img in X_test:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    X_test_3C.append(img_3C)\n    \nX_train_3C = np.array(X_train_3C)\nX_test_3C = np.array(X_test_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Transforming targets into categorical classes","metadata":{}},{"cell_type":"code","source":"binarizer = LabelBinarizer()\n\nlabels_train = binarizer.fit_transform(class_train)\nlabels_train = to_categorical(labels_train)\nlabels_test = binarizer.fit_transform(class_test)\nlabels_test = to_categorical(labels_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Defining the metrics and losses for the structure segmentation model ","metadata":{}},{"cell_type":"code","source":"def iou_score(y_pred, y_true, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n    iou = (intersection + smooth)/(union + smooth)\n    return iou\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)\n\ndef jacard_coef(y_true, y_pred):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n\ndef jacard_coef_loss(y_true, y_pred):\n    return -jacard_coef(y_true, y_pred) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Structuring and training the classification network using VGG19","metadata":{}},{"cell_type":"code","source":"vgg_19 = VGG19(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, CHANNELS_3C))\nvgg_19.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, layer in enumerate(vgg_19.layers):\n    print(i,layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Don't compile if you'll training with RF","metadata":{}},{"cell_type":"code","source":"for layer in vgg_19.layers[:17]:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_19.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = models.Sequential()\nclassifier.add(vgg_19)\nclassifier.add(layers.GlobalAveragePooling2D())\nclassifier.add(layers.BatchNormalization())\nclassifier.add(layers.Flatten())\nclassifier.add(layers.Dense(128, activation='relu'))\nclassifier.add(layers.Dropout(0.6))\nclassifier.add(layers.Dense(128, activation='relu'))\nclassifier.add(layers.Dropout(0.4))\nclassifier.add(layers.Dense(128, activation='relu'))\nclassifier.add(layers.Dropout(0.3))\nclassifier.add(layers.Dense(2, activation='softmax'))\nclassifier.summary()\nclassifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(rotation_range=10, zoom_range=0.1)\ndatagen.fit(X_train_3C)\ndata_augmentation = datagen.flow(X_train_3C, labels_train, batch_size=16)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=1e-5, patience=5, verbose=1), ModelCheckpoint('Classifier_pneumo.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')]\nresult_class = classifier.fit(data_augmentation, validation_data=(X_test_3C, labels_test), callbacks=callbacks, epochs=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ReduceLROnPlateau(monitor='val_acc', factor=0.1, min_delta=1e-5, patience=5, verbose=1), ModelCheckpoint('Classifier_pneumo.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='max')]\nresult_class = classifier.fit(X_train_3C, labels_train, validation_data=(X_test_3C, labels_test),batch_size=16, epochs=100, callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier.save('Classifier_complete.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9.1 - VGG19 to RF/SVM","metadata":{}},{"cell_type":"code","source":"feature_extractor=vgg_19.predict(X_train_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_extractor.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = feature_extractor.reshape(feature_extractor.shape[0], -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SVM","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC\nSVM_model = SVC(kernel = 'rbf', random_state = 1, C = 2.0, probability=True)\nSVM_model.fit(features, class_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_feature = vgg_19.predict(X_test_3C)\nX_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n\nprediction_SVM = SVM_model.predict(X_test_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RF","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nRF_model = RandomForestClassifier(n_estimators = 50, random_state = 0)\nRF_model.fit(features, labels_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_feature = vgg_19.predict(X_test_3C)\nX_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n\nprediction_RF = RF_model.predict(X_test_features)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10. Loading and evaluating the classification model","metadata":{}},{"cell_type":"markdown","source":"To normal vgg19","metadata":{}},{"cell_type":"code","source":"load_classifier = load_model('../input/package/Classifier_pneumo (1).h5')\nload_classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"load_classifier.evaluate(X_test_3C, labels_test,batch_size=16, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pred = load_classifier.predict(X_test_3C, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pred = class_pred.round()\nclass_true = labels_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To vgg19 + SVM","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nprint (\"Accuracy = \", metrics.accuracy_score(class_test, prediction_SVM.round()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pred = prediction_SVM.round()\nclass_true = class_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"To vgg19 + RF","metadata":{}},{"cell_type":"code","source":"from sklearn import metrics\nprint (\"Accuracy = \", metrics.accuracy_score(labels_test, prediction_RF.round()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_pred = prediction_RF.round()\nclass_true = labels_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 13. Doing some predictions","metadata":{}},{"cell_type":"code","source":"class_true[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = classifier.predict(X_test_3C[[1]].astype(np.float64), verbose=1)\nprediction.round()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 12. Structuring and training the Xnet network for segmentation","metadata":{}},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():    \n    input_shape=(SIZE,SIZE,1)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n\n    img_input = Input(shape=input_shape)\n\n    conv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(img_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = Activation(\"relu\")(batch1)\n    pool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n\n    conv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(pool1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = Activation(\"relu\")(batch2)\n    pool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n\n    conv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = Activation(\"relu\")(batch3)\n    pool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n\n    conv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = Activation(\"relu\")(batch4)\n\n    conv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = Activation(\"relu\")(batch5)\n\n    up6 = UpSampling2D(size=(2, 2))(act5)\n    conv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up6)\n    batch6 = BatchNormalization()(conv6)\n    act6 = Activation(\"relu\")(batch6)\n    concat6 = concatenate([act3,act6])\n\n    up7 = UpSampling2D(size=(2, 2))(concat6)\n    conv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up7)\n    batch7 = BatchNormalization()(conv7)\n    act7 = Activation(\"relu\")(batch7)\n    concat7 = concatenate([act2,act7])\n\n    conv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = Activation(\"relu\")(batch8)\n    pool8 = MaxPooling2D(pool_size=(2, 2))(act8)\n\n    conv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = Activation(\"relu\")(batch9)\n    pool9 = MaxPooling2D(pool_size=(2, 2))(act9)\n\n    conv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = Activation(\"relu\")(batch10)\n\n    conv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = Activation(\"relu\")(batch11)\n\n    up12 = UpSampling2D(size=(2, 2))(act11)\n    conv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up12)\n    batch12 = BatchNormalization()(conv12)\n    act12 = Activation(\"relu\")(batch12)\n    concat12 = concatenate([act9,act12])\n\n    up13 = UpSampling2D(size=(2, 2))(concat12)\n    conv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up13)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  Activation(\"relu\")(batch13)\n    concat13 = concatenate([act8,act13])\n\n    up14 = UpSampling2D(size=(2, 2))(concat13)\n    conv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(up14)\n    batch14 = BatchNormalization()(conv14)\n    act14 = Activation(\"relu\")(batch14)\n    concat14 = concatenate([act1,act14])\n\n    output_xnet = Conv2D(1, (1, 1), activation='sigmoid')(concat14)\n\n    model = Model(img_input, output_xnet)\n    model.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=[dice_coef_loss])\n    model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ModelCheckpoint('Segmenter_pneumo.h5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True, mode='min')]\nresults = model.fit(IMAGE_TRAIN_PNEUMO, MASKS_TRAIN_PNEUMO, validation_split=0.25,batch_size=8 * tpu_strategy.num_replicas_in_sync, epochs=300, callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(results.history['dice_coef_loss'], label='train')\nplt.plot(results.history['val_dice_coef_loss'], label='test')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('Segmenter_complete.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model_autoencoder = load_model('./Segmenter_pneumo_yes.h5', custom_objects=dependencies)\nloaded_model_autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 16\nim = model.predict(IMAGE_TEST_PNEUMO[[number]].astype(np.float32))\npredicted_rx = np.squeeze(im.astype(np.float32))\nplt.imshow(predicted_rx, cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 400\nim = loaded_model_autoencoder.predict(X_test[[number]].astype(np.float16))\nim = np.squeeze(im.astype(np.float16))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\nimg = cv2.imread('./predicted_000.jpg',1)\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nfig, ax = plt.subplots(1,1, figsize = (8,4))\nax.imshow(thresh, cmap='gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 14. Loading and evaluating the segmentation model","metadata":{}},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss, 'iou_score': iou_score}\nloaded_model = load_model('../input/my-segmenter/my_segmenter (1).h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = loaded_model.evaluate(X_train, y_train,batch_size=16, verbose=1)\nprint(\"Loss and dice_coef_loss:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 15. Doing some predictions","metadata":{}},{"cell_type":"code","source":"number = 124","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(IMAGE_TEST_PNEUMO[number], cmap = 'gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(MASKS_TEST_PNEUMO[number], cmap = 'gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Heat map","metadata":{}},{"cell_type":"code","source":"image_rx = np.squeeze(IMAGE_TEST_PNEUMO[number].astype(np.float64))\nplt.imsave('img_000.jpg', image_rx, cmap='gray')\nimg_000 = cv2.imread('./img_000.jpg',1)\n\n\nsegmentation = loaded_model.predict(X_test[[number]].astype(np.float64),verbose = 1)\nsegmentation = np.squeeze(segmentation.astype(np.float64))\nplt.imsave('mask_000.jpg', segmentation, cmap='gray')\nimg = cv2.imread('./mask_000.jpg',1)\n#img_grey = img[:,:,0]\n#min_ = img_grey.min()\n#max_ = img_grey.max()\n#ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n#plt.imsave('mask_thresh_000.jpg', thresh, cmap='gray')\n#img = cv2.imread('./mask_thresh_000.jpg',1)\n\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nheatmap_img = cv2.applyColorMap(gray_img, cv2.COLORMAP_JET)\nadded = cv2.addWeighted(heatmap_img, 0.3, img_000, 0.7, 0)\nplt.imshow(added)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mask","metadata":{}},{"cell_type":"code","source":"img = cv2.imread('./mask_000.jpg')\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nplt.imshow(np.squeeze((thresh).astype(np.uint8)),cmap = 'gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 16. Interesting things to publish","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(5,3, figsize=(30,70))\nn_image = [8, 87, 250, 198, 45]\npaths = ['./mask_8.jpg', './mask_87.jpg','./mask_250.jpg', './mask_198.jpg', './mask_45.jpg']\n\nfor i in range(0,5):\n    axs[i][0].imshow(IMAGE_TEST_PNEUMO[n_image[i]], cmap = 'gray')\n    axs[i][0].title.set_text('Chest x-ray')\n    axs[i][1].imshow(MASKS_TEST_PNEUMO[n_image[i]], cmap = 'gray')\n    axs[i][1].title.set_text('Original Mask')\n    img = cv2.imread(paths[i])\n    img_grey = img[:,:,0]\n    min_ = img_grey.min()\n    max_ = img_grey.max()\n    ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    axs[i][2].imshow(np.squeeze((thresh).astype(np.uint8)),cmap = 'gray')\n    axs[i][2].title.set_text('AI predicted mask')\n    \nfig.savefig('images.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = cv2.imread('./mask_45.jpg')\nfor row in range(SIZE):\n    for col in range(SIZE):\n        if np.all(img1[row,col] >= [50,50,50]):\n            img1[row,col] = [255,0,0]\n            \nimg2 = cv2.imread('./img_45.jpg')\n\nsum_ = cv2.addWeighted( img1, 0.3, img2, 1, 0)\nfig1, axs = plt.subplots(1,1, figsize=(4,4))          \nplt.imshow(sum_)\nplt.show()\nfig1.savefig('Image_red.png') ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 17. Lung segmentation from Chest X-Ray ","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nfrom cv2 import imread\nimport cv2\nimport matplotlib.pyplot as plt\n\nimage_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png\")\nmask_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/\",\"masks/\")\n\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Way adapted to import the dataset: https://www.kaggle.com/nikhilpandey360/lung-segmentation-from-chest-x-ray-dataset","metadata":{}},{"cell_type":"code","source":"mask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]\ncheck = [i for i in mask if \"mask\" in i]\n\ntesting_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check\n\n#len(image_file_name) - len(training_files)\n#len(testing_files)\n#image_file_name\n#training_files\n#testing_files","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"im_train = list()\nmask_train = list()\nim_test = list()\nmask_test = list()\n\nfor i in tqdm(testing_files): \n    im = cv2.imread(os.path.join(image_path,i),cv2.IMREAD_GRAYSCALE)\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    im = cv2.equalizeHist(im)\n    mask = cv2.imread(os.path.join(mask_path,i),cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    im_test.append(im)\n    mask_test.append(mask)\n    \nfor i in tqdm(training_files): \n    im = cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\"),cv2.IMREAD_GRAYSCALE)\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    im = cv2.equalizeHist(im)\n    mask = cv2.imread(os.path.join(mask_path,i+\".png\"),cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (SIZE,SIZE), interpolation = cv2.INTER_AREA)    \n    im_train.append(im)\n    mask_train.append(mask)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SIZE = 128\n\nim_train = np.array(im_train)\nmask_train = np.array(mask_train)\nim_test = np.array(im_test)\nmask_test = np.array(mask_test)\n\nim_train = im_train.reshape((len(im_train), SIZE, SIZE, 1))\nmask_train = mask_train.reshape((len(mask_train), SIZE, SIZE, 1))\nim_test = im_test.reshape((len(im_test), SIZE, SIZE, 1))\nmask_test = mask_test.reshape((len(mask_test), SIZE, SIZE, 1))\n\nX_train = im_train.astype('float32') / 255\ny_train = mask_train.astype('float32') / 255\nX_test = im_test.astype('float32') / 255\ny_test = mask_test.astype('float32') / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape=(SIZE,SIZE,1)\nclasses=1\nkernel_size = 3\nfilter_depth = (64,128,256,512,0)\n    \nimg_input = Input(shape=input_shape)\n\nconv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(img_input)\nbatch1 = BatchNormalization()(conv1)\nact1 = Activation(\"relu\")(batch1)\npool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n\nconv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(pool1)\nbatch2 = BatchNormalization()(conv2)\nact2 = Activation(\"relu\")(batch2)\npool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n\nconv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool2)\nbatch3 = BatchNormalization()(conv3)\nact3 = Activation(\"relu\")(batch3)\npool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n\nconv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool3)\nbatch4 = BatchNormalization()(conv4)\nact4 = Activation(\"relu\")(batch4)\n\nconv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act4)\nbatch5 = BatchNormalization()(conv5)\nact5 = Activation(\"relu\")(batch5)\n\nup6 = UpSampling2D(size=(2, 2))(act5)\nconv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up6)\nbatch6 = BatchNormalization()(conv6)\nact6 = Activation(\"relu\")(batch6)\nconcat6 = concatenate([act3,act6])\n\nup7 = UpSampling2D(size=(2, 2))(concat6)\nconv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up7)\nbatch7 = BatchNormalization()(conv7)\nact7 = Activation(\"relu\")(batch7)\nconcat7 = concatenate([act2,act7])\n\nconv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(concat7)\nbatch8 = BatchNormalization()(conv8)\nact8 = Activation(\"relu\")(batch8)\npool8 = MaxPooling2D(pool_size=(2, 2))(act8)\n\nconv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool8)\nbatch9 = BatchNormalization()(conv9)\nact9 = Activation(\"relu\")(batch9)\npool9 = MaxPooling2D(pool_size=(2, 2))(act9)\n\nconv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool9)\nbatch10 = BatchNormalization()(conv10)\nact10 = Activation(\"relu\")(batch10)\n\nconv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act10)\nbatch11 = BatchNormalization()(conv11)\nact11 = Activation(\"relu\")(batch11)\n\nup12 = UpSampling2D(size=(2, 2))(act11)\nconv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up12)\nbatch12 = BatchNormalization()(conv12)\nact12 = Activation(\"relu\")(batch12)\nconcat12 = concatenate([act9,act12])\n\nup13 = UpSampling2D(size=(2, 2))(concat12)\nconv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up13)\nbatch13 = BatchNormalization()(conv13)\nact13 =  Activation(\"relu\")(batch13)\nconcat13 = concatenate([act8,act13])\n\nup14 = UpSampling2D(size=(2, 2))(concat13)\nconv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(up14)\nbatch14 = BatchNormalization()(conv14)\nact14 = Activation(\"relu\")(batch14)\nconcat14 = concatenate([act1,act14])\n\noutput_xnet = Conv2D(1, (1, 1), activation='sigmoid')(concat14)\n\nmodel = Model(img_input, output_xnet)\nmodel.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=[dice_coef_loss])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ReduceLROnPlateau(monitor='val_dice_coef_loss', factor=0.1, min_delta=1e-5, patience=8, verbose=1), ModelCheckpoint('Segmenter_lung.h5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True, mode='min')]\nresults = model.fit(X_train, y_train, validation_split=0.1,batch_size=16, epochs=300, callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(results.history['dice_coef_loss'], label='train')\nplt.plot(results.history['val_dice_coef_loss'], label='test')\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('Segmenter_lung_complete.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('../input/segmenter-mais-eficente-300/Segmenter_lung (2).h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = loaded_model.evaluate(X_test, y_test,batch_size=16, verbose=1)\nprint(\"Loss and dice_coef_loss:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 80\nimage_rx = np.squeeze(X_test[number].astype(np.float64))\nplt.imsave('img_000.jpg', image_rx, cmap='gray')\nimg_000 = cv2.imread('./img_000.jpg',1)\n\n\nsegmentation = model.predict(X_test[[number]].astype(np.float64),verbose = 1)\nsegmentation = np.squeeze(segmentation.astype(np.float64))\nplt.imsave('mask_000.jpg', segmentation, cmap='gray')\nimg = cv2.imread('./mask_000.jpg',1)\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nplt.imsave('mask_thresh_000.jpg', thresh, cmap='gray')\nimg = cv2.imread('./mask_thresh_000.jpg',1)\n\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nheatmap_img = cv2.applyColorMap(gray_img, cv2.COLORMAP_JET)\nadded = cv2.addWeighted(heatmap_img, 0.3, img_000, 0.7, 0)\nplt.imshow(added)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_000 = cv2.imread('./img_000.jpg',1)\nplt.imshow(img_000)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_rx = np.squeeze(y_test[number].astype(np.float64))\nplt.imsave('mask_000.jpg', mask_rx, cmap='gray')\nmask_000 = cv2.imread('./mask_000.jpg',1)\nplt.imshow(mask_000)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mask_t_000 = cv2.imread('mask_thresh_000.jpg',1)\nplt.imshow(mask_t_000)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 18. Lung segmentation from pneumothorax chest X-Ray ","metadata":{}},{"cell_type":"code","source":"X_test = np.concatenate((IMAGE_TEST_PNEUMO,IMAGE_TEST_NO_PNEUMO))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = im_test.astype('float32') / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_R = list()\n\nfor img in X_test:\n    img_R = np.concatenate((img,)*3, axis=-1)\n    X_test_R.append(img_R)\n    \nX_test_R = np.array(X_test_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_test_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 1\nimage_rx = np.squeeze(X_test_[number].astype(np.float64))\nplt.imsave('img_000.jpg', image_rx, cmap='gray')\nimg_000 = cv2.imread('./img_000.jpg',1)\n\nsegmentation = model.predict(X_test_[[number]].astype(np.float64),verbose = 1)\nsegmentation = np.squeeze(segmentation.astype(np.float64))\nplt.imsave('mask_000.jpg', segmentation, cmap='gray')\nimg = cv2.imread('./mask_000.jpg',1)\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nplt.imsave('mask_thresh_000.jpg', thresh, cmap='gray')\nimg = cv2.imread('./mask_thresh_000.jpg',1)\n\ngray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\nheatmap_img = cv2.applyColorMap(gray_img, cv2.COLORMAP_JET)\nadded = cv2.addWeighted(heatmap_img, 0.3, img_000, 0.7, 0)\nplt.imshow(added)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 19. Importing relevant packages for radiomics","metadata":{}},{"cell_type":"code","source":"pip install pyradiomics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport SimpleITK as sitk\nimport six\nfrom radiomics import featureextractor, getTestCase, glcm, glrlm, glszm, imageoperations, shape, getImageTypes, getFeatureClasses, getParameterValidationFiles","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 20. Structuring the radiomics analysis","metadata":{}},{"cell_type":"code","source":"X_test_ = list()\n\nfor img in X_train:\n    img_R = np.concatenate((img,)*3, axis=-1)\n    X_test_.append(img_R)\n    \nX_test_ = np.array(X_test_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_images = len(X_test_)\nlen_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,len_images):    \n    image_chest = np.squeeze(X_train_R[i].astype(np.float64))\n    plt.imsave('./images/Image_chest'+str(i)+'.jpg', image_chest, cmap = 'gray')\n    image_segmentation = model.predict(X_test_[[i]].astype(np.float64),verbose = 1)\n    image_segmentation = np.squeeze(image_segmentation.astype(np.float64))\n    plt.imsave('./images/Mask_chest'+str(i)+'.jpg', image_segmentation, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = cv2.imread('.images/Image_chest.jpg',0)\nimg2 = cv2.imread('.images/Mask_chest.jpg',0)\n\nimg = [\"\",img1,img2]\nfig=plt.figure(figsize=(8, 8))\ncolumns = 2\nrows = 1\nfor i in range(1, columns*rows+1):\n    img_ = img[i]\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img_,cmap = 'gray')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for i in range(0,len_images): \n#    image = sitk.ReadImage('./Image_chest'+str(i)+'.jpg', sitk.sitkInt8)\n#    mask = sitk.ReadImage('./Mask_chest'+str(i)+'.jpg', sitk.sitkInt8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"applyLog = False\napplyWavelet = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"settings = {'binWidth':25,'label': 1, 'interpolator': sitk.sitkBSpline, 'resampledPixelSpacing':None}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extractor = featureextractor.RadiomicsFeatureExtractor(**settings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(featureVector)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"featureVector = []\nfor i in range(0,len_images): \n    image = sitk.ReadImage('./images/Image_chest'+str(i)+'.jpg', sitk.sitkInt8)\n    mask = sitk.ReadImage('./images/Mask_chest'+str(i)+'.jpg', sitk.sitkInt8)\n    result = pd.Series(extractor.execute(image, mask))\n    featureVector.append(result)\n    print(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(featureVector)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(featureVector)\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv('Features', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('./Features')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.columns.tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(columns = ['Unnamed: 0', 'diagnostics_Versions_PyRadiomics', 'diagnostics_Versions_Numpy', 'diagnostics_Versions_SimpleITK', 'diagnostics_Versions_PyWavelet', 'diagnostics_Versions_Python', 'diagnostics_Configuration_Settings', 'diagnostics_Configuration_EnabledImageTypes', 'diagnostics_Image-original_Hash', 'diagnostics_Image-original_Dimensionality', 'diagnostics_Image-original_Spacing', 'diagnostics_Image-original_Size', 'diagnostics_Image-original_Mean', 'diagnostics_Image-original_Minimum', 'diagnostics_Image-original_Maximum', 'diagnostics_Mask-original_Hash', 'diagnostics_Mask-original_Spacing', 'diagnostics_Mask-original_Size', 'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_VoxelNum', 'diagnostics_Mask-original_VolumeNum', 'diagnostics_Mask-original_CenterOfMassIndex', 'diagnostics_Mask-original_CenterOfMass'])\ndf","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', df.shape[0]+1)\ndf","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 20.1 - Feature reduction","metadata":{}},{"cell_type":"code","source":"pip install shap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.inspection import permutation_importance\nimport shap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/features-radiomics/Features_10k.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df, class_train, test_size=0.25, random_state=12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_C_train.dtype","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators=100)\nrf.fit(X_F_train, y_C_train)\n#explainer = shap.TreeExplainer(rf)\n#shap_values = explainer.shap_values(X_F_train)\n#shap.summary_plot(shap_values, X_F_test, plot_type=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint (\"Accuracy = \", metrics.accuracy_score(y_C_test, prediction.round()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sorted_idx = rf.feature_importances_.argsort()\nfig = plt.subplots(figsize=(10,26))\nplt.barh(df.columns.to_list(), rf.feature_importances_[sorted_idx])\nplt.xlabel(\"Random Forest Feature Importance\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nseaborn.clustermap(df.corr(), metric=\"correlation\", cmap = 'coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nseaborn.heatmap(df.corr(),annot = False, cmap = 'coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf_ = RandomForestClassifier() \nrfecv = RFECV(estimator=rf_, step=1, cv=5,scoring='accuracy')\nrfecv = rfecv.fit(X_F_train, y_C_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', X_F_train.columns[rfecv.support_])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2=df.loc[:,['original_firstorder_10Percentile', 'original_firstorder_90Percentile',\n       'original_firstorder_Energy', 'original_firstorder_Entropy',\n       'original_firstorder_InterquartileRange',\n       'original_firstorder_Kurtosis', 'original_firstorder_Mean',\n       'original_firstorder_Median',\n       'original_firstorder_RobustMeanAbsoluteDeviation',\n       'original_firstorder_RootMeanSquared',\n       'original_firstorder_TotalEnergy', 'original_firstorder_Uniformity',\n       'original_firstorder_Variance', 'original_glcm_Autocorrelation',\n       'original_glcm_ClusterProminence', 'original_glcm_ClusterShade',\n       'original_glcm_ClusterTendency', 'original_glcm_Contrast',\n       'original_glcm_Correlation', 'original_glcm_DifferenceAverage',\n       'original_glcm_DifferenceEntropy', 'original_glcm_DifferenceVariance',\n       'original_glcm_Id', 'original_glcm_Idm', 'original_glcm_Idmn',\n       'original_glcm_Idn', 'original_glcm_Imc1', 'original_glcm_Imc2',\n       'original_glcm_InverseVariance', 'original_glcm_JointAverage',\n       'original_glcm_JointEnergy', 'original_glcm_JointEntropy',\n       'original_glcm_MaximumProbability', 'original_glcm_SumAverage',\n       'original_glcm_SumEntropy', 'original_glcm_SumSquares',\n       'original_gldm_DependenceEntropy',\n       'original_gldm_DependenceNonUniformity',\n       'original_gldm_DependenceVariance',\n       'original_gldm_GrayLevelNonUniformity',\n       'original_gldm_LargeDependenceEmphasis',\n       'original_gldm_LargeDependenceHighGrayLevelEmphasis',\n       'original_gldm_LargeDependenceLowGrayLevelEmphasis',\n       'original_gldm_LowGrayLevelEmphasis',\n       'original_gldm_SmallDependenceEmphasis',\n       'original_gldm_SmallDependenceHighGrayLevelEmphasis',\n       'original_gldm_SmallDependenceLowGrayLevelEmphasis',\n       'original_glrlm_GrayLevelNonUniformity',\n       'original_glrlm_GrayLevelNonUniformityNormalized',\n       'original_glrlm_GrayLevelVariance', 'original_glrlm_LongRunEmphasis',\n       'original_glrlm_LongRunLowGrayLevelEmphasis',\n       'original_glrlm_LowGrayLevelRunEmphasis', 'original_glrlm_RunEntropy',\n       'original_glrlm_RunLengthNonUniformity',\n       'original_glrlm_RunLengthNonUniformityNormalized',\n       'original_glrlm_RunVariance', 'original_glrlm_ShortRunEmphasis',\n       'original_glrlm_ShortRunHighGrayLevelEmphasis',\n       'original_glrlm_ShortRunLowGrayLevelEmphasis',\n       'original_glszm_GrayLevelNonUniformity',\n       'original_glszm_GrayLevelNonUniformityNormalized',\n       'original_glszm_GrayLevelVariance',\n       'original_glszm_HighGrayLevelZoneEmphasis',\n       'original_glszm_LargeAreaHighGrayLevelEmphasis',\n       'original_glszm_LargeAreaLowGrayLevelEmphasis',\n       'original_glszm_LowGrayLevelZoneEmphasis',\n       'original_glszm_SizeZoneNonUniformity',\n       'original_glszm_SizeZoneNonUniformityNormalized',\n       'original_glszm_SmallAreaEmphasis',\n       'original_glszm_SmallAreaHighGrayLevelEmphasis',\n       'original_glszm_SmallAreaLowGrayLevelEmphasis',\n       'original_glszm_ZoneEntropy', 'original_glszm_ZoneVariance',\n       'original_ngtdm_Busyness', 'original_ngtdm_Coarseness',\n       'original_ngtdm_Complexity', 'original_ngtdm_Contrast',\n       'original_ngtdm_Strength']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df2.to_csv('Features_reduced', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced = pd.read_csv('./Features_reduced')\ndf_reduced = df_reduced.drop(columns = 'Unnamed: 0', axis=1)\ndf_reduced","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nX_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df_reduced, class_train, test_size=0.25, random_state=12)\nrf = RandomForestClassifier()\nrf.fit(X_F_train, y_C_train)\nprint (\"Accuracy = \", metrics.accuracy_score(y_C_test, rf.predict(X_F_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,10))\nseaborn.clustermap(df_reduced.corr(), metric=\"correlation\", cmap = 'coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced.corr()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = list()\ncorr_matrix = df_reduced.corr()\n\nfor i in range(len(corr_matrix .columns)):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i, j]) > 0.3:\n            colname = corr_matrix.columns[i]\n            corr_features.append(str(colname))\n            \ndf_reduced_corr = df_reduced.drop(columns = corr_features, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr.to_csv('Features_reduced_corr', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nX_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df_reduced_corr, class_train, test_size=0.25, random_state=12)\nrf = RandomForestClassifier()\nrf.fit(X_F_train, y_C_train)\nprint (\"Accuracy = \", metrics.accuracy_score(y_C_test, rf.predict(X_F_test)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 21. Assigning a BRISQUE score for each image ","metadata":{}},{"cell_type":"code","source":"pip install image-quality","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imquality.brisque as brisque","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features = pd.DataFrame({'Brisque_score':[]})\ndf_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = []\nfor i in range(0,len(X_test_R)):\n    score.append(brisque.score(X_test_R[i]))\ndf_features['Brisque_score'] = score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_features.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"No_train = df_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"No_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"No_train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 22. TEST - Segmenter using VGG, ResNet, Inception and among others as backbones","metadata":{}},{"cell_type":"code","source":"pip install -U segmentation-models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.utils import normalize\nfrom tensorflow.keras.metrics import MeanIoU\n%env SM_FRAMEWORK=tf.keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models as sm\nsm.set_framework('tf.keras')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = 1\nactivation = 'sigmoid'\nLR = 0.0001\noptim = keras.optimizers.Adam(LR)\nBATCH_SIZE = 16\n\ndice_loss = sm.losses.DiceLoss()\nmetrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_R = list()\n\nfor img in X_train:\n    img_R = np.concatenate((img,)*3, axis=-1)\n    X_train_R.append(img_R)\n    \nX_train_R = np.array(X_train_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_R = list()\n\nfor img in X_test:\n    img_R = np.concatenate((img,)*3, axis=-1)\n    X_test_R.append(img_R)\n    \nX_test_R = np.array(X_test_R)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BACKBONE1 = 'resnet34'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\n\nx_train = preprocess_input1(X_train_R)\nx_val = preprocess_input1(X_test_R)\n\nmodel = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes = n_classes, activation = activation)\nmodel.compile('Adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ModelCheckpoint('Segmenter_lung.h5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True, mode='min')]\nhistory = model.fit(x_train, y_train, batch_size = 16, epochs = 800, verbose = 1, validation_data = (x_val,y_test), callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('resnet34_segmenter.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nmodel = load_model('../input/package/resnet34_segmenter (1).h5', custom_objects=dependencies)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = None\nmodel = None","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('../input/segmenter-mais-eficente-300/Segmenter_lung (2).h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\nresults = loaded_model.evaluate(x_val,y_test,batch_size=16, verbose=1)\nprint(\"Loss and dice_coef_loss:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 23. VGG16 Feature importance","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications import VGG16\nvgg_16 = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, CHANNELS_3C))\nvgg_16.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, layer in enumerate(vgg_16.layers):\n    print(i,layer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in vgg_16.layers[:19]:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_16.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_feature = vgg_16.predict(X_train_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_feature.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_features = X_train_feature.reshape(X_train_feature.shape[0], -1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_features.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train_features[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_vgg16 = pd.DataFrame(X_train_features)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_vgg16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_vgg16.to_csv('Features_vgg16', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_vgg16 = pd.read_csv('../input/features-vgg16/Features_vgg16')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_train = pd.DataFrame([class_train])\ntarget_train.to_csv('Targets_train.csv', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df_vgg16, class_train, test_size=0.30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nX_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df_vgg16, class_train, test_size=0.25, random_state=12)\nrf = RandomForestClassifier()\nrf.fit(X_F_train, y_C_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint (\"Accuracy = \", metrics.accuracy_score(y_C_test, prediction.round()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"MCC: \", metrics.matthews_corrcoef(y_C_test, prediction.round()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\n\nconfusion_matrix = confusion_matrix(y_C_test, prediction.round())\nconfusion_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sn.heatmap(confusion_matrix, annot=True)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\nclf = ExtraTreesClassifier(n_estimators=50)\nclf = clf.fit(X_F_train, y_C_train)\nmodel = SelectFromModel(clf, prefit=True)\nX_new = model.transform(df_vgg16)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_reduced = pd.DataFrame(X_new)\ntrain_reduced.to_csv('train_reduced.csv', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_reduced = pd.read_csv('../input/festures-vgg16-reduced/train_reduced.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_train =  pd.read_csv('../input/targets-pneumo/Targets_train.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nX_F_train, X_F_test, y_C_train, y_C_test = train_test_split(train_reduced, class_train, test_size=0.25, random_state=12)\nrf = RandomForestClassifier()\nrf.fit(X_F_train, y_C_train)\nprediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features = list()\ncorr_matrix = train_reduced.corr()\nfor i in range(len(corr_matrix .columns)):\n    for j in range(i):\n        if abs(corr_matrix.iloc[i, j]) > 0.3:\n            colname = corr_matrix.columns[i]\n            corr_features.append(str(colname))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_features_ = np.asarray(corr_features)\ncorr_features_ = np.unique(corr_features_)\ncorr_features_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_reduced_corr = train_reduced.drop(columns = corr_features_, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_reduced_corr = vgg16_reduced_corr.drop(columns = ['Unnamed: 0'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_reduced_corr.to_csv('vgg16_reduced_corr', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_train = class_train.drop(columns = ['Unnamed: 0']).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_reduced_corr.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nX_F_train, X_F_test, y_C_train, y_C_test = train_test_split(vgg16_reduced_corr, class_train, test_size=0.30, random_state=12)\nrf = RandomForestClassifier()\nrf.fit(X_F_train, y_C_train)\nprediction = rf.predict(X_F_test)\nclass_pred = prediction.round()\nclass_true = y_C_test\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction = rf.predict(vgg16_reduced_corr)\nclass_pred = prediction.round()\nclass_true = class_train\nprint(classification_report(class_pred, class_true))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_selection import RFECV\nfrom sklearn.ensemble import RandomForestClassifier\n\nrf_ = RandomForestClassifier() \nrfecv = RFECV(estimator=rf_, step=1, cv=5,scoring='recall_macro')\nrfecv = rfecv.fit(X_F_train, y_C_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', X_F_train.columns[rfecv.support_])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_best_features = df_vgg16.loc[:,[]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fetures_vgg16['F_VGG16'] = X_test_features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Finally: Hybrid dataset ","metadata":{}},{"cell_type":"code","source":"vgg16_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_reduced_corr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final = pd.merge(df_reduced_corr, vgg16_reduced_corr, how = 'left', left_index = True, right_index = True)\ndf_final.to_csv('dataframe_king', sep=',', encoding='utf-8')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\npredictors = scaler.fit_transform(df_final)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\n\nrf = RandomForestClassifier()\nrf.fit(predictors, class_train)\nscores = cross_val_score(rf, df_final, class_train, cv=3)\nprint(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\nscores = cross_val_score(rf, df_final, class_train, cv=3, scoring='recall_macro')\nprint(\"%0.2f recall_macro with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n\n\n\n#X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(df_final, class_train, test_size=0.30, random_state=12)\n#rf = RandomForestClassifier()\n\n#rf.fit(df_final, class_train)\n#prediction = rf.predict(df_final)\n#class_pred = prediction.round()\n#class_true = y_C_test\n#print(classification_report(class_pred, class_train))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train, X_F_test, y_C_train, y_C_test = train_test_split(predictors, class_train, test_size=0.30, random_state=12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nMLP = MLPClassifier(verbose = True, max_iter = 1000, tol = 0.000010, solver='adam', hidden_layer_sizes=(100), activation = 'relu', batch_size=200, learning_rate_init=0.001)\nMLP.fit(predictors, class_train)","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scores = cross_val_score(MLP, predictors, class_train, cv=3)\nprint(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\nscores = cross_val_score(MLP, predictors, class_train, cv=3, scoring='recall_macro')\nprint(\"%0.2f recall_macro with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_F_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = models.Sequential()\nclassifier.add(layers.Dense(128, activation='relu',input_dim=245))\nclassifier.add(layers.Dropout(0.3))\nclassifier.add(layers.Dense(64, activation='relu'))\nclassifier.add(layers.Dropout(0.2))\nclassifier.add(layers.Dense(1, activation='sigmoid'))\nclassifier.summary()\nclassifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\nresult_class = classifier.fit(X_F_train, y_C_train, validation_data=(X_F_test, y_C_test),batch_size=8, epochs=100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}