{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Importing and installing relevant packages for our project","metadata":{}},{"cell_type":"code","source":"pip install pyradiomics","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install -U segmentation-models","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os \nimport cv2\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom tqdm import tqdm\nimport PIL\nimport time\nfrom IPython import display\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import classification_report\nfrom sklearn import metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.layers import Input, Dropout, Conv2D, MaxPooling2D, concatenate, Reshape, Conv2DTranspose, LeakyReLU, BatchNormalization, Activation, UpSampling2D \nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import models \nfrom tensorflow.keras import backend as K\nfrom keras.callbacks import History \nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.optimizers import Adam\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense\nimport seaborn\nfrom keras.optimizers import RMSprop\nfrom sklearn.feature_selection import RFECV\n%env SM_FRAMEWORK=tf.keras\nimport segmentation_models as sm\nsm.set_framework('tf.keras')","metadata":{"execution":{"iopub.status.busy":"2021-07-19T13:49:25.548536Z","iopub.execute_input":"2021-07-19T13:49:25.548969Z","iopub.status.idle":"2021-07-19T13:49:33.981859Z","shell.execute_reply.started":"2021-07-19T13:49:25.548873Z","shell.execute_reply":"2021-07-19T13:49:33.979542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import print_function\nimport SimpleITK as sitk\nimport six\nfrom radiomics import featureextractor, getTestCase, glcm, glrlm, glszm, imageoperations, shape, getImageTypes, getFeatureClasses, getParameterValidationFiles","metadata":{"execution":{"iopub.status.busy":"2021-07-19T13:49:33.982977Z","iopub.status.idle":"2021-07-19T13:49:33.983447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Assigning a seed","metadata":{}},{"cell_type":"code","source":"seed = 1\n#random.seed = seed\n#np.random.seed = seed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Defining variables","metadata":{}},{"cell_type":"code","source":"SIZE = 256\nCHANNELS = 1\nCHANNELS_3C = 3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Importing datasets","metadata":{}},{"cell_type":"markdown","source":"Directories","metadata":{}},{"cell_type":"code","source":"supression_images_dir = os.path.join(\"../input/xray-bone-shadow-supression/augmented/augmented/source/\")\nsupression_targets_dir = os.path.join(\"../input/xray-bone-shadow-supression/augmented/augmented/target/\")\nsupression_images_list = os.listdir(supression_images_dir)\nsupression_target_list = os.listdir(supression_targets_dir)\n\nimage_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/CXR_png\")\nmask_path = os.path.join(\"../input/chest-xray-masks-and-labels/Lung Segmentation/\",\"masks/\")\nimages = os.listdir(image_path)\nmask = os.listdir(mask_path)\n\ncovid_images_dir_train = os.path.join(\"../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train/\")\ncovid_images_dir_test = os.path.join(\"../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test/\")\ncovid_images_metadata = \"../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\"\ncovid_images_summary = \"../input/coronahack-chest-xraydataset/Chest_xray_Corona_dataset_Summary.csv\"\ncovid_images_train = os.listdir(covid_images_dir_train)\ncovid_images_test = os.listdir(covid_images_dir_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Catching images","metadata":{}},{"cell_type":"markdown","source":"*Supression*","metadata":{}},{"cell_type":"code","source":"supression_images = list()\nsupression_targets = list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"j = 0\nfor i in tqdm(supression_target_list):\n    if j < 4000:\n        path_images = supression_images_dir + str(i)\n        path_targets = supression_targets_dir + str(i)\n        image = cv2.imread(path_images,cv2.IMREAD_GRAYSCALE)\n        image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n        image = cv2.bitwise_not(image)\n        image = cv2.equalizeHist(image)\n        targets = cv2.imread(path_targets,cv2.IMREAD_GRAYSCALE) \n        targets = cv2.resize(targets, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n        targets = cv2.bitwise_not(targets)\n        targets = cv2.equalizeHist(targets)\n        supression_images.append(image)\n        supression_targets.append(targets)\n    j += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\n#del supression_images\n#del image\n#del supression_targets\n#del targets\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUPRESSION_IMAGES = np.array(supression_images)\nSUPRESSION_IMAGES = SUPRESSION_IMAGES.reshape((len(SUPRESSION_IMAGES), SIZE, SIZE, 1))\nSUPRESSION_IMAGES = SUPRESSION_IMAGES.astype('float32') / 255\n\nSUPRESSION_TARGETS = np.array(supression_targets)\nSUPRESSION_TARGETS = SUPRESSION_TARGETS.reshape((len(SUPRESSION_TARGETS), SIZE, SIZE, 1))\nSUPRESSION_TARGETS = SUPRESSION_TARGETS.astype('float32') / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUPRESSION_IMAGES_3C = list()\nSUPRESSION_TARGETS_3C = list()\n\nfor img in SUPRESSION_IMAGES:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    SUPRESSION_IMAGES_3C.append(img_3C)\n    \nfor img in SUPRESSION_TARGETS:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    SUPRESSION_TARGETS_3C.append(img_3C)\n    \nSUPRESSION_IMAGES_3C = np.array(SUPRESSION_IMAGES_3C)\nSUPRESSION_TARGETS_3C = np.array(SUPRESSION_TARGETS_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(SUPRESSION_IMAGES_3C.shape,SUPRESSION_TARGETS_3C.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*Segmentation*","metadata":{}},{"cell_type":"code","source":"mask = [fName.split(\".png\")[0] for fName in mask]\nimage_file_name = [fName.split(\"_mask\")[0] for fName in mask]\ncheck = [i for i in mask if \"mask\" in i]\n\ntesting_files = set(os.listdir(image_path)) & set(os.listdir(mask_path))\ntraining_files = check\n\nima = list()\nmas = list()\nima_canny = list()\nima_otsu = list()\nj = 0\nfor i in tqdm(testing_files):\n    im = cv2.imread(os.path.join(image_path,i),cv2.IMREAD_GRAYSCALE)\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    im = cv2.equalizeHist(im)\n    im2 = cv2.GaussianBlur(im,(5,5),0)\n    im3 = cv2.Canny(im2,56,56)\n    ret,im2 = cv2.threshold(im2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    im2 = cv2.bitwise_not(im2)\n    mask = cv2.imread(os.path.join(mask_path,i),cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    _,mask = cv2.threshold(mask,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    ima.append(im)\n    mas.append(mask)\n    ima_otsu.append(im2)\n    ima_canny.append(im3)\n    \nfor i in tqdm(training_files): \n    im = cv2.imread(os.path.join(image_path,i.split(\"_mask\")[0]+\".png\"),cv2.IMREAD_GRAYSCALE)\n    im = cv2.resize(im, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    im = cv2.equalizeHist(im)\n    im2 = cv2.GaussianBlur(im,(5,5),0)\n    im3 = cv2.Canny(im2,56,56)\n    ret,im2 = cv2.threshold(im2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    im2 = cv2.bitwise_not(im2)\n    mask = cv2.imread(os.path.join(mask_path,i+\".png\"),cv2.IMREAD_GRAYSCALE)\n    mask = cv2.resize(mask, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    _,mask = cv2.threshold(mask,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    ima.append(im)\n    mas.append(mask)\n    ima_otsu.append(im2)\n    ima_canny.append(im3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEGMENTATION_IMAGES = np.array(ima)\nSEGMENTATION_MASKS = np.array(mas)\n\nSEGMENTATION_IMAGES = SEGMENTATION_IMAGES.reshape((len(SEGMENTATION_IMAGES), SIZE, SIZE, 1))\nSEGMENTATION_MASKS = SEGMENTATION_MASKS.reshape((len(SEGMENTATION_MASKS), SIZE, SIZE, 1))\n\nSEGMENTATION_IMAGES = SEGMENTATION_IMAGES.astype('float32') / 255\nSEGMENTATION_MASKS = SEGMENTATION_MASKS.astype('float32') / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEGMENTATION_IMAGES_3C = list()\nSEGMENTATION_MASKS_3C = list()\n\nfor img in SEGMENTATION_IMAGES:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    SEGMENTATION_IMAGES_3C.append(img_3C)\n    \nfor img in SEGMENTATION_MASKS:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    SEGMENTATION_MASKS_3C.append(img_3C)\n    \nSEGMENTATION_IMAGES_3C = np.array(SEGMENTATION_IMAGES_3C)\nSEGMENTATION_MASKS_3C = np.array(SEGMENTATION_MASKS_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = list()\nfiles_tes = list(testing_files)\nfiles_tra = list(training_files)\nfor name in files_tes:\n    names.append(name)\nfor name in files_tra:\n    names.append(name)\nnames","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seg = list()\nfor item in names:\n    nm = ''.join([str(elem) for elem in item.split(\".png\", 1)])\n    seg.append(nm)\nseg","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*COVID-19*","metadata":{}},{"cell_type":"code","source":"metadata = pd.read_csv(\"../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\")\n\nmetadata_type_train = metadata[metadata['Dataset_type']=='TRAIN']\nmetadata_name_train = metadata_type_train['X_ray_image_name']\nmetadata_name_train = np.array(metadata_name_train)\n\nmetadata_type_test = metadata[metadata['Dataset_type']=='TEST']\nmetadata_name_test = metadata_type_test['X_ray_image_name']\nmetadata_name_test = np.array(metadata_name_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_images = list()\ncovid_images_otsu = list()\ncovid_images_canny = list()\ncovid_image_name = list()\n\nfor i in tqdm(metadata_name_train):\n    path_images_train = covid_images_dir_train + str(i)\n    image = cv2.imread(path_images_train,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    image2 = cv2.GaussianBlur(image,(5,5),0)\n    image3 = cv2.Canny(image2,56,56)\n    ret,image2 = cv2.threshold(image2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    image2 = cv2.bitwise_not(image2)\n    covid_images.append(image)\n    covid_images_otsu.append(image2)\n    covid_images_canny.append(image3)\n    covid_image_name.append(i)\n    \nfor i in tqdm(metadata_name_test):    \n    path_images_test = covid_images_dir_test + str(i)\n    image = cv2.imread(path_images_test,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    image = cv2.equalizeHist(image)\n    image2 = cv2.GaussianBlur(image,(5,5),0)\n    image3 = cv2.Canny(image2,56,56)\n    ret,image2 = cv2.threshold(image2,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    image2 = cv2.bitwise_not(image2)\n    covid_images.append(image)\n    covid_images_otsu.append(image2)\n    covid_images_canny.append(image3)\n    covid_image_name.append(i)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COVID_IMAGES = np.array(covid_images)\n\nCOVID_IMAGES = COVID_IMAGES.reshape((len(COVID_IMAGES), SIZE, SIZE, 1))\n\nCOVID_IMAGES = COVID_IMAGES.astype('float32') / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COVID_IMAGES_3C = list()\n\nfor img in COVID_IMAGES:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    COVID_IMAGES_3C.append(img_3C)\n    \nCOVID_IMAGES_3C = np.array(COVID_IMAGES_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5 - Defining the metrics for the models","metadata":{}},{"cell_type":"code","source":"def iou_score(y_pred, y_true, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    union = K.sum(y_true, -1) + K.sum(y_pred, -1) - intersection\n    iou = (intersection + smooth)/(union + smooth)\n    return iou\n\ndef dice_coef(y_true, y_pred, smooth=1):\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1 - dice_coef(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Bone supression from Chest X-Ray","metadata":{}},{"cell_type":"code","source":"n_classes = 1\nactivation = 'sigmoid'\nLR = 0.0001\noptim = tf.keras.optimizers.Adam(LR)\nBATCH_SIZE = 16\nX_train, X_test, y_train, y_test = train_test_split(SUPRESSION_IMAGES, SUPRESSION_TARGETS, test_size=0.30, random_state=12)\n#X_train_3C, X_test_3C, y_train_3C, y_test_3C = train_test_split(SUPRESSION_IMAGES_3C, SUPRESSION_TARGETS_3C, test_size=0.30, random_state=12)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape=(SIZE,SIZE,1)\nclasses=1\nkernel_size = 3\nfilter_depth = (64,128,256,512,0)\n    \nimg_input = Input(shape=input_shape)\n\nconv1 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(img_input)\nbatch1 = BatchNormalization()(conv1)\nact1 = Activation(\"relu\")(batch1)\npool1 = MaxPooling2D(pool_size=(2, 2))(act1)\n\nconv2 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(pool1)\nbatch2 = BatchNormalization()(conv2)\nact2 = Activation(\"relu\")(batch2)\npool2 = MaxPooling2D(pool_size=(2, 2))(act2)\n\nconv3 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool2)\nbatch3 = BatchNormalization()(conv3)\nact3 = Activation(\"relu\")(batch3)\npool3 = MaxPooling2D(pool_size=(2, 2))(act3)\n\nconv4 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool3)\nbatch4 = BatchNormalization()(conv4)\nact4 = Activation(\"relu\")(batch4)\n\nconv5 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act4)\nbatch5 = BatchNormalization()(conv5)\nact5 = Activation(\"relu\")(batch5)\n\nup6 = UpSampling2D(size=(2, 2))(act5)\nconv6 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up6)\nbatch6 = BatchNormalization()(conv6)\nact6 = Activation(\"relu\")(batch6)\nconcat6 = concatenate([act3,act6])\n\nup7 = UpSampling2D(size=(2, 2))(concat6)\nconv7 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up7)\nbatch7 = BatchNormalization()(conv7)\nact7 = Activation(\"relu\")(batch7)\nconcat7 = concatenate([act2,act7])\n\nconv8 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(concat7)\nbatch8 = BatchNormalization()(conv8)\nact8 = Activation(\"relu\")(batch8)\npool8 = MaxPooling2D(pool_size=(2, 2))(act8)\n\nconv9 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(pool8)\nbatch9 = BatchNormalization()(conv9)\nact9 = Activation(\"relu\")(batch9)\npool9 = MaxPooling2D(pool_size=(2, 2))(act9)\n\nconv10 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(pool9)\nbatch10 = BatchNormalization()(conv10)\nact10 = Activation(\"relu\")(batch10)\n\nconv11 = Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\")(act10)\nbatch11 = BatchNormalization()(conv11)\nact11 = Activation(\"relu\")(batch11)\n\nup12 = UpSampling2D(size=(2, 2))(act11)\nconv12 = Conv2D(filter_depth[2], (kernel_size, kernel_size), padding=\"same\")(up12)\nbatch12 = BatchNormalization()(conv12)\nact12 = Activation(\"relu\")(batch12)\nconcat12 = concatenate([act9,act12])\n\nup13 = UpSampling2D(size=(2, 2))(concat12)\nconv13 = Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\")(up13)\nbatch13 = BatchNormalization()(conv13)\nact13 =  Activation(\"relu\")(batch13)\nconcat13 = concatenate([act8,act13])\n\nup14 = UpSampling2D(size=(2, 2))(concat13)\nconv14 = Conv2D(filter_depth[0], (kernel_size, kernel_size), padding=\"same\")(up14)\nbatch14 = BatchNormalization()(conv14)\nact14 = Activation(\"relu\")(batch14)\nconcat14 = concatenate([act1,act14])\n\noutput_xnet = Conv2D(1, (1, 1), activation='sigmoid')(concat14)\n\nmodel = Model(img_input, output_xnet)\nmodel.compile(optimizer='adam', loss= 'binary_crossentropy', metrics=[dice_coef_loss])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ModelCheckpoint('Supression_lung_Xnet.h5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True, mode='min')]\nhistory = model.fit(X_train, y_train, batch_size = 64, epochs = 100, verbose = 1, validation_data = (X_test,y_test), callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('Xnet_supression.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('../input/package-models/Supression_lung_Xnet (1).h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\n#results = loaded_model.evaluate(X_test,y_test,batch_size=64, verbose=1)\n#print(\"Loss and dice_coef_loss:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 2\nimage_rx = np.squeeze(X_test[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\nsupression_rx = np.squeeze(y_test[number].astype(np.float64))\nplt.imsave('supression_000.jpg', supression_rx, cmap='gray')\nsupression_000 = cv2.imread('./supression_000.jpg',1)\n\npredicted_rx = loaded_model.predict(X_test[[number]].astype(np.float64),verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\npredicted_000 = cv2.imread('./predicted_000.jpg',1)\n\n\n\nstack = np.hstack((image_000,supression_000,predicted_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length = len(SEGMENTATION_IMAGES)\nimages_seg = list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/images')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for number in range(0,length):\n    predicted_rx = loaded_model.predict(SEGMENTATION_IMAGES[[number]].astype(np.float64),verbose = 1)\n    predicted_rx = np.squeeze(predicted_rx.astype(np.float64))\n    plt.imsave('./input/images/'+seg[number]+'.png', predicted_rx, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 2\nimage_rx = np.squeeze(SEGMENTATION_IMAGES[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\n\npredicted_rx = loaded_model.predict(SEGMENTATION_IMAGES[[number]].astype(np.float64),verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\npredicted_000 = cv2.imread('./predicted_000.jpg',1)\n\n\n\nstack = np.hstack((image_000,predicted_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.1.1 - Gan for bone supression or segmentation from Chest X-Ray","metadata":{}},{"cell_type":"code","source":"#def dice_loss(y_true, y_pred):\n#    y_true = tf.dtypes.cast(y_true, tf.float32)\n#    y_pred = tf.math.sigmoid(y_pred)\n#    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n#    denominator = tf.reduce_sum(y_true + y_pred)\n#    return 1 - (numerator / denominator)\nbeta = 0.5\ndef tversky_loss(y_true, y_pred):\n    y_true = tf.cast(y_true, tf.float32)\n    y_pred = tf.math.sigmoid(y_pred)\n    numerator = y_true * y_pred\n    denominator = y_true * y_pred + beta * (1 - y_true) * y_pred + (1 - beta) * y_true * (1 - y_pred)\n    return tf.subtract(1, tf.divide(tf.reduce_sum(numerator), tf.reduce_sum(denominator)))\n\ndef dice_coef_9cat(y_true, y_pred, smooth=1e-7):\n    '''\n    Dice coefficient for 10 categories. Ignores background pixel label 0\n    Pass to model as metric during compile statement\n    '''\n    y_true_f = K.flatten(K.one_hot(K.cast(y_true, 'int32'), num_classes=10)[...,1:])\n    y_pred_f = K.flatten(y_pred[...,1:])\n    intersect = K.sum(y_true_f * y_pred_f, axis=-1)\n    denom = K.sum(y_true_f + y_pred_f, axis=-1)\n    return K.mean((2. * intersect / (denom + smooth)))\n\ndef dice_coef_9cat_loss(y_true, y_pred):\n    '''\n    Dice loss to minimize. Pass to model as loss during compile statement\n    '''\n    return 1 - dice_coef_9cat(y_true, y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Length of our images (1 channel)\nprint(len(supression_images), len(supression_targets))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUPRESSION_IMAGES_GAN = (np.array(supression_images).reshape((len(supression_images), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5\nSUPRESSION_TARGETS_GAN = (np.array(supression_targets).reshape((len(supression_targets), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUPRESSION_IMAGES_GAN = (np.array(ima).reshape((len(ima), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5\nSUPRESSION_IMAGES_OTSU_GAN = (np.array(ima_otsu).reshape((len(ima_otsu), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5\nSUPRESSION_IMAGES_CANNY_GAN = (np.array(ima_canny).reshape((len(ima_canny), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5\nSUPRESSION_TARGETS_GAN = (np.array(mas).reshape((len(mas), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen_args = dict(rotation_range=10,\n                     width_shift_range=0.2,\n                     height_shift_range=0.2)\ndatagen = ImageDataGenerator(**data_gen_args)\n\nseed = 1\n\ni = 0\nimages_aug = []\nimages_otsu_aug = []\nimages_canny_aug = []\nmasks_aug = []\nfor batch in tqdm(datagen.flow(SUPRESSION_IMAGES_GAN, SUPRESSION_TARGETS_GAN, batch_size=1,seed=seed)):\n    images_aug.append(batch[0])\n    i += 1\n    if i > 703:\n        break\ni = 0        \nfor batch in tqdm(datagen.flow(SUPRESSION_IMAGES_OTSU_GAN, SUPRESSION_IMAGES_GAN, batch_size=1,seed=seed)):\n    images_otsu_aug.append(batch[0])\n    i += 1\n    if i > 703:\n        break\ni = 0        \nfor batch in tqdm(datagen.flow(SUPRESSION_IMAGES_CANNY_GAN, SUPRESSION_IMAGES_OTSU_GAN, batch_size=1,seed=seed)):\n    images_canny_aug.append(batch[0])\n    i += 1\n    if i > 703:\n        break\ni = 0\nfor batch in tqdm(datagen.flow(SUPRESSION_TARGETS_GAN, SUPRESSION_IMAGES_GAN, batch_size=1,seed=seed)):\n    masks_aug.append(batch[0])\n    i += 1\n    if i > 703:\n        break       ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(images_aug)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 400\naug_images0 = np.squeeze(images_aug[number].astype(np.float32)*127.5 + 127.5)\nplt.imsave('image_aug_000.jpg', aug_images0, cmap='gray')\nimg0 = cv2.imread('./image_aug_000.jpg',1)\n\naug_images1 = np.squeeze(images_otsu_aug[number].astype(np.float32)*127.5 + 127.5)\nplt.imsave('image_aug_001.jpg', aug_images1, cmap='gray')\nimg1 = cv2.imread('./image_aug_001.jpg',1)\n\naug_images2 = np.squeeze(images_canny_aug[number].astype(np.float32)*127.5 + 127.5)\nplt.imsave('image_aug_002.jpg', aug_images2, cmap='gray')\nimg2 = cv2.imread('./image_aug_002.jpg',1)\n\naug_masks = np.squeeze(masks_aug[number].astype(np.float32)*127.5 + 127.5)\nplt.imsave('mask_aug_000.jpg', aug_masks, cmap='gray')\nmask0 = cv2.imread('./mask_aug_000.jpg',1)\n\nstack = np.hstack((aug_images0, aug_images1, aug_images2, aug_masks))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SUPRESSION_IMAGES_GAN_3C = list()\n#SUPRESSION_TARGETS_GAN_3C = list()\n\n#for img in SUPRESSION_IMAGES_GAN:\n#    SUPRESSION_IMAGES_GAN_3C.append(np.concatenate((img,)*3, axis=-1))\n#    \n#for img in SUPRESSION_TARGETS_GAN:\n#    SUPRESSION_TARGETS_GAN_3C.append(np.concatenate((img,)*3, axis=-1))\n#\n#SUPRESSION_IMAGES_GAN_3C = np.array(SUPRESSION_IMAGES_GAN_3C)\n#SUPRESSION_TARGETS_GAN_3C = np.array(SUPRESSION_TARGETS_GAN_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"buffer_size = len(SUPRESSION_IMAGES_GAN)\nbatch_size = 32","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUPRESSION_IMAGES_GAN = np.append(SUPRESSION_IMAGES_GAN,images_aug)\nSUPRESSION_IMAGES_OTSU_GAN = np.append(SUPRESSION_IMAGES_OTSU_GAN,images_otsu_aug)\nSUPRESSION_IMAGES_CANNY_GAN = np.append(SUPRESSION_IMAGES_CANNY_GAN,images_canny_aug)\nSUPRESSION_TARGETS_GAN = np.append(SUPRESSION_TARGETS_GAN,masks_aug)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SUPRESSION_IMAGES_GAN = np.array(SUPRESSION_IMAGES_GAN).reshape((704*2, SIZE, SIZE, 1))\nSUPRESSION_IMAGES_OTSU_GAN = np.array(SUPRESSION_IMAGES_OTSU_GAN).reshape((704*2, SIZE, SIZE, 1))\nSUPRESSION_IMAGES_CANNY_GAN = np.array(SUPRESSION_IMAGES_CANNY_GAN).reshape((704*2, SIZE, SIZE, 1))\nSUPRESSION_TARGETS_GAN = np.array(SUPRESSION_TARGETS_GAN).reshape((704*2, SIZE, SIZE, 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(SUPRESSION_IMAGES_GAN)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 1000\naug_images0 = (np.squeeze(SUPRESSION_IMAGES_GAN[number].astype(np.float32))*127.5 + 127.5)\nplt.imsave('image_aug_000.jpg', aug_images0, cmap='gray')\nimg0 = cv2.imread('./image_aug_000.jpg',1)\n\naug_images1 = (np.squeeze(SUPRESSION_IMAGES_OTSU_GAN[number].astype(np.float32))*127.5 + 127.5)\nplt.imsave('image_aug_001.jpg', aug_images1, cmap='gray')\nimg1 = cv2.imread('./image_aug_001.jpg',1)\n\naug_images2 = (np.squeeze(SUPRESSION_IMAGES_CANNY_GAN[number].astype(np.float32))*127.5 + 127.5)\nplt.imsave('image_aug_002.jpg', aug_images2, cmap='gray')\nimg2 = cv2.imread('./image_aug_002.jpg',1)\n\naug_masks = (np.squeeze(SUPRESSION_TARGETS_GAN[number].astype(np.float32))*127.5 + 127.5)\nplt.imsave('mask_aug_000.jpg', aug_masks, cmap='gray')\nmask0 = cv2.imread('./mask_aug_000.jpg',1)\n\nstack = np.hstack((aug_images0, aug_images1, aug_images2, aug_masks))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_X = tf.data.Dataset.from_tensor_slices(SUPRESSION_IMAGES_GAN).batch(batch_size)\ntrain_dataset_otsu_X = tf.data.Dataset.from_tensor_slices(SUPRESSION_IMAGES_OTSU_GAN).batch(batch_size)\ntrain_dataset_canny_X = tf.data.Dataset.from_tensor_slices(SUPRESSION_IMAGES_CANNY_GAN).batch(batch_size)\ntrain_dataset_y = tf.data.Dataset.from_tensor_slices(SUPRESSION_TARGETS_GAN).batch(batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nimport tensorflow as tf  # TF 2.0\n\n\nclass SpectralNormalization(tf.keras.layers.Wrapper):\n    def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n        self.iteration = iteration\n        self.eps = eps\n        self.do_power_iteration = training\n        if not isinstance(layer, tf.keras.layers.Layer):\n            raise ValueError(\n                'Please initialize `TimeDistributed` layer with a '\n                '`Layer` instance. You passed: {input}'.format(input=layer))\n        super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n    def build(self, input_shape):\n        self.layer.build(input_shape)\n\n        self.w = self.layer.kernel\n        self.w_shape = self.w.shape.as_list()\n\n        self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_v',\n                                 dtype=tf.float32)\n\n        self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                 initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                 trainable=False,\n                                 name='sn_u',\n                                 dtype=tf.float32)\n\n        super(SpectralNormalization, self).build()\n\n    def call(self, inputs):\n        self.update_weights()\n        output = self.layer(inputs)\n        self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n        return output\n    \n    def update_weights(self):\n        w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n        \n        u_hat = self.u\n        v_hat = self.v  # init v vector\n\n        if self.do_power_iteration:\n            for _ in range(self.iteration):\n                v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                u_ = tf.matmul(v_hat, w_reshaped)\n                u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n        sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n        self.u.assign(u_hat)\n        self.v.assign(v_hat)\n\n        self.layer.kernel.assign(self.w / sigma)\n\n    def restore_weights(self):\n        self.layer.kernel.assign(self.w)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.initializers import RandomNormal\ndef make_generator_model():\n    \n    class SpectralNormalization(tf.keras.layers.Wrapper):\n        def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n            self.iteration = iteration\n            self.eps = eps\n            self.do_power_iteration = training\n            if not isinstance(layer, tf.keras.layers.Layer):\n                raise ValueError(\n                    'Please initialize `TimeDistributed` layer with a '\n                    '`Layer` instance. You passed: {input}'.format(input=layer))\n            super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n        def build(self, input_shape):\n            self.layer.build(input_shape)\n\n            self.w = self.layer.kernel\n            self.w_shape = self.w.shape.as_list()\n\n            self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                     initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                     trainable=False,\n                                     name='sn_v',\n                                     dtype=tf.float32)\n\n            self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                     initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                     trainable=False,\n                                     name='sn_u',\n                                     dtype=tf.float32)\n\n            super(SpectralNormalization, self).build()\n\n        def call(self, inputs):\n            self.update_weights()\n            output = self.layer(inputs)\n            self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n            return output\n\n        def update_weights(self):\n            w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n\n            u_hat = self.u\n            v_hat = self.v  # init v vector\n\n            if self.do_power_iteration:\n                for _ in range(self.iteration):\n                    v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                    v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                    u_ = tf.matmul(v_hat, w_reshaped)\n                    u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n            sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n            self.u.assign(u_hat)\n            self.v.assign(v_hat)\n\n            self.layer.kernel.assign(self.w / sigma)\n\n        def restore_weights(self):\n            self.layer.kernel.assign(self.w)\n    \n    input_shape=(128,128,1)\n    classes=1\n    kernel_size = 3\n    filter_depth = (64,128,256,512,0)\n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n\n    img_input1 = Input(shape=input_shape)\n    img_input2 = Input(shape=input_shape)\n    img_input3 = Input(shape=input_shape)\n\n    concat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n    \n    conv1 = SpectralNormalization(Conv2D(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat_input)\n    batch1 = BatchNormalization()(conv1)\n    act1 = layers.LeakyReLU(0.2)(batch1)\n\n    conv2 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = layers.LeakyReLU(0.2)(batch2)\n\n    conv3 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act2)\n    batch3 = BatchNormalization()(conv3)\n    act3 = layers.LeakyReLU(0.2)(batch3)\n\n    conv4 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act3)\n    batch4 = BatchNormalization()(conv4)\n    act4 = layers.LeakyReLU(0.2)(batch4)\n\n    conv5 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act4)\n    batch5 = BatchNormalization()(conv5)\n    act5 = layers.LeakyReLU(0.2)(batch5)\n\n    conv6 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act5)\n    batch6 = BatchNormalization()(conv6)\n    act6 = layers.LeakyReLU(0.2)(batch6)\n    concat6 = concatenate([act2,act6])\n\n    conv7 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat6)\n    batch7 = BatchNormalization()(conv7)\n    act7 = layers.LeakyReLU(0.2)(batch7)\n    concat7 = concatenate([act1,act7])\n\n    conv8 = SpectralNormalization(Conv2D(filter_depth[1], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(concat7)\n    batch8 = BatchNormalization()(conv8)\n    act8 = layers.LeakyReLU(0.2)(batch8)\n\n    conv9 = SpectralNormalization(Conv2D(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act8)\n    batch9 = BatchNormalization()(conv9)\n    act9 = layers.LeakyReLU(0.2)(batch9)\n\n    conv10 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act9)\n    batch10 = BatchNormalization()(conv10)\n    act10 = layers.LeakyReLU(0.2)(batch10)\n\n    conv11 = SpectralNormalization(Conv2D(filter_depth[3], (kernel_size, kernel_size), padding=\"same\", kernel_initializer = init))(act10)\n    batch11 = BatchNormalization()(conv11)\n    act11 = layers.LeakyReLU(0.2)(batch11)\n\n    conv12 = SpectralNormalization(Conv2DTranspose(filter_depth[2], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(act11)\n    batch12 = BatchNormalization()(conv12)\n    act12 = layers.LeakyReLU(0.2)(batch12)\n    concat12 = concatenate([act9,act12])\n\n    conv13 = SpectralNormalization(Conv2DTranspose(filter_depth[1], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat12)\n    batch13 = BatchNormalization()(conv13)\n    act13 =  layers.LeakyReLU(0.2)(batch13)\n    concat13 = concatenate([act8,act13])\n\n    conv14 = SpectralNormalization(Conv2DTranspose(filter_depth[0], (kernel_size, kernel_size),strides = (2,2), padding=\"same\", kernel_initializer = init))(concat13)\n    batch14 = BatchNormalization()(conv14)\n    act14 = layers.LeakyReLU(0.2)(batch14)\n    concat14 = concatenate([concat_input,act14])\n\n    output_xnet = SpectralNormalization(Conv2D(1, (1, 1), activation='tanh'))(concat14)\n\n    model = Model(inputs = [img_input1,img_input2,img_input3], outputs = output_xnet)\n    \n    model.summary()\n        \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_generator_model():\n    dependencies = {'dice_coef_loss': dice_coef_loss}\n    model = load_model('../input/package-models/Supression_lung_Xnet (1).h5', custom_objects=dependencies)\n    model.summary()\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.initializers import RandomNormal\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n    init = RandomNormal(stddev=0.02)\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    init = RandomNormal(stddev=0.02)\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    g = BatchNormalization()(g, training=True)\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n    g = tf.keras.layers.concatenate([g, skip_in])\n    g = Activation('relu')(g)\n    return g\n\ndef make_generator_model():\n    init = RandomNormal(stddev=0.02)\n    input_shape=(256,256,1)\n    \n    img_input1 = Input(shape=input_shape)\n    img_input2 = Input(shape=input_shape)\n    img_input3 = Input(shape=input_shape)\n\n    concat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n    \n    e1 = define_encoder_block(concat_input, 64, batchnorm=False)\n    e2 = define_encoder_block(e1, 128)\n    e3 = define_encoder_block(e2, 256)\n    e4 = define_encoder_block(e3, 512)\n    e5 = define_encoder_block(e4, 512)\n    e6 = define_encoder_block(e5, 512)\n    e7 = define_encoder_block(e6, 512)\n    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n    b = Activation('relu')(b)\n    d1 = decoder_block(b, e7, 512)\n    d2 = decoder_block(d1, e6, 512)\n    d3 = decoder_block(d2, e5, 512)\n    d4 = decoder_block(d3, e4, 512, dropout=False)\n    d5 = decoder_block(d4, e3, 256, dropout=False)\n    d6 = decoder_block(d5, e2, 128, dropout=False)\n    d7 = decoder_block(d6, e1, 64, dropout=False)\n    d8 = decoder_block(d7, concat_input, 64, dropout=False)\n    \n    out_image = Conv2D(1, (1, 1), activation='tanh')(d8)\n    \n    model = Model(inputs = [img_input1,img_input2,img_input3], outputs = out_image)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = make_generator_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_discrimator_model():\n    \n    \n    class SpectralNormalization(tf.keras.layers.Wrapper):\n        def __init__(self, layer, iteration=1, eps=1e-12, training=True, **kwargs):\n            self.iteration = iteration\n            self.eps = eps\n            self.do_power_iteration = training\n            if not isinstance(layer, tf.keras.layers.Layer):\n                raise ValueError(\n                    'Please initialize `TimeDistributed` layer with a '\n                    '`Layer` instance. You passed: {input}'.format(input=layer))\n            super(SpectralNormalization, self).__init__(layer, **kwargs)\n\n        def build(self, input_shape):\n            self.layer.build(input_shape)\n\n            self.w = self.layer.kernel\n            self.w_shape = self.w.shape.as_list()\n\n            self.v = self.add_weight(shape=(1, self.w_shape[0] * self.w_shape[1] * self.w_shape[2]),\n                                     initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                     trainable=False,\n                                     name='sn_v',\n                                     dtype=tf.float32)\n\n            self.u = self.add_weight(shape=(1, self.w_shape[-1]),\n                                     initializer=tf.initializers.TruncatedNormal(stddev=0.02),\n                                     trainable=False,\n                                     name='sn_u',\n                                     dtype=tf.float32)\n\n            super(SpectralNormalization, self).build()\n\n        def call(self, inputs):\n            self.update_weights()\n            output = self.layer(inputs)\n            self.restore_weights()  # Restore weights because of this formula \"W = W - alpha * W_SN`\"\n            return output\n\n        def update_weights(self):\n            w_reshaped = tf.reshape(self.w, [-1, self.w_shape[-1]])\n\n            u_hat = self.u\n            v_hat = self.v  # init v vector\n\n            if self.do_power_iteration:\n                for _ in range(self.iteration):\n                    v_ = tf.matmul(u_hat, tf.transpose(w_reshaped))\n                    v_hat = v_ / (tf.reduce_sum(v_**2)**0.5 + self.eps)\n\n                    u_ = tf.matmul(v_hat, w_reshaped)\n                    u_hat = u_ / (tf.reduce_sum(u_**2)**0.5 + self.eps)\n\n            sigma = tf.matmul(tf.matmul(v_hat, w_reshaped), tf.transpose(u_hat))\n            self.u.assign(u_hat)\n            self.v.assign(v_hat)\n\n            self.layer.kernel.assign(self.w / sigma)\n\n        def restore_weights(self):\n            self.layer.kernel.assign(self.w)\n    \n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n    inp = Input(shape=[SIZE, SIZE, 1], name='input_image')\n    inp_otsu = Input(shape=[SIZE, SIZE, 1], name='input_image_otsu')\n    inp_canny = Input(shape=[SIZE, SIZE, 1], name='input_image_canny')\n    tar = Input(shape=[SIZE, SIZE, 1], name='target_image')\n    \n    x = tf.keras.layers.concatenate([inp,inp_otsu,inp_canny,tar])\n    \n    conv1 = SpectralNormalization(Conv2D(64, (5,5), strides = (2,2), padding='same', kernel_initializer = init))(x)\n    batch1 = BatchNormalization()(conv1)\n    act1 = layers.LeakyReLU(0.2)(batch1)\n    drop1 = Dropout(0.3)(act1)\n    \n    conv2 = SpectralNormalization(Conv2D(128, (5,5), strides = (2,2), padding='same', kernel_initializer = init))(drop1)\n    batch2 = BatchNormalization()(conv2)\n    act2 = layers.LeakyReLU(0.2)(batch2)\n    drop2 = Dropout(0.3)(act2)    \n    \n    flat = layers.Flatten()(drop2)\n    last = layers.Dense(1, activation='sigmoid')(flat)\n    \n    return Model(inputs=[inp,inp_otsu,inp_canny, tar], outputs=last)   ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_discrimator_model():\n    \n    init = RandomNormal(mean = 0.0, stddev = 0.02)\n    inp = Input(shape=[SIZE, SIZE, 1], name='input_image')\n    inp_otsu = Input(shape=[SIZE, SIZE, 1], name='input_image_otsu')\n    inp_canny = Input(shape=[SIZE, SIZE, 1], name='input_image_canny')\n    tar = Input(shape=[SIZE, SIZE, 1], name='target_image')\n    \n    merged = tf.keras.layers.concatenate([inp,inp_otsu,inp_canny,tar])\n                                    \n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    flat = layers.Flatten()(d)\n    patch_out = layers.Dense(1, activation='sigmoid')(flat) \n    model = Model(inputs=[inp,inp_otsu,inp_canny, tar], outputs=patch_out)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator = make_discrimator_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"discriminator.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./input/training_checkpoints')\nshutil.rmtree('./input/images_gan')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_loss_2d(Y_gt, Y_pred):\n    H, W, C = Y_gt.get_shape().as_list()[1:]\n    smooth = 1e-5\n    pred_flat = tf.reshape(Y_pred, [-1, H * W * C])\n    true_flat = tf.reshape(Y_gt, [-1, H * W * C])\n    pred_flat = tf.cast(pred_flat, dtype=tf.float32)\n    true_flat = tf.cast(true_flat, dtype=tf.float32)\n    intersection = 2.0 * tf.reduce_sum(pred_flat * true_flat, axis=1) + smooth\n    denominator = tf.reduce_sum(pred_flat, axis=1) + tf.reduce_sum(true_flat, axis=1) + smooth\n    loss = 1.0 - tf.reduce_mean(intersection / denominator)\n    return loss\n\ndef generalised_dice_loss_2d(Y_gt, Y_pred):\n    Y_gt = tf.cast(Y_gt, dtype=tf.float32)\n    Y_pred = tf.cast(Y_pred, dtype=tf.float32)\n    \n    smooth = 1e-5\n    w = tf.reduce_sum(Y_gt, axis=[1, 2])\n    w = 1 / (w ** 2 + smooth)\n\n    numerator = Y_gt * Y_pred\n    numerator = w * tf.reduce_sum(numerator, axis=[1, 2])\n    numerator = tf.reduce_sum(numerator, axis=1)\n\n    denominator = Y_pred + Y_gt\n    denominator = w * tf.reduce_sum(denominator, axis=[1, 2])\n    denominator = tf.reduce_sum(denominator, axis=1)\n\n    gen_dice_coef = 2 * numerator / (denominator + smooth)\n    loss = tf.reduce_mean(1 - gen_dice_coef)\n    return loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/training_checkpoints')\n\nMAE = tf.keras.losses.MeanAbsoluteError()\nbinary_cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\ndef discriminator_loss(disc_real_output, disc_generated_output):\n    real_loss = binary_cross_entropy(tf.multiply(tf.ones_like(disc_real_output),0.9), disc_real_output)\n    fake_loss = binary_cross_entropy(tf.multiply(tf.zeros_like(disc_generated_output),0.1), disc_generated_output)\n    total_disc_loss = real_loss + fake_loss\n    return total_disc_loss\n\ndef generator_loss(disc_generated_output,fake_output_,real_output_):\n    #gan_dice = generalised_dice_loss_2d(real_output_, fake_output_)\n    #print(real_output_,fake_output_)\n    gan_loss = binary_cross_entropy(tf.ones_like(disc_generated_output), disc_generated_output)\n    l1_loss = MAE(real_output_,fake_output_)\n    #gan_fl = fl(real_output_,fake_output_)\n    total_gen_loss = gan_loss + (100 * l1_loss) #+ (60*gan_fl)\n    return total_gen_loss, gan_loss\n\ngenerator_optimizer = tf.keras.optimizers.Adam(1e-5, beta_1=0.5)\ndiscriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n\ncheckpoint_dir = './input/training_checkpoints'\ncheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\ncheckpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n                                 discriminator_optimizer=discriminator_optimizer,\n                                 generator=generator,\n                                 discriminator=discriminator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 3\nnum_examples_to_generate = 16\nidx = np.random.randint(0, len(SUPRESSION_IMAGES_GAN),num_examples_to_generate)\nseed1 = SUPRESSION_IMAGES_GAN[idx]\nseed2 = SUPRESSION_IMAGES_OTSU_GAN[idx]\nseed3 = SUPRESSION_IMAGES_CANNY_GAN[idx]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import datetime\nlog_dir=\"../logs/\"\n\nsummary_writer = tf.summary.create_file_writer(\n  log_dir + \"fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_steps(input_image,input_image_otsu,input_image_canny,target, epoch):\n    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n        generated_images = generator([input_image,input_image_otsu,input_image_canny], training=True)\n        real_output = discriminator([input_image,input_image_otsu,input_image_canny, target], training=True)\n        fake_output = discriminator([input_image,input_image_otsu,input_image_canny, generated_images], training=True)\n        gen_total_loss, gen_gan_loss = generator_loss(fake_output, generated_images, target)\n        disc_loss = discriminator_loss(real_output, fake_output)\n    gradients_of_generator = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n    with summary_writer.as_default():\n        tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n        tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n        #tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n        tf.summary.scalar('disc_loss', disc_loss, step=epoch)\n    return gen_total_loss,disc_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/images_gan')\ndef generate_and_save_images(model, epoch, test_input,test_input2,test_input3):\n    predictions = model([test_input,test_input2,test_input3],training = False)\n\n    fig = plt.figure(figsize=(8,8))\n\n    for i in range(predictions.shape[0]):\n        plt.subplot(4, 4, i + 1)\n        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n        plt.axis('off')\n    plt.savefig('./input/images_gan/image_at_epoch_{:04d}.png'.format(epoch))   \n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_loss(epoch, g_losses, d_losses):\n    plt.figure(figsize=(10,5))\n    plt.title(\"Loss, Epochs 0-\" + str(epoch))\n    plt.plot(g_losses,label=\"Generator\")\n    plt.plot(d_losses,label=\"Discriminator\")\n    #plt.plot(gan_dice_loss,label=\"Dice Loss Generator\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy\n\ndef train(X_dataset,X_train_dataset_otsu,X_train_dataset_canny,y_dataset, epochs):\n    g_loss = []\n    d_loss = []\n    gan_dice_loss = []\n    #gan_dice_ = []\n    for epoch in range(epochs):\n        start = time.time()\n        #print(start,X_dataset, y_dataset)\n        for image_batch,image_batch_otsu,image_batch_canny,target_batch in zip(X_dataset,X_train_dataset_otsu,X_train_dataset_canny,y_dataset):\n            generator_loss, discriminator_loss = train_steps(image_batch,image_batch_otsu,image_batch_canny,target_batch, epochs)\n        \n        g_loss.append(generator_loss.numpy())\n    \n        d_loss.append(discriminator_loss.numpy())\n        \n        #gan_dice_loss.append(gan_dice.numpy())\n        \n        display.clear_output(wait = True)\n        print(\"Generator loss: \" + str(g_loss))\n        print(\"Discriminator loss: \" + str(d_loss))\n        #print(\"Dice Loss:\" + str(gan_dice_loss))\n        plot_loss(epoch, g_loss, d_loss)\n        generate_and_save_images(generator, epoch + 1, seed1,seed2,seed3)\n\n        if (epoch + 1) % 15 == 0:\n            checkpoint.save(file_prefix=checkpoint_prefix)\n        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_image(epoch_no):\n    return PIL.Image.open('./input/images_gan/image_at_epoch_{:04d}.png'.format(epoch_no))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(train_dataset_X,train_dataset_otsu_X,train_dataset_canny_X,train_dataset_y, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_image(epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*GIF*","metadata":{}},{"cell_type":"code","source":"import glob\nimport imageio\n\nanim_file = 'gan_segmentation.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n    filenames = glob.glob('./input/images_gan/image*.png')\n    filenames = sorted(filenames)\n    for filename in filenames:\n        image = imageio.imread(filename)\n        writer.append_data(image)\n    image = imageio.imread(filename)\n    writer.append_data(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install git+https://github.com/tensorflow/docs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_docs.vis.embed as embed\n\nembed.embed_file(anim_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.save('generator_model.h5')\ndiscriminator.save('discriminartor_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.load_weights('./generator_model.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.initializers import RandomNormal\ndef define_encoder_block(layer_in, n_filters, batchnorm=True):\n    init = RandomNormal(stddev=0.02)\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    init = RandomNormal(stddev=0.02)\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n    g = BatchNormalization()(g, training=True)\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n    g = tf.keras.layers.concatenate([g, skip_in])\n    g = Activation('relu')(g)\n    return g\n\n\ninit = RandomNormal(stddev=0.02)\ninput_shape=(256,256,1)\n\nimg_input1 = Input(shape=input_shape)\nimg_input2 = Input(shape=input_shape)\nimg_input3 = Input(shape=input_shape)\n\nconcat_input = tf.keras.layers.concatenate([img_input1,img_input2, img_input3])\n\ne1 = define_encoder_block(concat_input, 64, batchnorm=False)\ne2 = define_encoder_block(e1, 128)\ne3 = define_encoder_block(e2, 256)\ne4 = define_encoder_block(e3, 512)\ne5 = define_encoder_block(e4, 512)\ne6 = define_encoder_block(e5, 512)\ne7 = define_encoder_block(e6, 512)\nb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\nb = Activation('relu')(b)\nd1 = decoder_block(b, e7, 512)\nd2 = decoder_block(d1, e6, 512)\nd3 = decoder_block(d2, e5, 512)\nd4 = decoder_block(d3, e4, 512, dropout=False)\nd5 = decoder_block(d4, e3, 256, dropout=False)\nd6 = decoder_block(d5, e2, 128, dropout=False)\nd7 = decoder_block(d6, e1, 64, dropout=False)\nd8 = decoder_block(d7, concat_input, 64, dropout=False)\n\nout_image = Conv2D(1, (1, 1), activation='tanh')(d8)\n\nmodel = Model(inputs = [img_input1,img_input2,img_input3], outputs = out_image)\nopt = Adam(1e-5, beta_1=0.5)\nmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\nreturn model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(1e-5, beta_1=0.5)\ngenerator.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaded_model = load_model('./generator_model.h5')\nloaded_model.compile(loss=['mae'], optimizer=opt)\nresults = loaded_model.evaluate([SUPRESSION_IMAGES_GAN,SUPRESSION_IMAGES_OTSU_GAN,SUPRESSION_IMAGES_CANNY_GAN], SUPRESSION_TARGETS_GAN,batch_size=32, verbose=1)\nprint(\"Loss:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = loaded_model.evaluate([SUPRESSION_IMAGES_GAN,SUPRESSION_IMAGES_OTSU_GAN,SUPRESSION_IMAGES_CANNY_GAN], SUPRESSION_TARGETS_GAN, verbose=1)\nprint(\"Loss:\", results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Masks","metadata":{}},{"cell_type":"code","source":"X_train = (np.array(ima).reshape((len(ima), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5\nX_train_otsu = (np.array(ima_otsu).reshape((len(ima_otsu), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5\nX_train_canny = (np.array(ima_canny).reshape((len(ima_canny), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5\ny_train = (np.array(mas).reshape((len(mas), SIZE, SIZE, 1)).astype('float64') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 300\nimage_rx = np.squeeze(X_train[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\n#supression_rx = np.squeeze(y_train[number].astype(np.float64))\n#plt.imsave('supression_000.jpg', supression_rx, cmap='gray')\n#supression_000 = cv2.imread('./supression_000.jpg',1)\n\npredicted_rx = generator.predict([X_train[[number]].astype(np.float64),X_train_otsu[[number]].astype(np.float64),X_train_canny[[number]].astype(np.float64)],verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\nimg = cv2.imread('./predicted_000.jpg',1)\n\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nkernel = np.ones((5,5),np.uint8)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\ncontours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\ncnt0 = contours[0].reshape(-1,2)\nepsilon0 = 0.000001*cv2.arcLength(cnt0,True)\napprox0 = cv2.approxPolyDP(cnt0,epsilon0,True)\ntry: \n    cnt1 = contours[1].reshape(-1,2)\n    epsilon1 = 0.0000001*cv2.arcLength(cnt1,True)\n    approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\nexcept:\n    pass\ncanvas = np.zeros(thresh.shape, np.uint8)\n\n#draw = cv2.drawContours(canvas, approx, -1, (0,255,0), 3)\n#plt.imsave('predicted_000.jpg', thresh, cmap='gray')\n\ncv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\ntry:\n    cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\nexcept:\n    pass\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\ncv2.imwrite('predicted_000.png',thresh)\npredicted_000 = cv2.imread('./predicted_000.png',1)\n\nout = np.zeros_like(thresh)\nfor i in range(0,SIZE):\n    for j in range(0,SIZE):\n        #out[thresh == 255] = image_rx[thresh == 255]\n        if thresh[i,j] == 255:\n            out[i,j] = image_rx[i,j]*127.5 + 127.5\n        \ncv2.imwrite('out_000.png',out)\nout_000 = cv2.imread('./out_000.png',1)\n\nstack = np.hstack((image_000, predicted_000,out_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"COVID","metadata":{}},{"cell_type":"code","source":"X_train = (np.array(covid_images).reshape((len(covid_images), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nX_train_otsu = (np.array(covid_images_otsu).reshape((len(covid_images_otsu), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5\nX_train_canny = (np.array(covid_images_canny).reshape((len(covid_images_canny), SIZE, SIZE, 1)).astype('float32') - 127.5) / 127.5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length = len(covid_image_name)\n#os.makedirs('./input/images_segment')\n\nfor number in range(0,length):\n    image_rx = np.squeeze(X_train[number].astype(np.float64))\n    predicted_rx = generator.predict([X_train[[number]].astype(np.float64),X_train_otsu[[number]].astype(np.float64),X_train_canny[[number]].astype(np.float64)],verbose = 1)\n    predicted_rx = np.squeeze(predicted_rx.astype(np.float64))\n    \n    plt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\n    img = cv2.imread('./predicted_000.jpg',1)\n\n    img_grey = img[:,:,0]\n    min_ = img_grey.min()\n    max_ = img_grey.max()\n    ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n    cnt0 = contours[0].reshape(-1,2)\n    epsilon0 = 0.000001*cv2.arcLength(cnt0,True)\n    approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n\n    try: \n        cnt1 = contours[1].reshape(-1,2)\n        epsilon1 = 0.0000001*cv2.arcLength(cnt1,True)\n        approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n    except:\n        pass\n\n    canvas = np.zeros(thresh.shape, np.uint8)\n\n    cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n    try:\n        cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n    except:\n        pass\n    ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    cv2.imwrite('predicted_000.png',thresh)\n    predicted_000 = cv2.imread('./predicted_000.png',1)\n\n    out = np.zeros_like(thresh)\n    for i in range(0,128):\n        for j in range(0,128):\n            if thresh[i,j] == 255:\n                out[i,j] = image_rx[i,j]*127.5 + 127.5\n                \n    cv2.imwrite('./input/images_segment/'+covid_image_name[number],out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid = \"./input/images_segment\"\ncovid_list = os.listdir(covid)\nlen(covid_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length = len(covid_image_name)\nos.makedirs('./input/segment')\n\nfor number in range(0,length):\n    image_rx = np.squeeze(X_train[number].astype(np.float64))\n    predicted_rx = generator.predict(X_train[[number]].astype(np.float64),verbose = 1)\n    predicted_rx = np.squeeze(predicted_rx.astype(np.float64))\n    \n    #plt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\n    #img = cv2.imread('./predicted_000.jpg',1)\n\n    #img_grey = img[:,:,0]\n    #min_ = img_grey.min()\n    #max_ = img_grey.max()\n    #ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    #contours,hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_TC89_KCOS)\n\n    #cnt0 = contours[0].reshape(-1,2)\n    #epsilon0 = 0.000001*cv2.arcLength(cnt0,True)\n    #approx0 = cv2.approxPolyDP(cnt0,epsilon0,True)\n\n    #cnt1 = contours[1].reshape(-1,2)\n    #epsilon1 = 0.0000001*cv2.arcLength(cnt1,True)\n    #approx1 = cv2.approxPolyDP(cnt1,epsilon1,True)\n\n    #canvas = np.zeros(thresh.shape, np.uint8)\n\n    #cv2.drawContours(canvas, [approx0],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n    #cv2.drawContours(canvas, [approx1],-1, (255, 255), thickness = -1, lineType = cv2.LINE_AA)\n    #ret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n    #cv2.imwrite('predicted_000.png',thresh)\n    #predicted_000 = cv2.imread('./predicted_000.png',1)\n\n    #out = np.zeros_like(thresh)\n    #for i in range(0,128):\n    #    for j in range(0,128):\n    #        if thresh[i,j] == 255:\n    #            out[i,j] = image_rx[i,j]*127.5 + 127.5\n                \n    cv2.imwrite('./input/segment/'+covid_image_name[number],predicted_rx)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.2 - Read and transform images","metadata":{}},{"cell_type":"code","source":"seg_path = os.path.join(\"./input/images/\")\n#segm = os.listdir(seg_path)\nIMAGES_SEG = list()\nfor i in tqdm(names):\n    path_images = seg_path + str(i)\n    image = cv2.imread(path_images,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    IMAGES_SEG.append(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGES_SEG = np.array(IMAGES_SEG)\nIMAGES_SEG = IMAGES_SEG.reshape((len(IMAGES_SEG), SIZE, SIZE, 1))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGES_SEG_3C = list()\n\nfor img in IMAGES_SEG:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    IMAGES_SEG_3C.append(img_3C)\n    \nIMAGES_SEG_3C = np.array(IMAGES_SEG_3C)\nIMAGES_SEG_3C = IMAGES_SEG_3C.astype('float32') / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Lung segmentation from Chest X-Ray","metadata":{}},{"cell_type":"code","source":"number = 3\nimage_rx = np.squeeze(SEGMENTATION_IMAGES[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\nsupression_rx = np.squeeze(IMAGES_SEG_3C[number].astype(np.float64))\nplt.imsave('supression_000.jpg', supression_rx, cmap='gray')\nsupression_000 = cv2.imread('./supression_000.jpg',1)\n\nsupression1_rx = np.squeeze(SEGMENTATION_MASKS[number].astype(np.float64))\nplt.imsave('supression1_000.jpg', supression1_rx, cmap='gray')\nsupression1_000 = cv2.imread('./supression1_000.jpg',1)\n\n\nstack = np.hstack((image_000,supression_000, supression1_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = 1\nactivation = 'sigmoid'\nLR = 0.0001\noptim = keras.optimizers.Adam(LR)\nBATCH_SIZE = 16\nBACKBONE1 = 'resnet34'\npreprocess_input1 = sm.get_preprocessing(BACKBONE1)\n\nX_train_s, X_test_s, y_train_s, y_test_s = train_test_split(IMAGES_SEG_3C, SEGMENTATION_MASKS, test_size=0.30, random_state=12)\n\nx_train = preprocess_input1(X_train_s)\nx_val = preprocess_input1(X_test_s)\n\nmodel = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes = n_classes, activation = activation)\nmodel.compile('Adam', loss='binary_crossentropy', metrics=[dice_coef_loss])\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callbacks = [ModelCheckpoint('Segmenter_lung.h5', monitor='val_dice_coef_loss', verbose=1, save_best_only=True, mode='min')]\nhistory = model.fit(x_train, y_train_s, batch_size = 16, epochs = 300, verbose = 1, validation_data = (x_val,y_test_s), callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('./Segmenter_lung.h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 200\nimage_rx = np.squeeze(X_test_s[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\nsupression_rx = np.squeeze(y_test_s[number].astype(np.float64))\nplt.imsave('supression_000.jpg', supression_rx, cmap='gray')\nsupression_000 = cv2.imread('./supression_000.jpg',1)\n\npredicted_rx = loaded_model.predict(X_test_s[[number]].astype(np.float64),verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\npredicted_000 = cv2.imread('./predicted_000.jpg',1)\n\n\n\nstack = np.hstack((image_000,supression_000,predicted_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(10,26))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. Classification Normal x Pneumonia","metadata":{}},{"cell_type":"code","source":"summary = pd.read_csv(\"../input/coronahack-chest-xraydataset/Chest_xray_Corona_dataset_Summary.csv\")\nsummary","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata = pd.read_csv(\"../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\")\nmetadata_ = metadata['Label']\nmetadata_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metadata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_image_name","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"le = preprocessing.LabelEncoder()\ntarget = le.fit_transform(metadata_)\ntarget","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('../input/package-models/Supression_lung_Xnet (1).h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/images_covid')\nlength = len(covid_image_name)\n\nfor number in range(0,length):\n    predicted_rx = loaded_model.predict(COVID_IMAGES[[number]].astype(np.float64),verbose = 1)\n    predicted_rx = np.squeeze(predicted_rx.astype(np.float64))\n    plt.imsave('./input/images_covid/'+covid_image_name[number], predicted_rx, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 28\nimage_rx = np.squeeze(COVID_IMAGES[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\n\npredicted_rx = loaded_model.predict(COVID_IMAGES[[number]].astype(np.float64),verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\npredicted_000 = cv2.imread('./predicted_000.jpg',1)\n\n\nstack = np.hstack((image_000,predicted_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(8,24))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"covid_images_for_seg = list()\n\nfor i in tqdm(covid_image_name):\n    path_images_train = './input/images_covid/' + str(i)\n    image = cv2.imread(path_images_train,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image, (SIZE,SIZE), interpolation = cv2.INTER_AREA)\n    covid_images_for_seg.append(image)\n\n\nCOVID_IMAGES_4SEG = np.array(covid_images_for_seg)\n\nCOVID_IMAGES_4SEG = COVID_IMAGES_4SEG.reshape((len(COVID_IMAGES_4SEG), SIZE, SIZE, 1))\n\nCOVID_IMAGES_4SEG = COVID_IMAGES_4SEG.astype('float32') / 255    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COVID_IMAGES_4SEG_3C = list()\n\nfor img in COVID_IMAGES_4SEG:\n    img_3C = np.concatenate((img,)*3, axis=-1)\n    COVID_IMAGES_4SEG_3C.append(img_3C)\n    \nCOVID_IMAGES_4SEG_3C = np.array(COVID_IMAGES_4SEG_3C)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dependencies = {'dice_coef_loss': dice_coef_loss}\nloaded_model = load_model('../input/package-model-2/Segmenter_lung (5).h5', custom_objects=dependencies)\nloaded_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef_loss])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('./input/images_covid_segmentation')\nlength = len(covid_image_name)\n\nfor number in range(0,length):\n    predicted_rx = loaded_model.predict(COVID_IMAGES_4SEG_3C[[number]].astype(np.float64),verbose = 1)\n    predicted_rx = np.squeeze(predicted_rx.astype(np.float64))\n    plt.imsave('./input/images_covid_segmentation/'+covid_image_name[number], predicted_rx, cmap = 'gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"number = 28\n\n\nimage_rx = np.squeeze(COVID_IMAGES_4SEG_3C[number].astype(np.float64))\nplt.imsave('image_000.jpg', image_rx, cmap='gray')\nimage_000 = cv2.imread('./image_000.jpg',1)\n\n\npredicted_rx = loaded_model.predict(COVID_IMAGES_4SEG_3C[[number]].astype(np.float64),verbose = 1)\npredicted_rx = np.squeeze(predicted_rx.astype(np.float64))\nplt.imsave('predicted_000.jpg', predicted_rx, cmap='gray')\n\nimg = cv2.imread('./predicted_000.jpg',1)\nimg_grey = img[:,:,0]\nmin_ = img_grey.min()\nmax_ = img_grey.max()\nret1, thresh = cv2.threshold(img_grey, min_, max_, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\nkernel = np.ones((5,5),np.uint8)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\nthresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\nplt.imsave('predicted_000.jpg', thresh, cmap='gray')\npredicted_000 = cv2.imread('./predicted_000.jpg',1)\n\nstack = np.hstack((image_000,predicted_000))\ncv2.imwrite('stack.png',stack)\n\nfig = plt.subplots(figsize=(8,24))\nstack = cv2.imread('./stack.png',1)\nplt.imshow(stack)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}